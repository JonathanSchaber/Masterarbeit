\newchap{Conclusion}
\label{chap:6_conclusion}


In a first paragraph, I will quickly point out the core elements of my thesis. In a second part, I
locate my findings in the current debate; and lastly, I will look into further steps that could be
taken from this point on.

My thesis consists mainly of three components: (1) The compilation of a German NLU
dataset, \emph{GerGLUE}, incorporating different tasks and modalities, as well as
including domain-specific language, ranging from colloquial to highly stylized texts.
(2) A pipeline which brings all data sets in the same workable format, computes SRLs
by implementing two freely available tools (ParZu, DAMESRL) and several instruments
for training and analyzing models. (3) \emph{GliBERT}, a BERT-based architecture
which combines vanilla BERT-embeddings with embedded SRLs during fine-tuning, with
several heads on top.

After carrying out a multitude of experiments with different heads, SRL implementations,
and merging techniques, I come to a guarded conclusion: For classification tasks, combining
embedded SRL information with contextualized word represenations during finetuning leads to
a performance gain as was demonstrated for German BERT embeddings. But the findings are not
too clear, sometimes there was even a negative effect observed for certain data sets and
configurations. However, it has to be kept in mind that there was noise detected on several
levels of the used data and implemented instruments, so that hypothetically, with cleaner
data and better SRLs, the effect would probably be clearly positive. For the both question
answering tasks, there was no positive effect of SRL information observable --- in contrary,
the effect was clearly negative. On the reasons for this, I can only speculate, and need
to delay this investigation for the other points on the list for future research in this field:hjhhhj

% TODO: elaborate more on general take aways


\section{Outlook / Future Work}

In the following list I scetch loosely further experiments, open questions, and topics which
seem to me worthy of investigation:

\begin{itemize}
  \item better SRL system (bspw. mit MOD-NEG detection)
  \item ``sincere'' hyper-param search
  \item more thoroughful SRL quality estimation
  \item compile data sets targeted at weaknesses of BERT
  \item ``Manually'' add negation particle from parse tree information
  \item Inspect weight matrices for further analysis of models
\end{itemize}


