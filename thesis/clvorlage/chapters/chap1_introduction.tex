\newchap{Introduction}
\label{chap:1_intro}

% \epigraph{Not only the entire ability to think rests on language... but language is also the crux of the misunderstanding of reason with itself.}{\textit{Johann Georg Hamann}}

In this chapter, I will expand a bit further to put the intent of this master's thesis into a
bigger picture. Therefore, I will line out the general problems and topics of NLU and elaborate
on the methods and techniques that were developed to address those questions.

Further, I will tie in my {\color{red} approach} with the current research efforts in NLU.


\section{Motivation}

Human language bears some truly mesmerizing features and puzzles, a lot of them are still not yet
understood in all its depths: For example, it is still unclear how children are able to learn the
grammar of their mother tongue from the corrupted and comparatively scarce language material they
are exposed to (cf. \cite{lust2006child, lewis2001learnability}).\myfootnote{The famous term describing this
phenomenon, ``Poverty of Stimulus'' (POS), was coined by \cite{chomsky1980cognitive}, arguing for
an innate language learning/processing faculty. This has led to a fierce debate over that issue:
Many researchers claim that the POS-motivated necessity for such an innate, human-specific,
genetic trait does not hold, and humans learn language simply by means of extremely sophisticated
statistic analysis. It has indeed been shown that infants are amazingly apt at extracting
statistical information from auditive input \citep{saffran1996statistical}. However, as was
countered by Chomsky and others, this does not fully explain the ability of children to apply
these statistical input cues to \emph{hierarchical} structures : ``The issue that is so central
to this particular POS problem is tacit knowledge by the child that grammatical rules apply to
such [hierarchical] structures'' \citep{berwick2013poverty} --- there is no behavioral explanation
for the tacit knowledge about hierarchical structures in the mind of the child. Therefore,
the POS argument still holds, although it has been somewhat weakened by empirical findings about
acquisition driven by statistical insights.}

%(POS, Chomsky etc) Another astonishing fact about human language
% is the overwhelming amount of languages that exist today, even that number was probably much
% higher a few centuries ago.  As to how languages evolve, change over time and what trajectories
% of possible change may be, lots of questions are still open, and there remains enough work
% to do.

One of the most trivial and enigmatic traits about human language and communication is
that we actually \emph{understand} each other so well: That during a discourse, person
X can reliably recover the encoded meaning of the expressions in the language signal
uttered by person Y, and vice versa, especially given the ``noisy channel'' problem (cf.
\cite{plotkin2000language}), which is elaborated on a little more below. Further, we are
able to reconstruct a lot information that is not explicitly stated in an expression, and
uphold such a mutually shared belief of state of affairs during a discourse. In fact,
this ``shared intentionality'' is hypothesized as being one of the traits that separates
human cognition and language from other animals (cf. \cite{tomasello2007shared}).

Because {\color{red} rational} thinking, reasoning, and cognition in general are being perceived
as essentially linked to human linguistic competences, communicative abilities have been proposed
to act as a proxy for attesting intelligence to non-human entities. \cite{turing1950computing}
suggested his renowned ``Turing-Test'' as method for determining the capabilities of artificial
intelligence systems: If the communicative behavior of an agent is indistinguishable from that of
a human agent, it is justifiable, according to this view, to attribute ``intelligence'' to such a
system.

However, reproducing human linguistic capabilities has turned out to be much harder
than was predicted during the 50ies, where scientists were enthused by then recent
developments of computers and predicted that machine translation would be a solved
problem by a few years \citep{hutchins2005history}. This is mainly due to the fact
that humans are incredibly apt at handling the various complexities present in the
linguistic signal; we handle those with such unconscious ease that we are mostly
not even aware of it:

\begin{description}
  \item[Vagueness] We have no problem dealing with vague statements like ``Most people never heard of it''; in a specific conversation situation we rely on extra-linguistic cues like pragmatics and common world knowledge to decide if ``most'' means 7.5 billion people, or 70\% of our friends, or if the approximate number is even relevant.
  \item[Ambiguity] The fact that a linguistic sign can't be interpreted in only one way, is an ubiquitous phenomenon in human language that is present on all levels: phonological, lexical, syntactic, semantic, pragmatic. A classic example for syntactic ambiguity would be the phrase ``He saw the elephant with a telescope''.
  \item[Corruption] Contrary to how we perceive language when speaking to each other, utterances are mostly not well-formed, grammatical sentences, but show a varying degree of stutter, incomplete phrases, repetitions, and other ``mistakes''. While not as present in written language, depending on the domain, there still is quite some noise present, e.g. in online chat threads etc. Still, we mostly have no problems at all, reconstructing the encoded information from such a corrupted signal --- contrary to algorithmic models as will become obvious during the course thesis.
  \item[Common world knowledge] Normally the information we encode in ordinary conversation is highly condensed and as scarce as possible --- most of the actual information is reconstructed by the receiver, making use of general knowledge about the world (factual knowledge, such as ``Bern is the capital of Switzerland'' and ``Switzerland lies in Europe'', which together with logical reasoning, e.g. the \textit{modus ponendo pones}, lead to true deductions like ``Bern must be geographically located in Europe'') and the actual situation, time, and place the conversation takes place.
\end{description}

So, every system that is built aiming at processing natural language in a ``deep'', human-like
manner must cope with this inherent fuzzinesses of human communication. In the field of
applied computational linguistics, often referred to as Natural Language Processing (NLP),
this subfield of research is known as Natural Language Understanding (NLU).\myfootnote{Note
that I will not engage in the discussion about whether it is philosophically appropriate
to claim that computational models ``understand'' human language. A lot of controversy has
arisen around this issue, with positions ranging from completely denying language models any
sort of (linguistic) understanding \citep{bender2021dangers} to the current trend of simply
concentrating on beating NLU SOTAs with ever larger models and blindly taking this as proof
of building architectures capable of learning human language. I would argue that the thruth
lies somewhere in between: Of course it is not enough to perform well on a standardized data
set to speak of ``understanding'', however, as \cite{sahlgren2021singleton} point out: Also
in humans, especially children, we measure language competences indirectly ``by using various
language proficiency tests, such as vocabulary tests, cloze tests, reading comprehension, as
well as various forms of production, interaction, and mediation tests \textelp{}''. Therefore,
I think it is not completely unsound to assess NLU capabilities of artificial systems
by measuring their performance on standardized datasets.}
NLU aims at building systems which are able to retrieve the semantic content encoded
in natural language and are able to further act upon it: For example, a chatbot should
be capable of ``understanding'' that the questions ``What's the weather like?'', ``Can
you tell me today's weather forecast, please?'', ``Will I need an umbrella today?'' all
have more or less the same meaning and should provoke the same answer and/or reaction
of the system.\myfootnote{Although one could argue that the third question differs from
the first two since it is a polar question; i.e. a simple ``yes'' or ``no'' would be
grammatically correct --- however, I have the strong feeling one would perceive this as
a very dry, or even rude, answer and would expect a more elaborated answer in a regular
conversation context.}

% TODO: embed this quote


% ``It is always precarious to build arguments on inherently vague and general
% concepts such as `language', `understanding' and `meaning,' as the resulting
% theoretical constructs may become so overly general that they almost become
% vacuous.'' \cite{sahlgren2021singleton}

% \begin{quote}
%   learning a language entails learning the set of symbols and rules that define the
%   system. Learning the set of symbols equals vocabulary acquisition, while learning
%   the rules entails recognizing and formalizing grammatical, morphological, and
%   syntactic regularities.i We measure these competencies in humans — often indirectly
%   — by using various language proficiency tests, such as vocabulary tests, cloze
%   tests, reading comprehension, as well as various forms of production, interaction,
%   and mediation tests \textelp{}. \cite{sahlgren2021singleton}
% \end{quote}

% \begin{quote}
%   there is an overwhelming body of empirical results to demonstrate that current language models
%   have a passable capacity to detect the symbols and rules that define human language. This is not
%   what is under dispute in the current debate; what is under dispute is whether such structural
%   knowledge about the workings of the language system suffices.
% \end{quote}

\subsection{History, Methods, Problems of NLP and NLU}


% ``The `understanding' these models have of language is entirely structural,
% and thus does not extend beyond the language system'' \cite{sahlgren2021singleton}

% ``We can of course always question whether there is any `real' under-
% standing going on, but if the absence or presence of this `real' understanding
% has no effect on the behavior of the system, it will be a mere epiphenomenon
% that need not concern us.'' \cite{sahlgren2021singleton}

% ``consciousness is not an extra ingredient in addition to the complexity of a system:
% consciousness is the complexity of the system. Our point is that understanding is also
% not an extra ingredient of a symbol manipulation system: `understanding' is a term we
% use to describe the complexity of such a system.'' \cite{sahlgren2021singleton}

% ``Our point is that when the behavior of an NLU system becomes sufficiently complex, it will be
% easier to explain its behavior using intentional terms such as `understanding,' than to use a
% purely functional explanation.'' \cite{sahlgren2021singleton}

% The subsection of NLP that deals with the semantics, i.e. meanings, of utterances, is NLU.


NLP, and NLU as a sub-discipline of it, is ``[t]he engineering side of computational
linguistics'', that is ``largely concerned with building computational tools that do
useful things with language'' \cite{johnson2009statistical}. Therefore, the main goal
of NLP is not to describe or explain structures in human language employing computational
theories but rather to solve a specific problem regarding human language: For example, one
wants to design and implement a system that automatically detects the emotion that is
transported in a given text snippet. In the relatively young history of the field of
NLP, there are three d phases identifiable regarding the main architectural strategies of these
models or systems, which I will briefly outline:

During the first, or \emph{symbolic}, phase of NLP that lasted approximately from the 1950ies
until the 1980ies, systems addressing tasks such as machine translation were architectures that
consisted of carefully hand-written symbolic grammars and knowledge bases. This period was heavily
influenced by works in theoretical linguistics, especially Chomsky's transformational-generative
grammar \citep{chomsky2009syntactic,chomsky2014aspects}. The initial enthusiam over the theoretical
proficiency of such models that sat in, however, was soon severely dampened when it became clear
that the complexity of human language in real-world applications had been underestimated.


From the 1990ies on, a \emph{statistical turn} took place, and NLP turned towards
data-driven solutions, making use of the increased availability of large amounts of
electronic text on the one hand and computers with increased computating power and
memory on the other \citep{liddy2001natural}.
NLP problems were now being addressed by learning patterns from huge data collections. One
driver of this paradigm shift were the various difficulties the traditional systems bore: Their
development ``requir[ed] a great deal of domain-specific knowledge engineering. In addition,
the systems were brittle and could not function adequately outside the restricted tasks for
which they were designed'' \citep[p.~13]{brill1997overview}. The new, statistical {\color{red}
approach} tried to tackle NLU-problems by shifting the focus from tedious hand-crafting ``to
empirical, or corpus-based, methods in which development is much more data driven and is at
least partially automated by using statistical or machine-learning methods to train systems
on large amounts of real language data'' \citep[p.~13]{brill1997overview}. The main challenge
for engineers and scientists now laid in identifying suitable features and encoding them in
appropriate data structures, according to which the algorithm would learn helpful patterns from
the language data for solving the task at hand.

% A classical, although not really NLP specific,
% example would be spam detection: Instead of writing rules according to which an email gets
% classified as potential spam or not, one creates a dataset with thousands of mails, represented
% as bag-of-word vectors\myfootnote{The vocabulary $V$ consisting of all tokens in the emails
% gets encoded into a large vector $v^{|V|}$ where for each mail the dimensions corresponding
% to the words present in the mail} and each labelled if it is spam or not. a machine learning
% algorithm, e.g. a naive-bayes classifier, can now be trained on this dataset to ``learn'' the
% likelihood functions according to which an unseen mail then can by classified.

With this orientation towards data-driven NLP solutions came also the {\color{red} technique}
of comparing different architectures on standardized data sets to evaluate their capabilities
regarding the problem the dataset was constructed to {\color{red} image/abbilden}.

For half a decade now the next stage in NLU and NLP in general was entered: we are now in the
middle of the \emph{neural age} of computational linguistics, where models are constructed
implementing deep, i.e. multi-layered, neural networks for learning generalizable patterns and
functions from data. For many people in the NLP field, the advent of those powerful but at
the same time difficult to interpret, obscure machine learning algorithms also posed a threat to
the established approaches regarding NLP problems: ``Deep Learning waves have lapped at the
shores of computational linguistics for several years now, but 2015 seems like the year when
the full force of the tsunami hit the major Natural Language Processing (NLP) conferences''
\citep[p.~701]{manning2015computational}. Nevertheless, deep learning approaches are by now an integral
part of the vast majority NLP applications.

In contrast to the statistical period's main challenge --- the identification and extraction
of suitable features ---, now the algorithms are itself learning the features that are the
most informative for a given task from raw data.\myfootnote{This is probably most obvious in
computer vision contexts, where the input data for neural models is the raw RGB pixel image
data, in contrast to pre-deep learning algorithms, where the input of a machine learning
system would be a data structure produced by some feature detection d algorithm, such as SIFT
\citep{lowe1999object}. For text, however, the case is not as clear as to what the ``raw''
representation of it for a model would be, as will be shown in the next chapter.} The human
part in the process is now ``reduced'' to design the overall model architecture, define the
hypaerparameters of the model and the training set up, and compile large enough amounts of
data that are, in the best case, also of good quality.

While the roughly sketched methods above apply to a wide ranges of
applications in NLP, I will now point to some of the enquiries NLU aims
at: Simply put, NLP is concernced with the structural side of natural
language text, while NLU looks at the content of these utterances. For
example, typical NLP tasks such as dependency parsing, POS-tagging, and
coreference soltution don't require a semantic representation of words
or phrases --- often, it suffices to look at structural properties such
as morphology, simple frequency statstics, or transition probablities
to solve such problems to an acceptable extent. On the other hand, NLU
tries to process language more in a manner like humans do it: We infer
something from language, recocile communication information with our
world knowledge, answer questions, detect logical inconsistencies etc.

% \cite{mcshane2017natural} in her paper on NLU in cognitive agents argues that truly
% NLU-capable systems's abilities must go beyond ``mere'' symbol processing:

% \begin{quote}
%   cognitive agents must be nimble in the face of incomplete interpretations since even people do not
%   perfectly understand every aspect of every utterance they hear. This means that once an agent
%   has reached the best interpretation it can, it must determine how to proceed — be that acting
%   upon the new information directly, remembering whatever it has understood and waiting to see
%   what happens next, seeking out information to fill in the blanks, or asking its interlocutor
%   for clarification. The reasoning needed to support NLU extends far beyond language itself,
%   including, nonexhaustively, the agent’s understanding of its own plans and goals; its dynamic
%   modeling of its interlocutor’s knowledge, plans, and goals, all guided by a theory of mind;
%   its recognition of diverse aspects of human behavior, such as affect, cooperative behavior,
%   and the effects of cognitive biases; and its integration of linguistic interpretations with
%   its interpretations of other perceptive inputs, such as simulated vision and nonlinguistic
%   audition. Considering all of these needs, it seems hardly possible that fundamental NLU
%   will ever be achieved through the kinds of knowledge-lean text-string manipulation being
%   pursued by the mainstream natural language processing (NLP) community. Instead, it requires
%   a holistic approach to cognitive modeling of the type we are pursuing in a paradigm called
%   OntoAgent.
% \end{quote}

All disagreements about the very nature of ``understanding'' and ``communication'' set aside,
there is probably consensus that we are far from being able to construct a system that
would pass the Turing test.
As laid out in the quote above, such a model would need
to be equipped with



\subsection{Subtasks of Solving NLU}

As the endeavor of building a holistic, fully NLU capable agent is probably an objective too
ambitious to achieve at once, the strategy in modern computational linguistics is to break it
down into smaller ``subproblems'':

Several core building blocks of NLU have been identified and datasets comprising examples tailored at those
have been compiled. The performance of new models and approaches on such data sets is often taken as
a proxy for attesting NLU capabilities targeted at the task.

Some of these proposed subproblems or proto-tasks of NLU are the following:

\begin{description}
  \item[Sentiment Detection] Given a sentence, we can normally assess if the emotion transmitted by
      it is rather positive, negative, or neutral: ``Oh my, what a lovely day!'' is clearly positive,
      while  ``asdasd'' probably is not.
  \item[Grammaticality Recognition] Being able to understand utterances in a language also implies
      being able to judge the grammaticality of any statement in that language: ``Eagles that fly can
      eat'' is judged as valid by English speakers while ``Eagles that fly eat can'' is not.
  \item[Entailment Recognition] An important ability of understanding is the recognition of the
      logical relationship in which two utterances stand. In other words, given two sentences $A$ and
      $B$, does $B$ follow from $A$? For example, given the sentence ``The weather forecast predicts
      rainfall the next days'' does the sentence ``Tomorrow will be a beautiful, sunny day'' conform,
      contradict or stand in a neutral relation to the first sentence.
  \item[Question Answering] To locate a (or rather, the) relevant text span in a given context according to some
      questions is also a task where one would assume that some sort of understanding is needed:
      Given the question `` What was the name of the King of England?'' and the context ``Henry
      V (16 September 1386 – 31 August 1422) was King of England from 1413 until his death in
      1422.'', a system would would need to extract the span ``Henry V''.
\end{description}

Since each of these tasks and datasets are focused on a specific subpart of general NLU and
it is by no means implied that a system which e.g. performs well on entailment recognition
will be able to extract answer spans to an acceptable degree. Therefore, to assert that some
model or approach does indeed capture some properties of real NLU, it has become standard
to evaluate on several of those subtasks. One of the best established compilations of such
subtasks is the GLUE benchmark citep{wang2018glue}, `` a collection of NLU tasks including
question answering, sentiment analysis, and textual entailment, and an associated online
platform for model evaluation, comparison, and analysis.'' \citep{wang2018glue}.

Since my thesis is concerned with German and there is no such standardized benchmark, I
compiled one for myself --- GerGLUE. GLUE and GerGLUE are described in more detail in
chapter \ref{chap:3_datasets}.


\subsection{Text Representations}

Text can be analysed and represented in various ways; in fact, those characters on the
sheet you are reading right now are one form of representing language. However, for an
algorith language represented by means of an alphabetical script is not a well-suited
encoding --- since de Saussure it is established that the actual characters are completely
arbitrary in what they denote \citep{de1989cours}. There is nothing in the properties of
the character(-sequence) \emph{itsef} which would relate it necessarily to the thing it
represents. Nothing in the mere shape of the character sequence ``contrary'' implicates
on what meaning, or signifié, this string, or signifiant, maps onto. As human beings, if
capable of reading the Latin alphabet and knowing the English language, we decipher the
string to symbolize the linguistic concept, we pronounce /\textprimstress k\textscripta
nt\textturnr \textschwa \textturnr i /.\myfootnote{There exist so-called featural writing
systems which actually encode phonological information in the form of their characters,
e.g. the Korean Hangul alphabet, which encodes the position of the tongue for producing a
consonant \citep{sampson1985writing}.} In other words, for a computational system to act
upon human language input, we must find a way to encode this input in a way, that actually
represents structural information; depending on what the model is aimed for, this may be
phonological, syntactical, or semantic properties.

% \myfootnote{For simplicity, I will
% focus on written language in my thesis, however this applies to other modalities like
% speech and signing as well.}
For example, one could represent each word of a sentence as a number, e.g. the page number of the
Oxford English Dictionary on which the definition of the word --- or its lemma base form ---is
given: <Every> <event> <has> <a> <cause> $\rightarrow$ <234> <229> <388> <12> <176>. However, that
would probably not be very informative, but if we represent each word of a sequence by its POS, a
computational system designed for e.g. identifying Named Entities might retrieve task-supporting
information from it; especially if both representations, the ``normal'' one and the POS one, are
combined: <Every DET> <event NOUN> <has VERB> <a DET> <cause NOUN>.


\subsubsection*{Embeddings}


Most NLU models don't operate on the text as it is, i.e. as an array of UTF-8 encoded
signs. Often, it is easier to implement an algorithm that process text in some way, to
encode this text numerically. A strategy adopted quite early is the so-called Bag of
Words \citep{harris1954distributional} technique, which encoded a sequence of words $s$
in one vector, basically indicating what items of a given vocabulary or present in $s$.
% Given a corpus of texts, the whole vocabulary $V$, or some subset,
% e.g. the most frequent 10,000 tokens, gets encoded in one large vector $v \in 0^{|V|}$. Where
% the $i$th dimension of $v$ stands for the $i$th item in $V$.
% To encode a sentence $S$ in this vector, for each token in it, the correlating dimension of the
% vector gets set to 1.
While this BOW technique is quite effective for certain tasks, e.g. information extraction
systems often make use of it, it has some flaws: It fails in particular to reflect the core
property of language being inherently sequential --- the BOW encodings of ``Alice hit Bob''
and ``Bob hit Alice'' are indistinguishable.

Therefore, other methods of representing word sequences numerically have been devised, which assign
to each word in a sequence a numeral representation, thus preserving the sequential information.
Examples of such a representation would be Latent Semantic Analysis \citep{furnas1988using}, which
generates word vectors by reducing high-dimensional word co-occurrence matrices via singular value
decomposotion, or word2vec \citep{mikolov2013distributed} which showed the possibility of letting a
neural model compute those embeddings applying a language modeling objective.



\paragraph*{Contextualized Word Embeddings}

Research on the generation algorriths of such numerical word embeddings which can
be used as text representations for various NLP tasks has experienced tremendous
intereset in recent years, producing various architectures, and frameworks, leading
to the now state of the art of contextualized word embeddings: Such implementations
account for the fact that the semantic function of a word is heavily dependent on
the context in which it appears: The word ``building'' has quite different semantic
and syntactic funtions in the followng sentences: ``This is a very high building!''
and ``She was building an empire'' --- in this obvious example\myfootnote{The two
sentences exemplify the problem of homonymy: Two different lemmata having the same
word form. However, even if the same lemma is used in different context, subtle
changes in semantics and grammatical function are present.}, a word representation
framework which does not account for this, will clearly fail to adequatly interpret
such sentences.

The afore mentioned neural approaches in NLP have proven to be very apt at
producing such representations: ``The gains so far [from Deep Learning] have
not so much been from true Deep Learning (use of a hierarchy of more abstract
representations to promote generalization) as from the use of distributed word
representations—through the use of real-valued vector representations of words
and concepts.'' \citep[p.~703]{manning2015computational}

% CONTUNIATION OF QUOTA: Having a dense, multi-dimensional representation of similarity between all
% words is incredibly useful in NLP, but not only in NLP.

One effective framework of producing such contextualized word embeddings is BERT \citep{devlin2018bert},
which I also will employ for the experiments in my thesis. The general concpts of contextualized
word embeddings, transfer learning, and BERT in particular will be described in the next chapter
\ref{chap:2_approach}, section \ref{sec:pretrained-embeddings}.


\subsubsection*{Semantic Structures}

While the motivation for representing a sentence numerically is to let algorithms operate
then ``autonomously'' on these representations, for example by computing some distance measures
between a query and a set of texts for information retrieval, one can also try to encode
some structural information of the sentence at hand.
To support a model with information about what grammatical relations between
parts of a sentence are present, one could provide the algorithm with the syntax parse
tree of the sentence. This way, the difference between the afore mentioned
two ``hitting''-sentences would be clearly distinguishable.

\paragraph*{Semantic Role Labels}

Semantic Roles are a linguistic tool developed for analyzing a sentence regarding the
semantic relations that hold between different entities involved in the action described by
it, thus ``explaining both the syntactic structure as well as the meaning of sentences''
\cite{bussmann2006routledge}. It is sometimes considered to be one of the oldes concepts in
linguistic, conceptually contemplated as early as in the 6th century BCE by the old-indian
grammarian P\=a\d{n}ini (cf. \citep{gildea2002automatic}).

The core intention is to identify generalizable semantic functions, or semantic roles,
that participants in an event can engage in. With such an instrument, it is possible to
model the semantic equivalence of grammatical and syntactical quite different sentences
(after \cite{palmer2010semantic}):

\begin{examples}
  \item John broke the window.
  \item The window broke.
\end{examples}

Although ``break'' is a transitive verb in the first sentence while in the second an intransitive;
although ``window'' is the grammatical object in the prior while the grammatical object in the
latter --- the expressed action, or the encoded information, is the same both times --- that an
object, the window, was shattered.

Semantic Roles are an attempt to formalize this by attributing each constituent
a generalizable label. In this case, ``the window'' would be labelled as \emph{patient}
, i.e. the participant undergoing a change of state, in both sentences.
In the first, where there is also a clear initiator of this change, ``John''
would be labelled as the \emph{agent} of the event.

A more detailed elucidation on the concept semantic roles and its history wil be
given in chapter \ref{chap:2_approach}, section \ref{sec:semantic-roles}.

Thus, as a further form of representation, any sentence could be represented by the words in it
replaced by their Semantic Role Label (SRL): <John> <broke> <the> <window> $\rightarrow$ <AGENT>
<PREDICATE> <PATIENT> <PATIENT>. (Or, as mentioned before, a combination of the ``normal'' text
representation combined with SRLs)




\section{Contributions/Goals}

The goal of this thesis will be to explore if a combination of the two above described text
representation techniques may lead to embeddings which support machine learning algorithms
targeted at NLU tasks. For English, \cite{zhang2019semantics} showed that combining BERT
embeddings with numerically encoded SRL information leads to an increase in performance
compared to the vanilla BERT architecture on NLU tasks. However, their findings are somewhat
inconsistent and, probably due to the format of a short paper, the description of the
architecture and sound analysis of the results are {\color{red} rather meager.}\myfootnote{For
example, it is not clear \emph{what} results for the datasets are being reported: The best
run out of several experiments, the average performance of several experiments, etc. (due to
the random initialization of the weight matrices of the head modules and SRL encoder, there
are expectable fluctuations in performance, which makes it highly improbably that only one
model per task was trained). Neither control \citeauthor{zhang2019semantics} for statistical
significance, which makes sound statements about architecture superiority quite disputable.}

Although my approach stands in the tradition of recent machine learning trends in NLP --- i.e.
training a model on data and evaluating on test data for assessing model capabilities --- I
nevertheless view it also as an attempt at re-integrating linguistically motivated structures
into NLP: ``Recently at ACL conferences, there has been an over-focus on numbers, on beating the
state of the art. Call it playing the Kaggle game'' \citep[p.~702]{manning2015computational}.
Despite the apparent success of linguistic-agnostic architectures on NLP benchmarks, those
models tell us little about the nature of human language and the structural properties of it;
\citeauthor{manning2015computational} continuing: ``It would be good to return some emphasis
within NLP to cognitive and scientific investigation of language rather than almost exclusively
using an engineering model of research.''

By implementing textual representations more grounded in linguistic theories, I see one of
the contributions of my model also in antagonizing the tendency of modern NLP of becoming
more a brute force data engineering discipline and less a research endeavor motivated by
linguistic enigmas and possible insight in the inner workings of human language by trying
to address those puzzles employing a computational approach.


\section{Research Questions}

The research questions that shall be answered in this thesis, are:

\begin{enumerate}
  \item \label{ques:one} Does the combination of  BERT embeddings with structured SRL information have a positive,
                         measurable effect on NLU tasks?
    \begin{itemize}
      \item Since I replicate in some sense the work of \cite{zhang2019semantics}, are my findings similar to what they reported?
      \item Are there differences between datsets, registers, tasks, etc.?
      \item Are the datasets well-suited for making sound statements about the effect of enriching BERT embeddings with SRLs?
      \item In case the answer to the question above is no, does not hold, is there a way to determine nevertheless if SRLs might have a positive effect in more appropriate settings?
      \item Can I determine what aspect(s) of SRLs support models in downstream tasks?
    \end{itemize}
  \item \label{ques:two} Which head architecture for fine-tuning BERT-based, SRL-enriched text representations is best suited for
                          NLU tasks?
  \item \label{ques:three} What effects have different representation methods of combinations of BERT-subtokens with SRLs and different encoding techniques regarding the multilayered nature of semantic roles?
    \begin{itemize}
      \item The number of considered predicate-argument
            structures is fixed to be three per sentence; is it more effective to fill empty slots with
            0-SRLs, or duplicating existing SRLs?
      \item To merge BERT embeddings with SRLs, either
            the splitted BERT subtokens need to be merged back or the SRLs have to splitted up --- does
            this lead to different results?
    \end{itemize}

\end{enumerate}



\section{Thesis Structure}

In this first chapter I gave a very brief overview of general trends in
NLP over the past decades and highlighted some

Chapter \ref{chap:2_approach} introduces the basic concept of BERT,
its {\color{red} shortcomings} and presented solution or improvements. Further,
I explain my approach and the relating linguistic concepts.

The datasets I compiled to test my models on are described in detail
in chapter \ref{chap:3_datasets}.

In chapter \ref{chap:4_architecture}, I describe the details of the architecture of
my BERT-variant in all detail: The identification and encoding of the semantic role
labels, the different combination procedures of the BERT embeddings with these, as
well as the different head architectures.

The overview and discussion of the performance of the various model architectures on
the GerGLUE data set is made in chapter \ref{chap:5_results}.

Finally, I draw some insights and conclusions in the last chapter \ref{chap:6_conclusion}.

