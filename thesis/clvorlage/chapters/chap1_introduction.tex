\newchap{Introduction}
\label{chap:1_intro}

\epigraph{Not only the entire ability to think rests on language... but language is also the crux of the misunderstanding of reason with itself.}{\textit{Johann Georg Hamann}}

In this chapter, I will expand a bit further to put the intent if this master's thesis into
a bigger picture. Therefore, I will line out the general techniques and problems of NLP in
general and NLU in particular, which led to the approach at hand. {\color{red} After that,
I position my approach in current field.}


\section{Motivation}

Human language bears some truly mesmerizing features and puzzles, a lot of them are still not
yet understood in all its depths: For example, it is still unclear how children are able to
learn the grammar of their mother tongue from the corrupted and comparatively scarce language
material they are exposed to.
%(POS, Chomsky etc) Another astonishing fact about human language
% is the overwhelming amount of languages that exist today, even that number was probably much
% higher a few centuries ago.  As to how languages evolve, change over time and what trajectories
% of possible change may be, lots of questions are still open, and there remains enough work
% to do.
But maybe the most trivial and enigmatic trait about human language is that
we actually \emph{understand} each other: That during a discourse, person X can retrieve
the intentioned meaning of expressions uttered by person Y, and vice versa.  Further, we are
able to logically deduce a whole lot information that is not explicitly stated in a sentence,
and uphold such a state of affairs during the whole conversation.
%Maybe one of the most
% enigmatic and fascinating traits of human language is the fact that for us humans, exchanging
% information through language is a meaninglessly working process.
That this is not as trivial as it might look like on first sight, show the following
considerations:

\begin{description}
  \item[Vagueness] We have no problem dealing with vague statements like ``Most people never heard of it''; in a specific conversation situation we rely on extra-linguistic cues like pragmatics and common world knowledge to decide if ``most'' means 7.5 billion people, or 70\% of our friends, or if the approximate number is even relevant (maybe it was ironically spoken, etc.)
  \item[Ambiguity] The fact that a linguistic sign can't be interpreted in only one way, is an ubiquitous phenomenon in human language that is present on all levels: phonological, lexical, syntactic, semantic, pragmatic. A classic example for syntactic ambiguity would be the phrase ``He saw the elephant with a telescope''.
  \item[Corruption] Contrary to how we perceive language when speaking to each other, utterances are mostly not well-formed, grammatical sentences, but show a varying degree of stutter, incomplete phrases, repetitions, and other ``mistakes''. While not as present in written language, depending on the domain, there still is quite some noise present, e.g. in online chat threads etc. Still, we mostly have no problems at all, reconstructing the encoded information from such a corrupted signal.
  \item[Common world knowledge] Normally the information we encode in ordinary conversation is highly condensed and as scarce as possible --- most of the actual information is reconstructed by the receiver, making use of general knowledge about the world (factual knowledge, such as ``Bern is the capital of Switzerland'', logical consequence such as ``If $X$ was at the party yesterday evening, then $X$ was not in his apartment yesterday evening'', etc.) and the actual situation, time, and place the conversation takes place.
\end{description}

% ``The engineering side of computational linguistics, often called natural language processing
% (NLP), is largely concerned with building computational tools that do useful things with
% language'' \cite{johnson2009statistical}

So, every system that is built aiming at processing natural language in a ``deep'', human-like
manner must cope with this inherent fuzzinesses of human communication. In the field of
applied computational linguistics, often referred to as Natural Language Processing (NLP),
this subfield of research is known as Natural Language Understanding (NLU).\myfootnote{Note
that I will not engage in the discussion about whether it is philosophically appropriate
to claim that computational models ``understand'' human language. A lot of controversy has
arisen around this issue, with positions ranging from completely denying language models any
sort of (linguistic) understanding \citep{bender2021dangers} to the current trend of simply
concentrating on beating NLU SOTAs with ever larger models and blindly taking this as proof
of building architectures capable of learning human language. I would argue that the thruth
lies somewhere in between: Of course it is not enough to perform well on a standardized data
set to speak of ``understanding'', however, as \cite{sahlgren2021singleton} point out: Also
in humans, especially children, we measure language competences indirectly ``by using various
language proficiency tests, such as vocabulary tests, cloze tests, reading comprehension, as
well as various forms of production, interaction, and mediation tests \textelp{}''.}

% ``It is always precarious to build arguments on inherently vague and general
% concepts such as `language', `understanding' and `meaning,' as the resulting
% theoretical constructs may become so overly general that they almost become
% vacuous.'' \cite{sahlgren2021singleton}

% \begin{quote}
%   learning a language entails learning the set of symbols and rules that define the
%   system. Learning the set of symbols equals vocabulary acquisition, while learning
%   the rules entails recognizing and formalizing grammatical, morphological, and
%   syntactic regularities.i We measure these competencies in humans — often indirectly
%   — by using various language proficiency tests, such as vocabulary tests, cloze
%   tests, reading comprehension, as well as various forms of production, interaction,
%   and mediation tests \textelp{}. \cite{sahlgren2021singleton}
% \end{quote}

\begin{quote}
  there is an overwhelming body of empirical results to demonstrate that current language models
  have a passable capacity to detect the symbols and rules that define human language. This is not
  what is under dispute in the current debate; what is under dispute is whether such structural
  knowledge about the workings of the language system suffices.
\end{quote}

\subsection{History, Methods, Problems of NLU}


% ``The `understanding' these models have of language is entirely structural,
% and thus does not extend beyond the language system'' \cite{sahlgren2021singleton}

% ``We can of course always question whether there is any `real' under-
% standing going on, but if the absence or presence of this `real' understanding
% has no effect on the behavior of the system, it will be a mere epiphenomenon
% that need not concern us.'' \cite{sahlgren2021singleton}

% ``consciousness is not an extra ingredient in addition to the complexity of a system:
% consciousness is the complexity of the system. Our point is that understanding is also
% not an extra ingredient of a symbol manipulation system: `understanding' is a term we
% use to describe the complexity of such a system.'' \cite{sahlgren2021singleton}

% ``Our point is that when the behavior of an NLU system becomes sufficiently complex, it will be
% easier to explain its behavior using intentional terms such as `understanding,' than to use a
% purely functional explanation.'' \cite{sahlgren2021singleton}

% The subsection of NLP that deals with the semantics, i.e. meanings, of utterances, is NLU.
During the first phase of NLP, approximately from the 1950ies until the 1980ies, systems
that addressed NLU problems were architectures that consisted of carefully hand-written
symbolic grammars and knowledge bases that aimed at tackling a specific problem, such as
recognizing textual entailment, coreference resolution, sentiment analysis, and so on.

From the 90ies on, the so-called emph{statistical revolution} took place, and NLU related
problems were now being addressed by learning patterns from huge data collections. One driver
of this paradigm shift were the various difficulties the traditional systems bore: Their
development ``requiring a great deal of domain-specific knowledge engineering. In addition,
the systems were brittle and could not function adequately outside the restricted tasks for
which they were designed'' \citep[p.~13]{brill1997overview}. The new, statistical {\color{red}
approach} tries to tackle NLU-problems by shifting the focus from tedious hand-crafting ``to
empirical, or corpus-based, methods in which development is much more data driven and is at
least partially automated by using statistical or machine-learning methods to train systems
on large amounts of real language data'' \citep[p.~13]{brill1997overview}. The main challenge
for engineers and scientists now laid in discovering suitable features, according to which the
algorithm would hopefully learn helpful patterns from the language data for solving the task
at hand. With this orientation towards data-driven NLP solutions came also the possibility to
compare different architectures on the same standardized data set and measure which performed
better --- as laid out before, this has led to the problematic temptation to focus on beating
SOTAs without a great deal of theoretical linguistic considerations behind.

For almost a decade now a next stage in NLU and NLP in general was entered: we are now in the
middle of the \emph{neural age} of computational linguistics. In contrast to the statistical
period's main challenge --- the identification and extraction of suitable features ---, now the
algorithms are itself learning the features that are the most informative for a given task. The
human part in the process is reduced to design the overall model architecture and compile large
large enough amounts of data that are, in the best case, also of good quality.


\subsection{Contextualized Word Embeddings in NLU}

Since the beginning of the neural age, there was the problem as to how could text be numerically
represented, so that the algorithms could extract meaningful feature patterns and
that there is as little information loss as possible (since a numeric representation is always
an abstraction of the real data, there naturally is some unpreventable information loss).
The solution that was proposed by \cite{mikolov2013distributed} is the approach that is still
in use today in its core idea:

\begin{itemize}
  \item Initialize a random vector for each word in the vocabulary.
  \item Train a neural model to learn the best numerical representation of each word
    by giving it a simple task on huge amounts of unlabeled data (like CBOW, next word
    prediction, etc.).
  \item Save those numeric representations and use them in target task at hand.
\end{itemize}

While the basic approaches of this approach still hold --- train randomly initialized vectors on
large amounts of unlabeled data with a neural network with a simple training goal ---, some important
changes or additions to today's implementation have been made:

\begin{itemize}
  \item The original word2vec embeddings were \emph{fixed}, in the sense that a word had always
    the same representation, regardless of the context
  \item The neural networks that computed these vectors were quite small (two layers of dimensionality
    300) and could be run on a standard machine.
    Today's models are huge (hundreds of millions of parameters are not unusual) and computationally
    very intensive and cannot be run locally.
  \item Due to the last point, practice has shifted towards pretraining these computationally heavy
    embeddings and finetuning them on the specific task along with it's goal
\end{itemize}

The architecture that has caused the most uproar was probably BERT \cite{devlin2018bert}, an
architecture that led to so many variants of it, that it created a whole new field inside the
NLP community --- the BERTology \cite{rogers2020primer}. BERT is a good example for a typical
neural age NLP model: It's architecture is completely agnostic of knowledge about language
whatsoever, it ``only'' operates on sequental concatenations of symbols; there is also no
preprocessing of the data --- no POS-tagging, no dependency parsing, no NER.\myfootnote{Because
of this non linguistic specific architecture, BERT can easily be adapted to operate on other
sequential data. This has actually be done: \cite{ji2020dnabert} for example trained a DNABERT
model for successfully deciphering non-coding DNA.}
Albeit this complete lack of any sort of explicit linguistic knowledge, by only extracting
statistical patterns it learns from processing huge amounts of text, BERT achieved several
SOTAs on well-established NLU data sets, such as GLUE \cite{wang2018glue}.

However, as I will describe in more detail in the next chapter, BERT exposes also
some weaknesses and undesirable flaws: While being able to perform surprisingly well
on some tasks, there are situations where BERT fails in rather trivial situations.

As I laid out before, in the past decades computational linguistics has undergone several
``revolutions'' which, although some people might see this differently, can be described as
moving from a strong emphasis on linguistics to a more data-driven computational discipline.

Furthermore, the introduction of deep learning into computational linguistics has introduced a
so called \emph{black box}; which means essentially that although the underlying formulas and the
architecture of neural nets are well-known --- the mathematics behind them is rather simple ---,
it is nevertheless impossible to determine \emph{what exactly} those models learn from the data.


\section{Research Questions}

The research questions that shall be answered in this thesis, are:
\begin{enumerate}
 \item What do I do? Try to boost BERT embeddings on NLU tasks
 \item How do I do it?  Combine BERT embeddings with encoded SRL information
 \item And why? BERT lacks any linguistic knwoledge and shows error behaviour which suggests adding some could help
 \item more concrete questions:
 \begin{itemize}
    \item Can I reproduce \cite{zhang2019semantics} for German?
    \item Am I able to reach reported SOTAs of the data sets?
    \item Is there a difference for different head architectures? And if yes, why?
 \end{itemize}
\end{enumerate}

Questions and Claims that are \textbf{not} being made:

\begin{itemize}
  \item No claim of ``real'' understanding
  \item carefully interpreting purely empirical results $\rightarrow$ data quality critique
\end{itemize}



\section{Thesis Structure}

In this first chapter I gave a very brief overview of general trends in
NLP over the past decades and highlighted some

Chapter \ref{chap:2_approach} introduces the basic concept of BERT,
its {\color{red} shortcomings} and presented solution or improvements. Further,
I explain my approach and the relating linguistic concepts.

The datasets I compiled to test my models on are described in detail
in chapter \ref{chap:3_datasets}.

In Chapter \ref{chap:4_architecture}, I describe the details of the architecture of
my BERT-variant in all detail: The identification and encoding of the semantic role
labels, the different combination procedures of the BERT embeddings with these, as
well as the different head architectures.

The overview and discussion of the performance of the various model architectures on
the GerGLUE data set is made in chapter \ref{chap:5_results}.

Finally, I draw some insights and conclusions in the last chapter \ref{chap:6_conclusion}.

