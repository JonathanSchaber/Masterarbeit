\newchap{Approach}
\label{chap:2_approach}

% \epigraph{\textgreek{πάντες ἄνθρωποι τοῦ εἰδέναι}}{\textit{Heraclitus of Ephesus}}


In this chapter, I will give a brief overview of several things: In a first step, I will elaborate
on the topic of pretrained embeddings, transfer learning, and BERT, which is probably the most
successful architecture implementing these concepts. Secondly, I will briefly demonstrate problems
that have been identified relating to the performance of BERT and its relation to semantics. Then,
I will point out some submitted solutions countering those problems. Lastly, I will describe my
approach and how it makes use of semantic roles.



\section{Pretrained Embeddings and Transfer Learning}
\label{sec:pretrained-embeddings}

In recent years, it has proven to be very effective to use word embeddings pre-computed by sentence
or document encoders as input representations for task-specific architectures, which may fine-tune
those embeddings while learning the task at hand. Pretrained word embeddings have the advantage
that they do not need to be learned from scratch by the system solving the task at hand.


\cite{bengio2003neural} first implemented distributed word representations by using a
neural \textit{n}-gram language model which could be re-used in downstream tasks. In
``Natural language processing (almost) from scratch'', \cite{collobert2011natural} showed
the utility of such embeddings for representing text as input for other neural networks
which addressed a multitude of classical NLP tasks. \cite{mikolov2013distributed} proved
that such embeddings could be computed using a modest one-layer neural network targeted at
self-supervised training objectives, namely CBOW and skip-gram. Context-sensitvity, i.e.
taking into account the surrounding words in the embeddings, was introduced by the ELMo
architecture \cite{peng2019transfer}. Since then, representing words using pretrained,
contextualized embeddings has become the standard in most NLP architectures.


% `` The general approach to
% building Deep Learning systems is compelling and powerful: The researcher defines a
% model architecture and a top-level loss function and then both the parameters and the
% representations of the model self-organize so as to minimize this loss, in an end-to-end
% learning framework.'' \citep[p.~703]{manning2015computational}

The architecture computing contextualized word embeddings that has caused the most uproar
recently was probably BERT \cite{devlin2018bert}, a model that led to so many variants of
it, that it created a whole new field inside the NLP community --- winkingly baptized as
``BERTology'' \cite{rogers2020primer}. BERT is a good example for a typical neural age
NLP system: Its architecture is completely agnostic of symbolic or structural, inguistic
knowledge about language whatsoever, it ``merely'' operates on sequential concatenations
of symbols. Therefore, it also does not employ preprocessing of the data of any kind ---
no POS-tagging, no dependency parsing, no NER.\myfootnote{Because of this non-linguistic
specific architecture, BERT can easily be adapted to operate on other sequential data.
This has actually been done: \cite{ji2020dnabert} for example trained a DNABERT model
for successfully deciphering non-coding DNA.} Despite this complete lack of any sort
of explicit linguistic knowledge, by essentially extracting statistical patterns which
it learns from processing huge amounts of text, the resulting BERT embeddings achieved
several SOTAs on well-established NLU datasets, such as GLUE \cite{wang2018glue}.

% Since the publication of the seminal paper ``BERT: Pre-training of deep bidirectional
% transformers for language understanding'' \cite{devlin2018bert} and the accompanying
% open-sourcing of its architecture\myfootnote{\url{https://github.com/google-research/bert}},
% BERT has probably been the most studied and cited NLP model producing word embeddings since
% word2vec \cite{mikolov2013distributed} --- amassing over 17,000 citations on Google Scholar
% as of April 2021.
% This massive interest from the NLP community in BERT suggests that it
% somehow must be accomplishing something which is of greater significance to the field than
% regular benchmark SOTA cracking by ``normal'' new or improved architectures.

The basic concept of BERT is described by \citeauthor{devlin2018bert} as
being a two-stepped framework: (1) Pretrain the model on unlabeled data over
different pretraining tasks\myfootnote{\citeauthor{devlin2018bert} use the
BooksCorpus, consisting of 800 million words, plus the English Wikipedia,
consisting of 2.5 billion words. BERT optimizes its parameters on two training
objectives: (1) Presented with a sentence containing one random word masked,
the model has to predict it, and (2) BERT has to decide if, given two randomly
sampled sentences, the second is a valid continuation of the first. Crucially,
both tasks can be generated automatically, no tedious human annotation of data
is needed.} and (2) for downstream tasks, use the embeddings by initializing
the model with the pretrained parameters and fine-tune all of the parameters
by using labeled data from the task at hand.

One of the distinctive features of BERT is the minimal difference in architecture between
pretraining and finetuning: The transformer based network which computes the contextualized
token embeddings during the language modeling pretraining is also used in downstream tasks,
only with a task-specific head on top of it. This makes re-implementing the BERT
model in other architectures quite convenient, which is one of the reasons I decided to
implement BERT in my approach as well.

Further, the numerical embeddings BERT ``learned'' to compute during the pre-training phase show to
be very apt at transferring to a wide range of down-stream tasks: As \citeauthor{devlin2018bert}
demonstrate, with marginal architecture adaption, i.e. the ``head'', to the task at hand,
vanilla BERT embeddings achieved several SOTA results on tasks ranging from natural language inference (NLI)
to question answering.

Another advantage of BERT is that the cost, hardware, and data intensive pre-training of the
embeddings must only be computed once; the downstream task-dependent fine-tunig can then
be carried out in a lean set up.\myfootnote{To give an impression on the expenses of pre-training
the BERT architecture: \cite{schwartz2019green} estimate the pre-training for BERT-large to have lasted four days
on 64 TPU chips, resulting in power expenditures of about \$7,000. However, this has to be considered
rather cheap compared to recent architectures' sizes: The largest architecture to date is the
T-NLG (Turing Natural Language Generation) built by Microsoft, possessing a staggering 17 billion
parameters --- that is approximately 48 times the size of BERT-large (350 million parameters), cf.
\cite{sharir2020cost}. Open AI's GPT-3's \citep{brown2020language} pretraining is estimated to have costed
\$12 million \citep{floridi2020gpt}. This trend of increasingly bigger language models has earned severe critique from
several sides, ranging from ecological and social to linguistic concerns over such models; for
a good overview of these points see \cite{bender2021dangers}.}

\fig{images/BERT_clipped.png}{fig:bert-architecture}{3D-visualization of the BERT architecture.
The 12 attention heads and following linear projections in one block (here called ``Layer'')
are vividly represented. The information flow is top-down, with the tokenized input sentence
starting with the [CLS] token on top, and the computed embeddings on bottom. Credit for the image
goes to \href{https://peltarion.com/blog/data-science/illustration-3d-bert}{Peltarion}.}{11}{BERT
Architecture}

From a more technical point of view, BERT is first and foremost a multi-layered bidirectional
transformer encoder. At its heart lies an implementation of the self-attention mechanism, the
transformer, introduced by \cite{vaswani2017attention}; the main difference, and apparent
advantage, to other architectures that implement the transformer architecture, e.g. Open AI's GPT
\citep{radford2018improving}, is that BERT is a bi-directional architecture. In simple terms,
BERT takes an input sequence, tokenizes it and computes contextualized vector representations
for each token via stacked blocks, depicted in figure \ref{fig:bert-architecture}, employing
self-attention and linear combination. For reasons of space, I will not go into more detail
here about BERT's architecture; the interested reader is referred to the original BERT paper by
\cite{devlin2018bert}, as well as \cite{clark2019does}, which provides insight into the inner
workings of BERT's attention mechanisms.

% \myfootnote{For a really % well made visualization of
% self-attention in BERT, I can  recommend \url{https://www.youtube.com/watch?v=-9vVhYEXeyQ}}.


% \citeauthor{devlin2018bert} impressively demonstrated the capabilities of BERT by obtaining
% new SOTA results  on eleven NLU tasks, increasing the GLUE score by 7.7\% absolute improvement.



\subsection{Problems, Weak Spots, Semanticity}
\label{sec:problems}

In recent years, a lot of research went into analyzing and improving the BERT architecture, as well
as trying to find explanations for the striking transfer learning capabilities of its  embeddings.

While BERT showed to be highly effective on several established datasets and
benchmarks such as GLUE \citep{wang2018glue}, it soon became obvious that it
also had its weak-spots: \citeauthor{ettinger2020bert} confronted BERT with
three language tasks originating in psycholinguistics which are well-known
to be difficult to tackle. After carrying out several experiments and error
analyses, he concludes that BERT ``struggles with challenging inferences and
role-based event prediction --- and it shows clear failures with the meaning
of negation'' \citep[p.~46]{ettinger2020bert}.

Apparently, while being able to solve NLU tasks to an impressive extent, BERT seems to be prone
to fail in situations where proper semantic understanding of text sequences is crucial, such as
detecting role reversal or sentence completion tasks.

\cite{jiang2019evaluating} also state ``that despite the high $F1$ scores, BERT models have
systematic error patterns'', which for them suggests ``that they still do not capture the
full complexity of human pragmatic reasoning.''

\cite{jin2020bert} go even further and create what are called adversarial attacks for laying open
weak spots of BERT: After observing that BERT seems to rely only on the statistical cues of
a small number of the input tokens to form its predictions, \citeauthor{jin2020bert} built a
sophisticated algorithm to permute the input sentences without actually changing its meaning.
Taken from the SNLI \citep{bowman2015snli} dataset, here is an example for such an attack:

\begin{examples}
  \item \textbf{Premise}: A child with wet hair is holding a butterfly decorated beach ball.

        \textbf{Original Hypothesis}: The \emph{child} is at the \emph{beach}.\\
        \textbf{Adversarial Hypothesis}: The \emph{youngster} is at the \emph{shore}.
\end{examples}

The italicized words are the ones that were affected by the adversarial algorithm.
Obviously --- for a human --- the meaning of the adversarial hypothesis has not
changed from the original one. One could argue that there is a slight difference
in style (the adversarial sounds somewhat overblown to me) but it would still count
as an entailment of the premise. However, as the authors report, BERT is affected
by such attacks and changes its predictions.

For SNLI, \citeauthor{jin2020bert} report to bring down BERT's original accuracy of 89,4\%
to an astonishing 4,0\% by permuting 18,5\% of the input tokens. Given that the permutations
are essentially nothing more than exchanging a word with a synonym or a semantically related
substitute, this outcome does not speak for BERT's quality.



% ``BERT shows a complete inability to prefer true over false completions for negative sentences.''
% \citep[p.~45]{ettinger2020bert}

\subsection{Solutions / Related Work}

But the NLP community was not only passive and/or destructive concerning BERT, it also produced a
vast number of adaptations, variations, and improvements to the vanilla BERT. The motivations
behind all those BERTlings are as manifold as one can think: some are adaptions to languages other
than English, some are general variations (in hope of improvement) of the BERT architecture, still
others attempt to explicitly address the problems outlined above.

The following overview sheds some light on the iridescent potpourri of the BERT
family.\myfootnote{This compilation is partly drawn from the towards-data-science article
\href{https://towardsdatascience.com/a-review-of-bert-based-models-4ffdc0f15d58}{``A
review of BERT based models''} by Ajit Rajasekharan.}
Note, however, that this is by no means an exhaustive presentation of all BERT-variants produced so far.


\begin{description}
  \item[\textbf{Adapting to other languages}] One of the most straightforward modifications to the BERT model is to pre-train it on different langauges. Examples for this are the French CamemBERT \cite{martin2019camembert}, the Italian AlBERTo \cite{polignano2019alberto}, or the Dutch BERTje \cite{de2019bertje}.\myfootnote{\cite{devlin2018bert} also trained a multi-lingual BERT (mBERT), which was trained on 104 languages. However, language-specific BERTs have been shown to be more performant than employing the mBERT.}
  \item[\textbf{Adapting to specialized domains}] BERT was pre-trained on two corpora: (1) The BooksCorpus \citep{zhu2015aligning}, consisting of 800 million words and comprising 16 different genres; and (2) the English Wikipedia, lists and tables excluded (2.5 billion words).
  Examples of BERTs pre-trained on specialized domains are for example BioBERT \cite{lee2020biobert}, which  is an adaption to biomedical language, and LEGAL-BERT \cite{chalkidis2020legalbert} which is a whole family of BERT models pre-trained on legal texts.
  \item[\textbf{Including different modalities}] Another, highly interesting amplification of the BERT architecture is the inclusion of additional modalities, for example (moving) images: VideoBERT \cite{sun2019videobert} learns embeddings for image-enriched texts and can be used for image captioning or image classification tasks.
  Several researchers claim that the future of NLP relies on combining text with sensory, e.g. visual, data for creating more stable and reliable models (cf. \citep{bisk2020experience, bender2021dangers}).
  \item[\textbf{Optimizing architecture/training objective(s)}] Several BERT-variations modify the actual architecture of BERT:  DistilBERT \cite{sanh2019distilbert} is a variant 60\% of the size of the original BERT while retaining 97\% of its original performance.
  RoBERTa \cite{liu2019roberta} essentially modifies core hyperparameteres such as batch-size, byte-level BPE, and the like, creating a more stable BERT.
  DeBERTa \cite{he2020deberta} modifies the attention mechanism and the position encoding, while TransBERT \cite{li2021transbert} introduces a new pre-training framework.
  \item[\textbf{Incorporating structured information}] One of the strengths of BERT is the self-supervised pre-training on unstructered, raw text. However, research has shown that including structured linguistic information can stabilize BERT and even counterbalance some of the known weaknesses (see above) to some extent:
  ERNIE \cite{sun2019ernie} includes a knowledge graph into BERT, making structural fact representations available to BERT.
  %StructBERT \cite{wang2019structbert},
  VGCN-BERT \cite{lu2020vgcn} combines a Vocabulary Graph Convolutional Network with the standard BERT, and \cite{zhang2019semantics} include semantic role labels in their SemBERT during fine-tuning.
\end{description}


\section{GliBERT}

Infected by the pandemic BERT-fever and persuaded by its proven transfer-learning capabilities,
I decide to also use BERT as pretrained, contextualized word representations in my architecture.
Specifically, I concentrate on German and choose the German BERT, pretrained and provided by
deepset\myfootnote{\url{https://deepset.ai/german-bert}}. Concentrating on the weak spots
identified relating to the semantic understanding of language, my approach will combine the
German BERT embeddings with structured linguistic information to counter those shortcomings.

There exist several linguistic structures which could
be hypothetically included into BERT. For example
\href{https://uni-tuebingen.de/en/faculties/faculty-of-humanities/departments/modern-languages/department-of-linguistics/chairs/general-and-computational-linguistics/ressources/lexica/germanet/}{GermaNet},
\citep{hamp1997germanet} is a large lexical-semantic net
that relates noun, verbs, and adjectives semantically
by grouping lexical units that express the same concept
into synsets and by defining semantic relations between
these synsets. As such, GermaNet can be characterized as
a thesaurus or a light-weight ontology. One difficulty
relating to such structures is that the encoding of such
hierarchical information and the subsequent combining
with contiguous data --- the sequence of BERT-embedded
tokens in a text --- is not straightforward and requires
an elaborate pipeline of different subsystems.

Another, more plain, possibility would be to implement some linguistic-semantic ``mark-up'' of
the tokens in a text: E.g. Dependency-parse the text and concatenate the BERT-embedded head tokens
with a numerically encoded representation of the directed binary grammatical relation
that it governs (``direct object'', ``determiner'', etc.).

% E.g.identify named entities, include the encoded structured information
% related to them, using the DBpedia \citep{auer2007dbpedia}, and enrich the BERT embeddings
% with them.

Despite these options, I choose to employ semantic roles for several reasons. Primarily,
because \citeauthor{zhang2019semantics} demonstrated successfully the feasibility of
this undertaking for English. Moreover, the addition of semantic roles to BERT strikes a
good balance between two extremes: (1) Including sophisticated knowledge structures, or
semantic information, which would require extensive preprocessing (stemming, identifying
content words, potential word sense disambiguation, look-up in the knowledge base) and
rather cumbersome encoding; and (2) straightforward, on the fly ``mark-up'' of input text,
with low information substance in the case of named entities. With semantic roles, I get
the best of both worlds: Structured information which is relatively easy to implement, as
discussed below, while --- hopefully --- truly adding semantic substance to the vanilla
BERT embeddings. In addition to outlining their goals, history and applications, the next
section describes in detail what Semantic Roles are and how I use them to augment BERT.

Since it is common practice to give your enhanced/variegated BERT architecture an appropriate
name, I decided to not deviate from this tradition and call my breed \textbf{G}erman
\textbf{l}inguistic \textbf{i}nformed BERT, or short: \textbf{GliBERT}.

All code relating to the following dataset set-ups, GliBERT architecture, and training
can be found in my \href{https://github.com/JonathanSchaber/Masterarbeit}{GitHub
repository}\myfootnote{\url{https://github.com/JonathanSchaber/Masterarbeit}}.


\section{Semantic Roles}
\label{sec:semantic-roles}

% Traditionally in linguistics, language is analyzed into different structural levels, where
% different tools for describing these levels, or strata, are used.
% In most theories, there are are four of these structural levels proposed:
% Beginning from the Bottom, there is the level of Phonetics and Phonology, followed by Morphology,
% then there is the level of Syntax, and the last one is Semantics.\myfootnote{Sometimes Pragmatics
% is conceptualized as an additional fifth layer on top, sometimes it is considered to form a field
% of its own; I follow the latter.}
% While the first three levels deal with the form of utterances of human language, semantics is
% concerned with the meaning of such utterances \citep[p.~4ff.]{kracht2007introduction}.

% \tab{tab:levels-of-lang}{Levels of language analysis and description.}
% {\begin{tabular}{|l|l|l|l|}
% \hline
% \multicolumn{2}{|c|}{Form}     & \multicolumn{2}{c|}{Meaning}     \\ \hline
%   % a & b & c & d \\ \hline
%   & \multicolumn{2}{c|}{Level} &                   \\ \hhline{====}
%         Syntax  & \multicolumn{2}{l|}{Sentence} & \multirow{3}{*}{Semantics} \\ \cline{1-3}
%         Morphology & \multicolumn{2}{l|}{Word} &                   \\ \cline{1-3}
%         Phonology & \multicolumn{2}{l|}{Sound} &                   \\ \hline
% \end{tabular}
% }{Levels of language}

One difficulty every system targeted at NLU must tackle, is the ability to cope with the
vast amount of flexibility and freedom in natural language to express or describe
one and the same state of affairs. There may be subtle differences in emphasis,
markedness, or style, but the following sentences all roughly describe the same
states of affairs:\myfootnote{Of course, from an aesthetic, literary point of view,
the choice of the right words is crucial and should by no means be played down ---
``The difference between the almost right word and the right word is really a large
matter. 'tis the difference between the lightning bug and the lightning'', as Mark
Twain famously put it.}

\begin{examples}
  \item The ship leaked critically due to the big waves and went down.
  \item \label{ex:sinking-sent} Severely damaged by the hurricane, the vessel sank to the ground.
  \item The crew --- unable to save the stricken freighter --- had to be evacuated by air.
\end{examples}

Although these three sentences make use of very different vocabulary --- an unweighted
BLEU score\myfootnote{BLEU is a metric which captures \textit{n}-gram overlap between
two ore more sentences, see chapter \ref{chap:3_datasets}, section \ref{sec:paws-x} for
more details.} is virtually zero between them --- it is obvious to a speaker of English
that they all convey more or less the same meaning, that all of them refer to the same
state of affairs: A ship sank because of the forces of nature. In linguistics, this is
often referred to as proposition: The ``lexical kernel of a sentence that determines
its truth conditions, regardless of the syntactic form and lexical filling of the given
form of expression'' \cite[p.~959]{bussmann2006routledge}. In other words, the three
sentences above describe the same states of affairs, which means that they are verified
or falsified by the same conditions in the real world --- i.e. \emph{if} what they are
denoting \emph{is} really the case.

Maybe the most obvious way of encoding the same proposition with different words is synonymy:
``Ship'', ``vessel'', and ``freighter'' all refer to the same object in the examples above. Having
several options when choosing a word to denote something is a paramount feature of human language.
As discussed in \ref{sec:problems}, merely exchanging a small subset of the words in a sentence
with their synonyms potentially has a severe impact on models which are aimed at NLU tasks on such
sentences. In other words, vanilla BERT often fails to recognize that two slightly different word
sequences have the same meaning.

Further, the description of one and the same event, e.g. the aforementioned proposition of a
sinking ship, can be linguistically encoded in various ways: In the second sentence, the process
is denominated explicitly using the verb ``to sink''; in the first, the semantically more obscure
semi-fixed expression ``to go down'' is used to inform about that very situation; while in the
third, the sinking of the ship is not mentioned explicitly but inferable from the circumstance of
``not being able to save'' it.

For a human speaker, all this disentangling, recognizing coreference, reconstructing not
explicitly mentioned information, etc. happens automatically and without effort --- for an
algorithm, however, phenomena like the ones mentioned pose serious challenges. In other
words, despite the differences that may be encountered on several linguistic levels, such
as the vocabulary, word ordering, emphasis, etc., there is a remarkable capability in human
language processing which reliably extracts the propositional content out of any linguistic
statement.

Therefore, equipping an NLU algorithm with tools that enable semantic interpretation capabilities
is a core issue that needs to be addressed: ``For computers to make effective use of information
encoded in text, it is essential that they be able to detect the events that are being described
and the event participants.'' \citep{palmer2010semantic}

As I laid out in section \ref{sec:problems}, in modern, purely data-driven models like BERT,
all linguistic, semantic, and factual knowledge the model acquires is infered, or learned by
it implicitly from raw text data. Nevertheless, and this is why the NLU field is so intrigued
by it, BERT seems to perform surprisingly well in tasks where such ``understanding'' of events
is being tested.\myfootnote{Of course, one does not assess epistemic understanding in the true
sense based on such tests, but attributes it behaviorist grounded on observable, and therefore
measurable performance on standardized trials --- as is done in human educational contexts, as
well (cf. \cite{sahlgren2021singleton}).} Simultaneously, some investigated failures of BERT
seem to indicate that this ``understanding'' does not go too deep and that, among other things,
the recognition of proposition equivalency between sentences is partially poor.

Semantic Roles are an attempt at creating an instrument with which it is possible to analyze the
meaning of sentences in a structured manner and being able to express in generalizable terms
their semantic properties, e.g. that two sentences express the same proposition. The central idea
here is that every utterance has an underlying semantic structure\myfootnote{Often, especially
in Generative Grammar traditions, this level is also known as deep structure, or D-structure.}
(sloppily phrased: ``Who did What to Whom, and How, When and Where?''), which can be realized in
different surface structures. There have been various undertakings in creating a vocabulary for
describing such structures, putting the focus on different aspects and showing varying degrees of
analytic detail.

The work ``The Case for Case'' \citep{fillmore1967case} is often seen as the starting point for
the theory of semantic roles in modern linguistics. In it, \citeauthor{fillmore1967case} argued
that what he called ``Deep-Cases'' play a crucial role in the Deep-Structure of sentences; the
hitherto prevalent view in Generative Grammar was that case was a purely Surface-Structure related
phenomenon and only one of several possibilities to realize syntactic relationships. Interestingly,
these ``Deep-Cases'' were semantically-motivated: in combination with so called verb-frames, these
cases would capture the semantic core of the proposition embedded in the Deep-Structure. A verb
like \emph{open} would e.g. form a frame denoting an ``opening event'' involving an actor, the
``Opener'', and an object, ``the thing opened'' (cf. \cite[p.~46f.]{fillmore1967case}). Seven
of such Deep-Cases were proposed by him, for example the ``Agentive'': `` [T]he case of the
typically animate perceived instigator of the action identified by the verb''; or the so-called
``Factitive'': `` [T]he case of the object or being resulting from the action or state identified
by the verb, or understood as a part of the meaning of the verb'' \citep[p.~46]{fillmore1967case}.
The Deep-Structure of a sentence would then be realized via certain transformational rules as
actual, linguistic utterance. For instance, the question ``Did he really go to school in XYZ?'' and
``He went to school in XYZ'' are realizations of the same underlying Deep-Structure. Once these
transformational rules and Deep-Structures are understood and described in sufficient manner, one
can turn the analysis around: by relating the observable surface structures of an utterance to
the underlying Deep-Structures via the mapping rules, we have an instrument for retrieving the
underlying semantic structure or proposition.

Building on these core concepts introduced by Fillmore, other linguists added features to
the project of formalizing the core semantic structures of propositions, as summarized by
\citeauthor{palmer2010semantic}: In the beginnings of the 1970s, \cite{jackendoff1972semantic}
expanded and refined Fillmore's model by introducing the concept of primitive conceptual
predicates and their property of governing arguments, which were conceptualized as bearing
some proto-semantics, similar to the Fillmorian Deep-Cases. This approach, known as ``Lexical
Conceptual Structure'' (LCS), proved to be an elegant theory and capable of generalizing
well between different verbs. In the 1990s LCS was implemented as system for representing
semantics in early NLU and translation models \citep{palmer2010semantic}. But, due to its
detailed analysis of verbs into (several) primitive predicates and their highly verb-specific
conceptualized semantic roles, LCS turned out to be cumbersome to extend to the whole range of
a vocabulary of a language.

In contrast, \cite{dowty1991thematic} approached the problem of constructing a framework for
analyzing core conceptual semantic structures from a different angle: Instead of providing
a detailed description of the primitive predicate and idiomatic argument structure for each
individual verb, he attempted to identify general functions of noun phrases in what he called
``thematic proto-roles''. To accomplish this, \citeauthor{dowty1991thematic} drew from the
theory of ``family resemblance'' and defined a set of attributes which would indicate such
a thematic role. ``The hypothesis put forth here about thematic roles is suggested by the
reflection that we may have had a hard time pinning down the traditional role types because
role types are simply not discrete categories at all, but rather are cluster concepts
\textelp{}'' \citep[p.~571]{dowty1991thematic}.

For example, \citep[p.~572]{dowty1991thematic} defines the property bundle of semantic Proto-Agents
as follows:

\begin{enumerate}[label=\alph*]
  \item volitional involvement in the event or state
  \item sentence (and/or perception)
  \item causing an event or change of state in another participant
  \item movement (relative to the position of another participant)
  \item (exists independently of the event named by the verb)
\end{enumerate}

Similar clusters of characteristics can also be defined for other proto-roles, like
patients or themes, etc.

However, like most theories in linguistics, Semantic Roles
remain a disputed topic in the field until today: ``There may be general agreement on
the cases (or Thematic Roles or Semantic Roles) \textelp{}, but there is substantial
disagreement on exactly when and where they can be assigned and which \textelp{}
should be added, if any'' \citep{palmer2010semantic}. However, the general, agreed
upon objective of semantic roles and similar concepts may be paraphrased as follows:

\begin{examples}
  \item \textbf{Semantic Roles are systematic abstractions of semantic functions that are attributed
  to the participants in a proposition expressed in human language.}
\end{examples}

The volitional acting entity in a situation is abstracted, e.g. as ``(Proto-)Agent''; regardless of
the actual, concrete event denoted by the verb. Similarly, noun phrases which denote participants
that undergo some state of change are captured as ``proto-patients''.

% \begin{examples}
%   \item He fears bears.
%   \item His fear of bears.
%   \item He is afraid of bears.
% \end{examples}

For some time now, there are lexical resources implementing one approach of structural
semantic annotation. For example, the PropBank \citep{palmer2005proposition}, which adds
``a layer of predicate-argument information, or semantic role labels, to the syntactic
structures of the Penn Treebank''; or FrameNet \citep{baker1998berkeley}, which aimed at
producing ``frame-semantic descriptions of several thousand English lexical items and
backing up these descriptions with semantically annotated attestations from contemporary
English corpora''.

% \begin{itemize}
%   \item ``conceptual relations that the referents of the noun phrases play with respect to the verb'' \citep{palmer2010semantic}
%   \item different syntactic constituents can bear same SR
%   \item Linking theory: Map from syntactic surface structure to underlying predicate argument semantics
% \end{itemize}

I focus here on the PropBank approach since the semantic role labeler I use in my
architecture was trained on the German part of CoNLL `09 \citep{hajivc2009conll}, which
consisted in semantic role labeling according to the PropBank scheme. In PropBank each
verb, or rather each verb sense, is attributed with a so-called frame. This frame
consists of a definition of the event denoted by that particalur verb sense and the
semantic arguments associated with. For example, the first frame of the verb \emph{to
sink}\myfootnote{\url{http://verbs.colorado.edu/propbank/framesets-english-aliases/sink.html}}
is analysed as follows:

\noindent\fbox{%
    \parbox{\textwidth}{%
      \emph{sink.01} (cause to) go down, esp into water, downward motion\\

      Roles:
      \begin{description}
        \item[Arg0-PAG] causer of sinking (vnrole: 45.4-agent)
        \item[Arg1-PPT] thing sinking (vnrole: 45.4-patient)
        \item[Arg2-EXT] EXT
        \item[Arg3-DIR] start point
        \item[Arg4-GOL] end point, destination
        \item[Arg5-MNR] instrument (vnrole: 45.4-instrument)
      \end{description}
    }%
}

Applied to the sentence  \ref{ex:sinking-sent}, this would lead to the following PropBank annotation:

\begin{examples}
  \item Severely damaged [\textsubscript{Arg0-PAG} by the hurricane], [\textsubscript{Arg1-PPT} the vessel] [\textsubscript{Rel} sank] [\textsubscript{Arg4-GOL} to the ground].
\end{examples}


Although the PropBank annotations are verb-specific, there are some generalizations in the first
number of arguments as to what proto-role they denote, as the authors of PropBank write: ``For
a particular verb, Arg0 is generally the argument exhibiting features of a Prototypical Agent
\textelp{}, while Arg1 is a Prototypical Patient or Theme'' \citep[p.~75]{palmer2005proposition}.
In their English PropBank Annotation Guideluines, \cite{bonial2012english} nevertheless propose
generalizations even for the higher arguments:

\begin{description}
  \item[\customcolorbox{\textbf{Arg0}}{blue}] agent
  \item[\customcolorbox{\textbf{Arg1}}{green}] patient
  \item[\customcolorbox{\textbf{Arg2}}{yellow}] instrument, benefactive, attribute
  \item[\customcolorbox{\textbf{Arg3}}{red}] starting point, benefactive, attribute
  \item[\customcolorbox{\textbf{Arg4}}{manatee}] ending point
  \item[\customcolorbox{\textbf{ArgM}}{sage}] modifier
  \item[\customcolorbox{\textbf{Rel}}{llight-blue}] Relation (can be a verb, noun, or adjective)
\end{description}

That is to say, even if the higher numbered argument's proto-role is semantically somewhat
fuzzier than for argument zero and one, there are potentially generalizable patterns from
which a model --- trained on such annotated sentences --- might still be able to detect
task-supportive structures in the data.

% ``An individual verb’s semantic arguments are numbered, beginning with zero.
% For a particular verb, Arg0 is generally the argument exhibiting features of a Pro-
% totypical Agent (Dowty 1991), while Arg1 is a Prototypical Patient or Theme. No
% consistent generalizations can be made across verbs for the higher-numbered
% arguments, though an effort has been made to consistently define roles across mem-
% bers of VerbNet classes. In addition to verb-specific numbered roles, PropBank defines
% several more general roles that can apply to any verb.'' \citep[p.~75]{palmer2005proposition}

% ``Because verbs generally provide the bulk of the event semantics of any given sentence,
% verbs have been the target of most of the existing two million words of PropBank annotation.
% Nonetheless, to fully capture event relations, annotations must recognize the potential for
% their expression in the form of nouns, adjectives and multi-word expressions, such as Light
% Verb Constructions (LVCs)'' \citep[p.~3014]{bonial2014propbank}. Since my approach relies on
% dependency parsing for identifying predicates, I only focus on verb predicates since these
% are reliably extractable from the dependency parse tree (see section \ref{sec:srl-module}),
% contrary to the mentioned non-verbal predicates.

% Although, as is exemplified by the third sentence, in the following list, that the
% predication information might also be carried by a noun phrase or complex predicate
% (e.g. light verb + adjective):

In the following, some example sentences from the PropBank
frames are presented\myfootnote{accessible through this
\href{https://github.com/propbank/propbank-frames.git}{GitHub
repository}}. Semantic roles are highlighted using the colors
from the previous list. Note that only one relation is
marked in the sentences, even if there are multiple. Since
DAMESRL, the module I use for SRL tagging, only treats verbs
as semantic roles distributing relations, I include only
verbal ``Rel''s in the examples:\myfootnote{To me, not all
annotations in PropBank are beyond all doubt; for example,
in sentence \ref{itm:wrongsrl} ``an investment banker'' is
labelled as agent ``maximzing'' the the patient ``shareholder
value'' --- however, I would argue that it's rather the
``alternative'' that take proto-agentive role in maximizing
the shareholder values.}

\begin{examples}
  \item \customcolorbox{[\textsubscript{Arg0} Yasser Arafat]}{blue} has \customcolorbox{[\textsubscript{Rel} written]}{llight-blue} \customcolorbox{[\textsubscript{Arg2} to the chairman of the International Olympic Committee]}{yellow}, asking him to back a Palestinian bid to join the committee.
  \item Once \customcolorbox{[\textsubscript{Arg0} he]}{blue} \customcolorbox{[\textsubscript{Rel} realized]}{llight-blue} \customcolorbox{[\textsubscript{Arg1} that Paribas's intentions weren't friendly]}{green}, he said, but before the bid was launched, he sought approval to boost his Paribas stake above 10\%.
  \item \customcolorbox{[\textsubscript{Arg1} National Market System volume]}{green} \customcolorbox{[\textsubscript{Rel} improved]}{llight-blue} \customcolorbox{[\textsubscript{Arg4} to 94,425,00 shares]}{manatee} \customcolorbox{[\textsubscript{Arg3} from 71.7 million Monday]}{red}.
  \item \customcolorbox{[\textsubscript{Arg0} The new round of bidding]}{blue} would seem to \customcolorbox{[\textsubscript{Rel} complicate]}{llight-blue} \customcolorbox{[\textsubscript{Arg1} the decision making]}{green} \customcolorbox{[\textsubscript{Arg2} for Judge James Yacos]}{yellow}.
  \item \label{itm:wrongsrl} The action followed by one day an Intelogic announcement that it will retain \customcolorbox{[\textsubscript{Arg0} an investment banker]}{blue} to explore alternatives ``to \customcolorbox{[\textsubscript{Rel} maximize]}{llight-blue} \customcolorbox{[\textsubscript{Arg1} shareholder value]}{green},'' including the possible sale of the company.
  \item \customcolorbox{[\textsubscript{Arg0} He]}{blue} \customcolorbox{[\textsubscript{ArgM-mod} would]}{sage} scream and \customcolorbox{[\textsubscript{Rel} cut]}{llight-blue} \customcolorbox{[\textsubscript{Arg1} himself]}{green} \customcolorbox{[\textsubscript{Arg3} with rocks]}{red}.
\end{examples}


% {\color{red} ``The main reason computational systems use semantic roles is to act as a shallow meaning
% representation that can let us make simple inferences that aren’t possible from the pure surface
% string of words, or even from the parse tree.'' \cite[p.~375]{jurafsky2019speech}

% In the literature, often \cite{gildea2002automatic} is considered to have formally defined the
% task of automatic SRL.

% ``Analysis of semantic relations and predicate-argument structure is one of the core pieces of any
% system for natural language understanding.'' \citep{palmer2010semantic}}

Thanks to lexical resources such as the PropBank, a multitude of models
aiming at labeling sentences with semantic roles are now available. For
German, there is e.g. DAMESRL \citep{do2018flexible}, trained on the CoNLL
'09 \citep{hajivc2009conll} data (which implements PropBank style SRLs).
This is also the semantic role labeler I employ in my GliBERT system.
Since I treat the semantic role labeler essentially as a blackbox in my
architecture and use it as an off-the-shelf SRL predictor, I will not go
into details about the concrete implementation of DAMESRL, as well as the
different approaches to automatic semantic role labeling in general ---
the interested reader is referred to \cite{do2018flexible} for the former
and e.g. \cite{palmer2010semantic} for the latter.

The following list contains some examples of DAMESRL-labelled sentences stemming from the
GliBERT corpus (see chapter \ref{chap:3_datasets}). The sentences are represented vertically
with the leftmost column being the actual sentence; each column represents one identified verb
(B-V) and its predicted semantic roles, labelled using the BIO-schema\myfootnote{Introduced by
\citep{ramshaw1999text}, the BIO-schema is an established way of adding a label to each token
in a sequence, indicating if it belongs to a certain subgroup, or chunk, of the sequence. For
example, to mark the prepositional phrase in a syntagma like ``He is running from the bear'',
one would mark the word beginning the PP with \textbf{B}, any other words inside the PP with
\textbf{I}, and all other words outside of it, using \textbf{O}: ``He[O] is[O] running[O]
from[B-PP] the[I-PP] bear[I-PP]''.} All the columns to the right of the verticalized sentence
represent one argument-predicate structure for this sentence. Note that the labels are slightly
differently labelled than in the PropBank, as listed before: \texttt{V} (``Verb'') stands for
\texttt{Rel} (``relation''), \texttt{A}\textit{n} stands for \texttt{Arg}\textit{n} (both are
abbreviations for ``argument'').

\textbf{deISEAR}

\begin{Verbatim}[commandchars=\\\{\}]
  Ich        \colorbox{white}{B-A0}         \colorbox{white}{O}
  fühlte     \colorbox{white}{B-V}          \colorbox{white}{O}
  [MASK]     \colorbox{white}{B-A1}         \colorbox{white}{O}
  ,          \colorbox{white}{I-A1}         \colorbox{white}{O}
  als        \colorbox{white}{I-A1}         \colorbox{white}{O}
  ich        \colorbox{white}{I-A1}         \colorbox{white}{B-A0}
  aus        \colorbox{white}{I-A1}         \colorbox{white}{O}
  Versehen   \colorbox{white}{I-A1}         \colorbox{white}{O}
  schlechte  \colorbox{white}{I-A1}         \colorbox{white}{B-A1}
  Milch      \colorbox{white}{I-A1}         \colorbox{white}{I-A1}
  getrunken  \colorbox{white}{I-A1}         \colorbox{white}{B-V}
  habe       \colorbox{white}{I-A1}         \colorbox{white}{O}
\end{Verbatim}

\textbf{MLQA}

\begin{verbatim}
  Welche       B-A1       B-A2
  Positionen   I-A1       I-A2
  muss         O          O
  man          B-A0       B-A0
  erreichen    B-V        O
  ,            O          O
  um           O          O
  die          O          B-A1
  von          O          I-A1
  Kaius        O          I-A1
  angeordnete  O          I-A1
  Position     O          I-A1
  eines        O          I-A1
  Läufers      O          O
  einzunehmen  O          B-V
  ?            O          O
\end{verbatim}

\textbf{XNLI}

\begin{verbatim}
  Es           O          O               O
  war          O          O               O
  das          O          O               O
  Wichtigste   O          O               O
  was          B-A1       O               O
  wir          B-A0       O               O
  sichern      B-V        O               O
  wollten      O          O               O
  da           O          O               O
  es           O          O               O
  keine        O          B-A1            O
  Möglichkeit  O          I-A1            O
  gab          O          B-V             O
  eine         O          B-A1            B-A3
  20           O          I-A1            I-A3
  Megatonnen   O          I-A1            I-A3
  -            O          I-A1            I-A3
  H            O          I-A1            I-A3
  -            O          I-A1            I-A3
  Bombe        O          I-A1            I-A3
  ab           O          I-A1            O
  zu           O          I-A1            B-A5
  werfen       O          I-A1            B-V
  von          O          I-A1            I-A5
  einem        O          I-A1            I-A5
  30           O          I-A3            I-A5
  ,            O          O               O
  C124         O          O               O
  .            O          O               O
\end{verbatim}

A detailed discussion of the SRLs produced by DAMESRL will be done in chapter
\ref{chap:5_results}, section \ref{sec:srl-noise}. In advance, it should be
noted that the automatically predicted SRLs seem to capture semantic properties
quite well (e.g. the second SRL-layer of the first sentence, where the predicate
``getrunken'', the agent ``ich'' and the theme ``schlechte Milch'' are correctly
identifed). However, there are some irritating results as well (e.g. the third
layer in the last example, where there is an uninterpretable Arg5 ``zu von einem
30'', interrupted by the predicate ``werfen'').

In the next chapter \ref{chap:3_datasets}, I will present the GerGLUE NLU corpus, and
the subsequent chapter \ref{chap:4_architecture}, the GliBERT architecture and actual
implementation of SRLs into the BERT architecture are described.


