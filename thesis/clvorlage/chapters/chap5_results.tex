\newchap{Results}
\label{chap:5_results}

In this chapter, I will report the results of my experiments on the six data sets. Additionally, I
conducted an ablation study on the XNLI data set, that is described in section \ref{sec:ablation}

% \subsection{deISEAR}

% \subsubsection{Example 1}

% \fig{images/SRLs_deISEAR_1.png}{fig:SRL-PAWS-X-1}{}{10}{}

% \subsubsection{Example 2}

% \fig{images/SRLs_deISEAR_2.png}{fig:SRL-PAWS-X-1}{}{15}{}

% \subsection{PAWS-X}

% \begin{landscape}

% \subsubsection{Example 1}

% \textbf{Sentence 1}

% Im Gegenzug [\textsubscript{predicate} gab] Grimoald [\textsubscript{A1} seine Tochter zur
% Hochzeit] und gewährte ihm das Herzogtum Spoleto nach dem Tod von Atto.

% Im Gegenzug gab Grimoald [\textsubscript{A0} seine Tochter] zur Hochzeit und
% [\textsubscript{predicate} gewährte] [\textsubscript{A2} ihm] [\textsubscript{A1} das Herzogtum
% Spoleto nach dem Tod von Atto] .

% \textbf{Sentence 2}

% %[\textsubscript{O} Im Gegenzug] [\textsubscript{predicate} gab] [\textsubscript{O} Grimoald]
% [\textsubscript{A1} seine Tochter] [\textsubscript{A3} in die Ehe] [\textsubscript{O} und
% gewährte ihm das Herzogtum Spoleto nach dem Tod von Atto] [\textsubscript{O} .]  Im Gegenzug
% [\textsubscript{predicate} gab] Grimoald [\textsubscript{A1} seine Tochter] [\textsubscript{A3}
% in die Ehe] und gewährte ihm das Herzogtum Spoleto nach dem Tod von Atto.

% %[\textsubscript{O} Im Gegenzug gab Grimoald] [\textsubscript{A0} seine Tochter]
% [\textsubscript{O} in die Ehe und] [\textsubscript{predicate} gewährte] [\textsubscript{A2}
% ihm] [\textsubscript{A1} das Herzogtum Spoleto nach dem Tod von Atto] [\textsubscript{O} .]  Im
% Gegenzug gab Grimoald [\textsubscript{A0} seine Tochter] in die Ehe und [\textsubscript{predicate}
% gewährte] [\textsubscript{A2} ihm] [\textsubscript{A1} das Herzogtum Spoleto nach dem Tod
% von Atto] .


% \fig{images/SRLs_PAWS-X_1.png}{fig:SRL-PAWS-X-1}{}{15}{}

% \subsubsection{Example 2}

% \textbf{Sentence 1}

% Camm [\textsubscript{predicate} entschied] , [\textsubscript{A1} dass beide Motoren eingesetzt
% werden sollten: Der Tempest Mk 5 hatte den Napier Saber eingebaut, während der Tempest Mk 2
% der Bristol Centaurus war] .

% Camm entschied, dass [\textsubscript{A1} beide Motoren] [\textsubscript{predicate} eingesetzt]
% werden sollten: [\textsubscript{A1} Der Tempest Mk 5 hatte den Napier Saber eingebaut, während]
% der Tempest Mk 2 der Bristol Centaurus war.

% Camm entschied, dass beide Motoren eingesetzt werden sollten: [\textsubscript{A0} Der Tempest
% Mk 5] hatte [\textsubscript{A3} den Napier Saber] [\textsubscript{predicate} eingebaut],
% während der Tempest Mk 2 der Bristol Centaurus war.

% Camm entschied, dass beide Motoren eingesetzt werden sollten: Der Tempest Mk 5 hatte den
% Napier Saber eingebaut, während [\textsubscript{A1} der Tempest Mk 2 der Bristol Centaurus]
% [\textsubscript{predicate} war] .

% \textbf{Sentence 2}

% Camm [\textsubscript{predicate} entschied] , [\textsubscript{A1} dass beide Motoren eingesetz
% werden sollten: Der Tempest Mk 5 war mit dem Napier Saber ausgestattet, während der Tempest
% Mk 2 den Bristol Centaurus hatte] .

% Camm entschied, dass [\textsubscript{A1} beide Motoren] [\textsubscript{predicate} eingesetzt]
% werden sollten: [\textsubscript{A1} Der Tempest Mk 5 war mit dem Napier Saber ausgestattet,
% während der Tempest Mk 2 den Bristol Centaurus hatte] .

% Camm entschied, dass beide Motoren eingesetzt werden sollten: [\textsubscript{A0} Der Tempest
% Mk 5] war [\textsubscript{A1} mit dem Napier Saber] [\textsubscript{predicate} ausgestattet]
% , während der Tempest Mk 2 den Bristol Centaurus hatte.

% Camm entschied, dass beide Motoren eingesetzt werden sollten: Der Tempest Mk 5 war mit dem
% Napier Saber ausgestattet, während [\textsubscript{A1} der Tempest Mk 2 den Bristol Centaurus]
% [\textsubscript{predicate} hatte] .

% \fig{images/SRLs_PAWS-X_2.png}{fig:SRL-PAWS-X-1}{}{15}{}

% \end{landscape}

% \subsubsection{Example 3}

% \fig{images/SRLs_PAWS-X_3.png}{fig:SRL-PAWS-X-1}{}{10}{}

% xwubsubsection{Example 4}

% \fig{images/SRLs_PAWS-X_4.png}{fig:SRL-PAWS-X-1}{}{15}{}

% \subsubsection{Example 5}

% \fig{images/SRLs_PAWS-X_5.png}{fig:SRL-PAWS-X-1}{}{10}{}

% \subsubsection{Example 6}

% \fig{images/SRLs_PAWS-X_6.png}{fig:SRL-PAWS-X-1}{}{10}{}

% \subsubsection{Example 7}

% \fig{images/SRLs_PAWS-X_7.png}{fig:SRL-PAWS-X-1}{}{10}{}

% \subsubsection{Example 8}

% \fig{images/SRLs_PAWS-X_8.png}{fig:SRL-PAWS-X-1}{}{10}{}

\section{Data Set Results}

\begin{itemize}
  \item conjecture: SRLs are rather adding noise in sequences that are too long. Extreme exmples are the Q\&A datasets.
  \item GRU architecture is probably strongest: most best models (even though mostly -SRL) and second best models, no worst performance
  \item 6 sgnificantly better +SRL vs. 3 significantly worse +SRL. There seems to be a slight trend that when merging subtokens, duplicating SRLs when too less predicates is better.
  \item all 3 worsening are for subtokenized architectures.
\end{itemize}

To obtain as stable results as possible, I decided to train five models for each architecture
and configuration, all initialized with different random seeds. Additionally, I ensembled the
five models, achieving a performance gain of several percentage points (see example of PAWS-X,
table \ref{tab:pawsx}). In table \ref{tab:results} below, the test set ensemble results for
each architecture on the non-question answering data set are reported. The results for the
architecture for the question answering tasks are reported in table \ref{tab:results-qa}.

In a first step, I will discuss on the overall performance of models when the SRLs are added, compared to the same architectures without.


\begin{landscape}\centering
  \vspace*{\fill}
  \tab{tab:results}{Accuracy ensemble results (per 5 models) on single sentence and sentence pair tasks.
                    \textbf{Bold} font marks the best result per line, \underline{underline} the second best, and \textit{italics} the poorest.
                    In the \emph{Scores} row, the afore mentioned extremes are accumulated for $-$SRL and $+$SRL;
                    note that if both +SRL configurations of an architecture achieved an extreme, it is only counted once.}{
    \scalebox{0.90}{
      \begin{tabular}{llccc|ccc|ccc|ccc|ccc|ccc}
                                                   &           & \multicolumn{6}{c|}{\textbf{{[}CLS{]} Head}}                                                                                                                                                                                                                      & \multicolumn{6}{c|}{\textbf{LHSA Head}}                                                                                                                                                                                                & \multicolumn{6}{c}{\textbf{GRU Head}}                                                                                                                                                                                                                           \\ \cline{3-20}
                                                   &           & \multicolumn{3}{c|}{subtokenized}                                                                                               & \multicolumn{3}{c|}{subtokens merged}                                                                                           & \multicolumn{3}{c|}{subtokenized}                                                                                   & \multicolumn{3}{c|}{subtokens merged}                                                                            & \multicolumn{3}{c|}{subtokenized}                                                                                             & \multicolumn{3}{c}{subtokens merged}                                                                                            \\ \cline{3-20}
                                                   &           & \multicolumn{1}{c|}{$-$SRL}                  & \multicolumn{2}{c|}{+SRL}                                                        & \multicolumn{1}{c|}{$-$SRL}                & \multicolumn{2}{c|}{+SRL}                                                          & \multicolumn{1}{c|}{$-$SRL}                    & \multicolumn{2}{c|}{+SRL}                                          & \multicolumn{1}{c|}{$-$SRL}                    & \multicolumn{2}{c|}{+SRL}                                       & \multicolumn{1}{c|}{$-$SRL}                  & \multicolumn{2}{c|}{+SRL}                                                      & \multicolumn{1}{c|}{$-$SRL}                     & \multicolumn{2}{c}{+SRL}                                                      \\ % \cline{3-4}\cline{6-7}\cline{9-10}\cline{12-13}\cline{15-16}\cline{18-19}
                                                   &           & \multicolumn{1}{c|}{}                        & \multicolumn{1}{c}{zeros}              & \multicolumn{1}{c|}{dupl.}              & \multicolumn{1}{c|}{}                      & \multicolumn{1}{c}{zeros}                 & \multicolumn{1}{c|}{dupl.}             & \multicolumn{1}{c|}{}                          & \multicolumn{1}{c}{zeros}             & \multicolumn{1}{c|}{dupl.} & \multicolumn{1}{c|}{}                          & \multicolumn{1}{c}{zeros}          & dupl.                      & \multicolumn{1}{c|}{}                        & \multicolumn{1}{c}{zeros}             & dupl.                                  & \multicolumn{1}{c|}{}                           & \multicolumn{1}{c}{zeros}             & dupl.                                 \\ \hline\hline
      \multicolumn{1}{c}{\multirow{2}{*}{deISEAR}} & $\alpha$  & \multicolumn{1}{c|}{71.52}                   & \multicolumn{1}{c}{72.19}              & \multicolumn{1}{c|}{71.52}              & \multicolumn{1}{c|}{72.19}                 & \multicolumn{1}{c}{\textit{67.55}}        & \multicolumn{1}{c|}{72.19}             & \multicolumn{1}{c|}{70.86}                     & \multicolumn{1}{c}{\textbf{77.48}}    & \multicolumn{1}{c|}{72.85} & \multicolumn{1}{c|}{74.17}                     & \multicolumn{1}{c}{72.85}          & \multicolumn{1}{c|}{74.17} & \multicolumn{1}{c|}{70.20}                   & \multicolumn{1}{c}{\underline{74.83}} & \multicolumn{1}{c|}{74.17}             & \multicolumn{1}{c|}{73.51}                      & \multicolumn{1}{c}{70.20}             & \multicolumn{1}{c}{71.52}             \\
      \multicolumn{1}{c}{}                         & $\beta$   & \multicolumn{1}{c|}{71.52}                   & \multicolumn{1}{c}{\underline{74.83}}  & \multicolumn{1}{c|}{\underline{74.83}}  & \multicolumn{1}{c|}{70.86}                 & \multicolumn{1}{c}{70.86}                 & \multicolumn{1}{c|}{72.85}             & \multicolumn{1}{c|}{\underline{74.83}}         & \multicolumn{1}{c}{\textit{68.21}}    & \multicolumn{1}{c|}{70.20} & \multicolumn{1}{c|}{\underline{74.83}}         & \multicolumn{1}{c}{73.51}          & \multicolumn{1}{c|}{70.86} & \multicolumn{1}{c|}{73.51}                   & \multicolumn{1}{c}{\underline{74.83}} & \multicolumn{1}{c|}{72.19}             & \multicolumn{1}{c|}{\textbf{76.82}}             & \multicolumn{1}{c}{70.20}             & \multicolumn{1}{c}{\underline{74.83}} \\ \cline{3-20}
      \multicolumn{1}{c}{\multirow{2}{*}{SCARE}}   & $\alpha$  & \multicolumn{1}{c|}{\underline{85.61}}       & \multicolumn{1}{c}{82.58}              & \multicolumn{1}{c|}{83.71}              & \multicolumn{1}{c|}{83.33}                 & \multicolumn{1}{c}{83.71}                 & \multicolumn{1}{c|}{\underline{85.61}} & \multicolumn{1}{c|}{83.33}                     & \multicolumn{1}{c}{83.71}             & \multicolumn{1}{c|}{84.09} & \multicolumn{1}{c|}{84.09}                     & \multicolumn{1}{c}{\textit{81.44}} & \multicolumn{1}{c|}{84.47} & \multicolumn{1}{c|}{83.71}                   & \multicolumn{1}{c}{83.33}             & \multicolumn{1}{c|}{84.09}             & \multicolumn{1}{c|}{\textbf{85.98}}             & \multicolumn{1}{c}{84.09}             & \multicolumn{1}{c}{83.71}             \\
      \multicolumn{1}{c}{}                         & $\beta$   & \multicolumn{1}{c|}{\underline{86.36}}       & \multicolumn{1}{c}{84.85}              & \multicolumn{1}{c|}{84.47}              & \multicolumn{1}{c|}{85.23}                 & \multicolumn{1}{c}{85.23}                 & \multicolumn{1}{c|}{85.23}             & \multicolumn{1}{c|}{\textbf{86.74}}            & \multicolumn{1}{c}{85.98}             & \multicolumn{1}{c|}{85.23} & \multicolumn{1}{c|}{84.47}                     & \multicolumn{1}{c}{\textit{83.33}} & \multicolumn{1}{c|}{84.09} & \multicolumn{1}{c|}{\textbf{86.74}}          & \multicolumn{1}{c}{85.98}             & \multicolumn{1}{c|}{83.71}             & \multicolumn{1}{c|}{\underline{86.36}}          & \multicolumn{1}{c}{84.09}             & \multicolumn{1}{c}{85.23}             \\ \cline{3-20}
      \multicolumn{1}{c}{\multirow{2}{*}{PAWS-X}}  & $\alpha$  & \multicolumn{1}{c|}{80.63}                   & \multicolumn{1}{c}{81.60}              & \multicolumn{1}{c|}{81.49}              & \multicolumn{1}{c|}{\textit{79.92}}        & \multicolumn{1}{c}{80.63}                 & \multicolumn{1}{c|}{82.51}             & \multicolumn{1}{c|}{81.19}                     & \multicolumn{1}{c}{80.78}             & \multicolumn{1}{c|}{80.07} & \multicolumn{1}{c|}{80.43}                     & \multicolumn{1}{c}{80.02}          & \multicolumn{1}{c|}{80.68} & \multicolumn{1}{c|}{82.26}                   & \multicolumn{1}{c}{82.77}             & \multicolumn{1}{c|}{82.77}             & \multicolumn{1}{c|}{82.82}                      & \multicolumn{1}{c}{\underline{82.87}} & \multicolumn{1}{c}{\textbf{83.53}}    \\
      \multicolumn{1}{c}{}                         & $\beta$   & \multicolumn{1}{c|}{87.49}                   & \multicolumn{1}{c}{\underline{88.05}}  & \multicolumn{1}{c|}{\textbf{88.21}}     & \multicolumn{1}{c|}{87.75}                 & \multicolumn{1}{c}{87.24}                 & \multicolumn{1}{c|}{88.00}             & \multicolumn{1}{c|}{86.83}                     & \multicolumn{1}{c}{87.39}             & \multicolumn{1}{c|}{87.09} & \multicolumn{1}{c|}{87.75}                     & \multicolumn{1}{c}{\textit{86.58}} & \multicolumn{1}{c|}{86.68} & \multicolumn{1}{c|}{87.60}                   & \multicolumn{1}{c}{87.60}             & \multicolumn{1}{c|}{87.90}             & \multicolumn{1}{c|}{88.00}                      & \multicolumn{1}{c}{88.00}             & \multicolumn{1}{c}{\underline{88.05}} \\ \cline{3-20}
      \multicolumn{1}{c}{\multirow{2}{*}{XNLI}}    & $\alpha$  & \multicolumn{1}{c|}{67.34}                   & \multicolumn{1}{c}{\textbf{67.52}}     & \multicolumn{1}{c|}{66.64}              & \multicolumn{1}{c|}{66.94}                 & \multicolumn{1}{c}{66.94}                 & \multicolumn{1}{c|}{\textit{66.26}}    & \multicolumn{1}{c|}{67.20}                     & \multicolumn{1}{c}{\underline{67.42}} & \multicolumn{1}{c|}{67.34} & \multicolumn{1}{c|}{66.38}                     & \multicolumn{1}{c}{67.08}          & \multicolumn{1}{c|}{66.92} & \multicolumn{1}{c|}{66.68}                   & \multicolumn{1}{c}{66.60}             & \multicolumn{1}{c|}{67.14}             & \multicolumn{1}{c|}{66.42}                      & \multicolumn{1}{c}{66.54}             & \multicolumn{1}{c}{66.26}             \\
      \multicolumn{1}{c}{}                         & $\beta$   & \multicolumn{1}{c|}{68.09}                   & \multicolumn{1}{c}{68.18}              & \multicolumn{1}{c|}{66.84}              & \multicolumn{1}{c|}{67.82}                 & \multicolumn{1}{c}{67.82}                 & \multicolumn{1}{c|}{\underline{68.36}} & \multicolumn{1}{c|}{66.31}                     & \multicolumn{1}{c}{65.60}             & \multicolumn{1}{c|}{66.40} & \multicolumn{1}{c|}{\textit{64.98}}            & \multicolumn{1}{c}{65.51}          & \multicolumn{1}{c|}{65.07} & \multicolumn{1}{c|}{66.84}                   & \multicolumn{1}{c}{67.82}             & \multicolumn{1}{c|}{67.02}             & \multicolumn{1}{c|}{67.64}                      & \multicolumn{1}{c}{66.31}             & \multicolumn{1}{c}{\textbf{68.53}}    \\ \hline\hline
      \multicolumn{1}{c}{Scores}                   &           & \multicolumn{1}{c|}{\underline{II}}          & \multicolumn{2}{c|}{\textbf{II} \underline{II}}                                  & \multicolumn{1}{c|}{}                      & \multicolumn{2}{c|}{\underline{II}}                                                & \multicolumn{1}{c|}{\textbf{I} \underline{I}}  & \multicolumn{2}{c|}{\textbf{I} \underline{I}}                      & \multicolumn{1}{c|}{\underline{I}}             & \multicolumn{2}{c|}{}                                           & \multicolumn{1}{c|}{\textbf{I}}              & \multicolumn{2}{c|}{\underline{II}}                                            & \multicolumn{1}{c|}{\textbf{II} \underline{I}}  & \multicolumn{2}{c}{\textbf{II} \underline{III}}                               \\ \cline{1-2}
      \multicolumn{1}{c}{+SRL}                     & \multicolumn{3}{l}{\textbf{4} \underline{10}} \\
      \multicolumn{1}{c}{$-$SRL}                   & \multicolumn{3}{l}{\textbf{4} \underline{5}}

      \end{tabular}
      % \begin{tablenotes}
      %     \item[1] Mirror movements in the affected hand, while the unaffected hand is moving at normal speed.
      %     \item[2] Mirror movements in the affected hand, while the unaffected hand is moving at fast speed.
      %     \item[3] Mirror movements in the unaffected hand as the affected hand is moving at normal speed.
      %     \item[4] Mirror movements in the unaffected hand as the affected hand is moving at fast speed. For TD children, the non-dominant hand corresponds to the affected hand.
      % \end{tablenotes}
    }
  }{Results}

  \tab{tab:configs}{The different hyperparameter configurations for each data set.}{
    \scalebox{0.9}{
      \begin{tabular}{lcc|cc|cc|cc||cc|cc}
                                 & \multicolumn{2}{c|}{deISEAR}                                                    & \multicolumn{2}{c|}{SCARE}                                                & \multicolumn{2}{c|}{PAWS-X}                                                                                                  & \multicolumn{2}{c|}{XNLI}                                                                          & \multicolumn{2}{c|}{MLQA}                                                                            & \multicolumn{2}{c}{XQuAD}                                                                        \\
                                 & \multicolumn{1}{c}{$\alpha$}           & \multicolumn{1}{c|}{$\beta$}           & \multicolumn{1}{c}{$\alpha$}             & \multicolumn{1}{c|}{$\beta$}   & \multicolumn{1}{c}{$\alpha$}                                           & \multicolumn{1}{c|}{$\beta$}                        & \multicolumn{1}{c}{$\alpha$}                  & \multicolumn{1}{c|}{$\beta$}                       & \multicolumn{1}{c}{$\alpha$}                    & \multicolumn{1}{c|}{$\beta$}                       & \multicolumn{1}{c}{$\alpha$}                   & \multicolumn{1}{c}{$\beta$}                     \\ \cline{2-13}
      epochs                     & 100                                    & 100                                    & 50                                       & 50                             & 20                                                                     & 20                                                  & 50                                            & 50                                                 & 50                                              & 50                                                 & 100                                            & 100                                             \\
      training set               & -                                      & -                                      & -                                        & -                              & \colorbox{blue}{\makecell{Train set scaled down \\ to ratio 70:15:15}} & \colorbox{blue}{Original Train set}                 & \colorbox{blue}{Original sets}                & \colorbox{blue}{Re-sampled and split 70:30:30}     & \colorbox{blue}{Normal splits}                  & \colorbox{blue}{Re-sampled and split 70:30:30}     &                                                &                                                 \\
      batch size                 & 16                                     & 16                                     & 16                                       & 16                             & 16                                                                     & 16                                                  & 16                                            & 16                                                 & 8                                               & 8                                                  & 8                                              & 8                                               \\
      maximum length             & \colorbox{blue}{40}                    & \colorbox{blue}{200}                   & \colorbox{blue}{50}                      & \colorbox{blue}{100}           & 100                                                                    & 100                                                 & 100                                           & 100                                                & 512                                             & 512                                                & 512                                            & 512                                             \\
      \end{tabular}
    }
  }{Data Set specific Configs}

  \tab{tab:hyper-configs}{General hyperparameter configurations.}{
    \scalebox{0.9}{
      \begin{tabular}{ll}
      learning rate              & 2e-05                         \\
      SRL embedding dimensions   & 20                            \\
      SRL GRU hidden size        & 32                            \\
      SRL number of layers       & 2                             \\
      SRL bias                   & True                          \\
      SRL bidirectional          & True                          \\
      SRL dropout                & 0.1                           \\
      \end{tabular}
    }
  }{Stable Hyperparameter Configs}

  \tab{tab:pawsx}{Ensemble vs. averages of PAWS-X $\beta$.}{
    \scalebox{0.9}{
      \begin{tabular}{lccc|ccc|ccc|ccc|ccc|ccc}
               & \multicolumn{6}{c|}{\textbf{{[}CLS{]} Head}}                                                                                                                                                                                                                      & \multicolumn{6}{c|}{\textbf{LHSA Head}}                                                                                                                                                                                                         & \multicolumn{6}{c}{\textbf{GRU Head}}                                                                                                                                                                                                                           \\ \cline{2-19}
               & \multicolumn{3}{c|}{subtokenized}                                                                                               & \multicolumn{3}{c|}{subtokens merged}                                                                                           & \multicolumn{3}{c|}{subtokenized}                                                                                            & \multicolumn{3}{c|}{subtokens merged}                                                                            & \multicolumn{3}{c|}{subtokenized}                                                                                             & \multicolumn{3}{c}{subtokens merged}                                                                                            \\ \cline{2-19}
               & \multicolumn{1}{c|}{$-$SRL}                  & \multicolumn{2}{c|}{+SRL}                                                        & \multicolumn{1}{c|}{$-$SRL}                & \multicolumn{2}{c|}{+SRL}                                                          & \multicolumn{1}{c|}{$-$SRL}                    & \multicolumn{2}{c|}{+SRL}                                                   & \multicolumn{1}{c|}{$-$SRL}                    & \multicolumn{2}{c|}{+SRL}                                       & \multicolumn{1}{c|}{$-$SRL}                  & \multicolumn{2}{c|}{+SRL}                                                      & \multicolumn{1}{c|}{$-$SRL}                     & \multicolumn{2}{c}{+SRL}                                                      \\
               & \multicolumn{1}{c|}{}                        & \multicolumn{1}{c}{zeros}              & \multicolumn{1}{c|}{dupl.}              & \multicolumn{1}{c|}{}                      & \multicolumn{1}{c}{zeros}                 & \multicolumn{1}{c|}{dupl.}             & \multicolumn{1}{c|}{}                          & \multicolumn{1}{c}{zeros}             & \multicolumn{1}{c|}{dupl.}          & \multicolumn{1}{c|}{}                          & \multicolumn{1}{c}{zeros}          & dupl.                      & \multicolumn{1}{c|}{}                        & \multicolumn{1}{c}{zeros}             & dupl.                                  & \multicolumn{1}{c|}{}                           & \multicolumn{1}{c}{zeros}             & dupl.                                 \\ \hline\hline
      Average  & \multicolumn{1}{c|}{86.31}                   & \multicolumn{1}{c}{86.49}              & \multicolumn{1}{c|}{86.63}              & \multicolumn{1}{c|}{86.56}                 & \multicolumn{1}{c}{85.48}                 & \multicolumn{1}{c|}{\underline{86.81}} & \multicolumn{1}{c|}{86.18}                     & \multicolumn{1}{c}{86.03}             & \multicolumn{1}{c|}{\textit{85.78}} & \multicolumn{1}{c|}{86.08}                     & \multicolumn{1}{c}{85.35}          & \multicolumn{1}{c|}{85.94} & \multicolumn{1}{c|}{86.35}                   & \multicolumn{1}{c}{86.40}             & \multicolumn{1}{c|}{86.71}             & \multicolumn{1}{c|}{86.70}                      & \multicolumn{1}{c}{86.70}             & \multicolumn{1}{c}{\textbf{86.87}}    \\
      Ensemble & \multicolumn{1}{c|}{87.49}                   & \multicolumn{1}{c}{\underline{88.05}}  & \multicolumn{1}{c|}{\textbf{88.21}}     & \multicolumn{1}{c|}{87.75}                 & \multicolumn{1}{c}{87.24}                 & \multicolumn{1}{c|}{88.00}             & \multicolumn{1}{c|}{86.83}                     & \multicolumn{1}{c}{87.39}             & \multicolumn{1}{c|}{87.09}          & \multicolumn{1}{c|}{87.75}                     & \multicolumn{1}{c}{\textit{86.58}} & \multicolumn{1}{c|}{86.68} & \multicolumn{1}{c|}{87.60}                   & \multicolumn{1}{c}{87.60}             & \multicolumn{1}{c|}{87.90}             & \multicolumn{1}{c|}{88.00}                      & \multicolumn{1}{c}{88.00}             & \multicolumn{1}{c}{\underline{88.05}} \\ \cline{2-19}
      Gain     & \multicolumn{1}{c|}{1.18}                    & \multicolumn{1}{c}{1.56}               & \multicolumn{1}{c|}{1.58}               & \multicolumn{1}{c|}{1.19}                  & \multicolumn{1}{c}{1.76}                  & \multicolumn{1}{c|}{1.19}              & \multicolumn{1}{c|}{.65}                       & \multicolumn{1}{c}{1.36}              & \multicolumn{1}{c|}{1.31}           & \multicolumn{1}{c|}{1.67}                      & \multicolumn{1}{c}{1.23}           & \multicolumn{1}{c|}{.74}   & \multicolumn{1}{c|}{1.25}                    & \multicolumn{1}{c}{1.20}              & \multicolumn{1}{c|}{1.19}              & \multicolumn{1}{c|}{1.30}                       & \multicolumn{1}{c}{1.30}              & \multicolumn{1}{c}{1.18}              \\ \cline{1-1}
      Average  & 1.26
      \end{tabular}
    }
  }{Gains Ensemble vs Average}
  \vfill
\end{landscape}


\tab{tab:gain-loss}{Ensemble percentage points gains (positive numbers) / losses (negative numbers) for +SRL over $-$SRL for each configuration. The best of the +SRL configurations was taken into account: \tikz[baseline=(char.base)]\node[minimum width=2em,text height=1.2ex, text depth=0.1ex,fill=blue,text=black](char){zeros};, \tikz[baseline=(char.base)]\node[minimum width=2em,text height=1.2ex, text depth=0.1ex,fill=dark-blue,text=black](char){duplicate};. Light blue denotes that both architectures performed \tikz[baseline=(char.base)]\node[minimum width=2em,text height=1.2ex, text depth=0.1ex,fill=llight-blue,text=black](char){equally}; (in which case both ensembles were controlled for significance). One asterisk signifies a $p$-value $<$ 10\%, two stand for $p <$ 5\% and three for $p <$ 1\%.}{
    \scalebox{1}{
      \begin{tabular}{llcccccc}
                                                   &           & \multicolumn{2}{c|}{\textbf{{[}CLS{]} Head}}                                                                 & \multicolumn{2}{c|}{\textbf{LHSA Head}}                                                                        & \multicolumn{2}{c}{\textbf{GRU Head}}                                                                     \\ \cline{3-8}
                                                   &           & \multicolumn{1}{c|}{subtok.}                          & \multicolumn{1}{c|}{merged}                          & \multicolumn{1}{c|}{subtok.}                          & \multicolumn{1}{c|}{merged}                            & \multicolumn{1}{c|}{subtok.}                        & \multicolumn{1}{c}{merged}                          \\ \hline\hline
      \multicolumn{1}{c}{\multirow{2}{*}{deISEAR}} & $\alpha$  & \multicolumn{1}{c|}{\cellcolor{blue} .67}             & \multicolumn{1}{c|}{\cellcolor{dark-blue} .00}       & \multicolumn{1}{c|}{\cellcolor{blue} 6.62**}          & \multicolumn{1}{c|}{\cellcolor{dark-blue} .00}         & \multicolumn{1}{c|}{\cellcolor{blue} 4.63**}        & \multicolumn{1}{c}{\cellcolor{dark-blue} $-1.99$}   \\
      \multicolumn{1}{c}{}                         & $\beta$   & \multicolumn{1}{c|}{\cellcolor{llight-blue} 3.31}     & \multicolumn{1}{c|}{\cellcolor{dark-blue} 1.99}      & \multicolumn{1}{c|}{\cellcolor{dark-blue} $-4.63$*}   & \multicolumn{1}{c|}{\cellcolor{blue} $-1.32$}          & \multicolumn{1}{c|}{\cellcolor{blue} 1.32}          & \multicolumn{1}{c}{\cellcolor{dark-blue} $-1.99$}   \\ \cline{3-8}
      \multicolumn{1}{c}{\multirow{2}{*}{SCARE}}   & $\alpha$  & \multicolumn{1}{c|}{\cellcolor{dark-blue} $-1.90$*}   & \multicolumn{1}{c|}{\cellcolor{dark-blue} 2.28*}     & \multicolumn{1}{c|}{\cellcolor{dark-blue} .76}        & \multicolumn{1}{c|}{\cellcolor{dark-blue} .38}         & \multicolumn{1}{c|}{\cellcolor{dark-blue} .38}      & \multicolumn{1}{c}{\cellcolor{blue} $-1.89$}        \\
      \multicolumn{1}{c}{}                         & $\beta$   & \multicolumn{1}{c|}{\cellcolor{blue} $-1.51$**}       & \multicolumn{1}{c|}{\cellcolor{llight-blue} .00}     & \multicolumn{1}{c|}{\cellcolor{blue} $-.76$}          & \multicolumn{1}{c|}{\cellcolor{dark-blue} $-.38$}      & \multicolumn{1}{c|}{\cellcolor{blue} .76}           & \multicolumn{1}{c}{\cellcolor{dark-blue} $-1.13$}   \\ \cline{3-8}
      \multicolumn{1}{c}{\multirow{2}{*}{PAWS-X}}  & $\alpha$  & \multicolumn{1}{c|}{\cellcolor{blue} .97*}            & \multicolumn{1}{c|}{\cellcolor{dark-blue} 2.59***}   & \multicolumn{1}{c|}{\cellcolor{blue} $-.41$}          & \multicolumn{1}{c|}{\cellcolor{dark-blue} .25}         & \multicolumn{1}{c|}{\cellcolor{llight-blue} .51}     & \multicolumn{1}{c}{\cellcolor{dark-blue} .71}       \\
      \multicolumn{1}{c}{}                         & $\beta$   & \multicolumn{1}{c|}{\cellcolor{dark-blue} .72*}       & \multicolumn{1}{c|}{\cellcolor{dark-blue} .25}       & \multicolumn{1}{c|}{\cellcolor{blue} .56}             & \multicolumn{1}{c|}{\cellcolor{dark-blue} $-1.07$***}  & \multicolumn{1}{c|}{\cellcolor{dark-blue} .30}      & \multicolumn{1}{c}{\cellcolor{dark-blue} .05}       \\ \cline{3-8}
      \multicolumn{1}{c}{\multirow{2}{*}{XNLI}}    & $\alpha$  & \multicolumn{1}{c|}{\cellcolor{blue} .18}             & \multicolumn{1}{c|}{\cellcolor{blue} $-.22$}         & \multicolumn{1}{c|}{\cellcolor{blue} .22}             & \multicolumn{1}{c|}{\cellcolor{blue} .70*}             & \multicolumn{1}{c|}{\cellcolor{dark-blue} .46}      & \multicolumn{1}{c}{\cellcolor{dark-blue} .12}       \\
      \multicolumn{1}{c}{}                         & $\beta$   & \multicolumn{1}{c|}{\cellcolor{blue} .09}             & \multicolumn{1}{c|}{\cellcolor{dark-blue} .44}       & \multicolumn{1}{c|}{\cellcolor{dark-blue} .09}        & \multicolumn{1}{c|}{\cellcolor{blue} .53}              & \multicolumn{1}{c|}{\cellcolor{blue} .98}           & \multicolumn{1}{c}{\cellcolor{dark-blue} .89}       \\ % \hline\hline
      % & \multicolumn{2}{l}{Accumulation}                  \\ \cline{2-4}
      % & \multicolumn{2}{l}{\textbf{Gains} (significant)}  & 32 (5) \\
      % & \multicolumn{2}{l}{\textbf{Losses} (significant)} & 15 (3) \\
     \end{tabular}
    }
  }{Gain-Loss}

\begin{figure}
  \begin{minipage}{0.45\linewidth}
  \vspace{0pt}
    \includegraphics[width=1.0\linewidth]{images/gain_losses_accumulated.pdf}
    % \fig{images/gain_losses_accumulated.pdf}{fig:Gain-Losses_mode}{Accumulated scores from table \ref{tab:gain-loss} of which SRL mode performed stronger out of a total of 48 settings. $-$SRL. The bars indicate a slight outperforming of duplicating SRLs instead of adding zeros.}{7}{SRL Mode comparison}
  \end{minipage}
  \hfill
  \begin{minipage}{0.45\linewidth}
  \vspace{0pt}
    \includegraphics[width=1.0\linewidth]{images/gain_losses_SRL.pdf}
    % \fig{images/gain_losses_SRL.pdf}{fig:Gain-Losses_SRL}{Accumulated Gains and Losses for +SRL. Darker shades indicate significant results. Light blue are architectures where gain equals 0.00. Note that the red colors correspond to the negative values of table \ref{tab:gain-loss}.}{7}{SRL Gains Losses}
  \end{minipage}
  \stepcounter{myfigure}
  \caption[Accumulated Gains and Losses.]{Accumulated scores from table \ref{tab:gain-loss}. \textbf{Left}: Which SRL mode performed stronger out of a total of 48 settings. The bars indicate a slight outperforming of duplicating SRLs instead of adding zeros. \textbf{Right}: Counts for Gains and Losses in all 48 settings. Darker shades indicate significant results. The light green tip stands for settings where the gain equals 0.00.}
\end{figure}


  \tab{tab:results-qa}{Accuracy ensemble results (per 5 models) on question answering tasks. \textbf{Bold} font marks the best result per line, \underline{underline} the second best, and \textit{italics} the poorest.}{
    \scalebox{1}{
      \begin{tabular}{llccc|ccc}
                                                 &           & \multicolumn{6}{c}{\textbf{Span Prediction Head}}                                                                                                                                                                                                \\ \cline{3-8}
                                                 &           & \multicolumn{3}{c|}{subtokenized}                                                                                                & \multicolumn{3}{c}{subtokens merged}                                                                          \\ \cline{3-8}
                                                 &           & \multicolumn{1}{c|}{$-$SRL}                     & \multicolumn{2}{c|}{+SRL}                                                      & \multicolumn{1}{c|}{$-$SRL}         & \multicolumn{2}{c}{+SRL}                                                \\ %\cline{3-4}\cline{6-7}
                                                 &           & \multicolumn{1}{c|}{}                           & \multicolumn{1}{c}{zeros}             & \multicolumn{1}{c|}{dupl.}             & \multicolumn{1}{c|}{}               & \multicolumn{1}{c}{zeros}          & dupl.                              \\ \hline\hline
      \multicolumn{1}{c}{\multirow{2}{*}{MLQA}}  & $\alpha$  & \multicolumn{1}{c|}{\textbf{30.69}}             & \multicolumn{1}{c}{\underline{29.68}} & \multicolumn{1}{c|}{\underline{29.68}} & \multicolumn{1}{c|}{21.92}          & \multicolumn{1}{c}{21.92}          & \multicolumn{1}{c}{\textit{21.81}} \\
      \multicolumn{1}{c}{}                       & $\beta$   & \multicolumn{1}{c|}{\textbf{44.75}}             & \multicolumn{1}{c}{\underline{44.55}} & \multicolumn{1}{c|}{43.41}             & \multicolumn{1}{c|}{\textit{41.66}} & \multicolumn{1}{c}{41.86}          & \multicolumn{1}{c}{41.79}          \\ \cline{3-8}
      \multicolumn{1}{c}{\multirow{2}{*}{XQuAD}} & $\alpha$  & \multicolumn{1}{c|}{\textbf{42.01}}             & \multicolumn{1}{c}{\underline{41.42}} & \multicolumn{1}{c|}{41.12}             & \multicolumn{1}{c|}{37.87}          & \multicolumn{1}{c}{36.98}          & \multicolumn{1}{c}{\textit{35.50}} \\
      \multicolumn{1}{c}{}                       & $\beta$   & \multicolumn{1}{c|}{\underline{46.57}}          & \multicolumn{1}{c}{45.43}             & \multicolumn{1}{c|}{\textbf{46.86}}    & \multicolumn{1}{c|}{37.43}          & \multicolumn{1}{c}{\textit{37.14}} & \multicolumn{1}{c}{39.14}          \\ \hline\hline
      \multicolumn{1}{c}{Scores}                 &           & \multicolumn{1}{c|}{\textbf{III} \underline{I}} & \multicolumn{2}{c|}{\textbf{I} \underline{III}}                                & \multicolumn{1}{c|}{}               & \multicolumn{2}{c}{}                                                    \\ \cline{1-2}
      \multicolumn{1}{c}{+SRL}                   & \multicolumn{3}{l}{\textbf{1} \underline{3}} \\
      \multicolumn{1}{c}{$-$SRL}                 & \multicolumn{3}{l}{\textbf{3} \underline{1}}

      \end{tabular}
    }
  }{Results-QA}


\subsection{Testing for Statistical Significance}

``if we rely on empirical evaluation to validate our hypotheses and reveal the correct language processing mechanisms, we better be sure that our results are not coincidental.'' \citep{dror2018hitchhiker}


$\delta(X) = M(A, X) - M(B, X)$

$H_0:\delta(X) \leq 0$

$H_1:\delta(X) > 0$

``It is important to have a method at hand that gives us assurances that the
observed increase in the test score on a test set reflects true improvement in system
quality.'' \citep{koehn2004statistical}

\citet{koehn2004statistical} focus strongly on significance testing in the context of evaluating
on a sub-sample of the test set --- due to expensiveness of testing on the whole set ---
and making statements about the reliability of this subset sample:

``Given a test result of \emph{m} BLEU, we want to compute with a confidence \emph{q} (or
p-level P = 1 - \emph{q}) that the rue BLEU score lies in an interval [\emph{m} - \emph{d},
\emph{m} + \emph{d}].'' \citep{koehn2004statistical}

Since the systems under review here predict on the exact same test set, the assumed independence
of the predictions of the two models holds no longer. \citet{morgan2005statistical} propose
the following algorithm for testing difference significance:

``When the results are better with the new technique, a question arises as to whether
these result differences are due to the new technique actually being better or just due to
chance. Unfortunately, one usually cannot directly answer the question “what is the probability
that the new technique is better given the results on the test data set”'' \citep{yeh2000more}

``But with statistics, one can answer the following proxy question: if the new technique was
actually no different than the old technique (the null hypothesis), what is the probability
that the results on the test set would be at least this skewed in the new technique’s
favor?'' \citep{yeh2000more}

Many evaluation metrics ``have a tendency to underestimate the significance of the results'',
due to their inherent assumption that the compared systems ``produce independent results''
when in reality, they tend to produce ``positively correlated results''. \citep{yeh2000more}


\begin{algorithm}
\caption{Approximate Randomization Algorithm}
\label{alg:approximate-randomization}
	\begin{algorithmic}[1]
    \STATE $O = \{x_1, \dotsc, x_n\} =$ test set
    \STATE $p(M,x) \leftarrow$ prediction from model $M$ on example $x$
    \STATE $O_A = \{p(A,x_1), \dotsc, p(A,x_n)\}$
    \STATE $O_B = \{p(B,x_1), \dotsc, p(B,x_n)\}$
    \STATE $O_{gold} =$ gold labels for $\{x_1, \dotsc, x_n\}$
    \STATE $r \leftarrow 0$
    \STATE $R \leftarrow 0$
    \STATE $threshold \leftarrow 1,000$
    \STATE $rand() \leftarrow$ returns $0$ or $1$, randomly
    \STATE $swap(x,y) \leftarrow$ exchanges elements $x \in A,y \in B$ such that $y \in A, x \in B$
    \STATE $p = 0.05$
    \STATE $e(\hat{Y},Y) =$ evaluation function for gold labels $\hat{Y}$ and predictions $Y$
    \STATE $t_{original} =\ \mid e(O_{gold},O_A) - e(O_{gold},O_B) \mid$
    \WHILE{$R < threshold$}
      \FORALL{$(a_i, b_i) \in O_A \times O_B \mid i \in I$}
        \IF{$rand() = 0$}
          \STATE $swap(a_i,b_i)$
        \ENDIF
      \ENDFOR
      \STATE $t_{permute} =\ \mid e(O_{gold},O_A') - e(O_{gold},O_B') \mid$
      \IF{$t_{permute} \geq t_{original}$}
        \STATE $r \mathrel{+}= 1$
      \ENDIF
      \STATE $R \mathrel{+}= 1$
    \ENDWHILE
    \IF{$\frac{r+1}{R+1} < p$}
      \STATE system $A$ truly better than system $B$
    \ENDIF
  \end{algorithmic}
\end{algorithm}


\subsubsection{Example Case for XNLI}


Let's consider the case for the non-merged subtokens setting in the resampled XNLI data set. The test
set contains 1,125 sentence pairs for which textual entailment must be predicted. From these 1,125
sentence pairs, 398 bear the gold label \emph{contradiction}, 357 are labeled \emph{entailment},
and 370 are \emph{neutral}; so, the class distribution of the set is fairly balanced.

I trained and optimized five systems for two architectures on the training and development set
of XNLI: One architecture is the plain ``vanilla'' GRU classifier described in section XXX, the
other is the same GRU architecture enriched with embedded SRLs (implementing the duplication
approach, described in section XXX). The ``vanilla'' system ensemble achieved an accuracy of
66,58\% on the XNLI test set, while the SRL enriched ensemble scored a 68,27\% --- in other
words, the SRL enchriched ensemble performed 1,69\% better than the ``vanilla'' ensemble.

To check if this difference truly measures the supremacy of the latter model over the first, I
apply the above described algorithm \ref{alg:approximate-randomization} for testing significance
by permuting the actual ensemble predictions. Note that both ensemble models were equally
right or wrong in 1,018 cases out of 1,125.  From this follows, in consequence, that in 90,49\%
of the cases the flipping of predictions between the ensemble models will have no effect.

Result p = 4.80\%

In contrary, if we compare this results to the zero implementation of SRLs, we observe something
different: The accuracy of this ensemble was slightly lower than the duplicate architecture;
namely 67,73\% or, speaking in differences, 1.15\% better than the vanilly ensemble. The
number of equally right or wrong examples was also slightly lower --- 1,010 examples were
equally wrong or correct predicted by the systems.

Result zeros p = 14.09\%

\section{SRL Evaluation}
\label{sec:srl-evaluation}

\section{Ablation study}
\label{sec:ablation}

To be able to make substantial claims about the positive influence about a new algorithm over an
established one, it is common ground to conduct an ablation study. In such a study, one tries to
determine which aspects of the proposed architecture contribute how much to the overall performance
gain (or loss, respectively).

In my case, i.e. the attempt to improve the performance of BERT regarding NLU tasks, the
following question would need some ablation experiments to be answered: What part of the
SRLs is most responsible for the performance boost? To be able to formulate this in a
matter which can be experimentally tested, I identify two easily separatable and testable
aspects of SRLs: Firstly, the information what parts of a sentence are the predicates.
The intuition behind this is that maybe the head relies mostly on the information as to
which tokens carry information about the events that happen in a given sentence. To test
this, I simply drpo the information about all SRLs, except the information that a token
is a predicate. In the second case, the hypothesis is reversed: Maybe the head is able to
get the most useful hints about the information which inidcates what role certain token
groups play in a given sentence. To test for this all information about predicates is
dropped and only information about arguments is preserved.

\begin{minipage}{1.0\linewidth}
  \begin{srl}
  \centering
    \begin{BVerbatim}[commandchars=\\\{\}, fontsize=\footnotesize]
      Ich        \colorbox{llight-blue}{B-A0}         O
      weiß       \colorbox{blue}{B-V}          O
      nicht      O             O
      ob         \colorbox{llight-blue}{B-A1}         O
      er         \colorbox{llight-blue}{I-A1}         \colorbox{llight-blue}{B-A0}
      danach     \colorbox{llight-blue}{I-A1}         O
      in         \colorbox{llight-blue}{I-A1}         \colorbox{llight-blue}{B-A1}
      Augusta    \colorbox{llight-blue}{I-A1}         \colorbox{llight-blue}{I-A1}
      geblieben  \colorbox{llight-blue}{I-A1}         \colorbox{blue}{B-V}
      ist        \colorbox{llight-blue}{I-A1}         O
      .          O             O
      ==============================
      Er         \colorbox{llight-blue}{B-A0}
      wohnte     \colorbox{blue}{B-V}
      weiterhin  O
      in         \colorbox{llight-blue}{B-A1}
      Augusta    \colorbox{llight-blue}{I-A1}
      .          O
    \end{BVerbatim}
    \caption{Normal SRLs.}
  \end{srl}
\end{minipage}

\begin{srl}[!h]
\centering
  \begin{minipage}{0.45\linewidth}
  \vspace{0pt}
    \begin{BVerbatim}[commandchars=\\\{\}, fontsize=\footnotesize]
      Ich        O            O
      weiß       \colorbox{blue}{B-V}         O
      nicht      O            O
      ob         O            O
      er         O            O
      danach     O            O
      in         O            O
      Augusta    O            O
      geblieben  O            \colorbox{blue}{B-V}
      ist        O            O
      .          O            O
      ==============================
      Er         O
      wohnte     \colorbox{blue}{B-V}
      weiterhin  O
      in         O
      Augusta    O
      .          O
    \end{BVerbatim}
  \end{minipage}
  \hfill
  \begin{minipage}{0.45\linewidth}
  \vspace{0pt}
    \begin{BVerbatim}[commandchars=\\\{\}, fontsize=\footnotesize]
      Ich        \colorbox{llight-blue}{B-A0}         O
      weiß       O             O
      nicht      O             O
      ob         \colorbox{llight-blue}{B-A1}         O
      er         \colorbox{llight-blue}{I-A1}         \colorbox{llight-blue}{B-A0}
      danach     \colorbox{llight-blue}{I-A1}         O
      in         \colorbox{llight-blue}{I-A1}         \colorbox{llight-blue}{B-A1}
      Augusta    \colorbox{llight-blue}{I-A1}         \colorbox{llight-blue}{I-A1}
      geblieben  \colorbox{llight-blue}{I-A1}         O
      ist        \colorbox{llight-blue}{I-A1}         O
      .          O             O
      ==============================
      Er         \colorbox{llight-blue}{B-A0}
      wohnte     O
      weiterhin  O
      in         \colorbox{llight-blue}{B-A1}
      Augusta    \colorbox{llight-blue}{I-A1}
      .          O
    \end{BVerbatim}
  \end{minipage}
\end{srl}
\captionof{srl}{\textbf{Left}: Only predicate SRls. \textbf{Right}:  Only argument SRLs.}


\tab{tab:pawsx-abla}{Ablation on Effect of PREDs and ARGs isolated. note that PRED/ARG SRL not significant (SCARE, XNLI ARGs almost, ca. 11\%)}{
  \scalebox{0.9}{
    \begin{tabular}{llcccc}
                     &                               & \multicolumn{1}{c|}{$-$SRL}                  & \multicolumn{3}{c}{+SRL}                                                                                                 \\
                     &                               & \multicolumn{1}{c|}{}                        & \multicolumn{1}{c}{only PREDs}         & \multicolumn{1}{c}{only ARGS}           & \multicolumn{1}{c}{normal}            \\ \cline{3-6}
    deISEAR $\alpha$ & LHSA Head subtok. zeros       & \multicolumn{1}{c|}{\textit{70.86}}          & \multicolumn{1}{c}{72.19}              & \multicolumn{1}{c}{\underline{75.50**}} & \multicolumn{1}{c}{\textbf{77.48**}}  \\
    SCARE $\alpha$   & [CLS] Head merged duplicate   & \multicolumn{1}{c|}{\textit{83.33}}          & \multicolumn{1}{c}{84.47}              & \multicolumn{1}{c}{\underline{85.23}}   & \multicolumn{1}{c}{\textbf{85.61*}}   \\
    PAWS-X $\beta$   & [CLS] Head merged duplicate   & \multicolumn{1}{c|}{\textit{79.92}}          & \multicolumn{1}{c}{80.53}              & \multicolumn{1}{c}{\underline{80.68}}   & \multicolumn{1}{c}{\textbf{82.51***}} \\
    XNLI $\beta$     & GRU Head subtok. zeros        & \multicolumn{1}{c|}{\textit{66.84}}          & \multicolumn{1}{c}{67.02}              & \multicolumn{1}{c}{\textbf{68.00}}      & \multicolumn{1}{c}{\underline{67.82}} \\
    \end{tabular}
  }
}{Ablation Study}
%%\section{BLEU Scores}
%\label{sec:5_bleuscores}
%
%Table \ref{bleuresults} shows how to use the predefined tab command to have it listed.
%%\tab{#1: label}{#2: long caption}{#3: the table content}{#4: short caption}
%\tab{bleuresults}{BLEU scores of different MT systems}
%{\begin{tabular}{ll|ccc|c}
%language pair		& ABC	& YYY	\\
%\hline
%EN$\rightarrow$DE	& 20.56	& 32.53 \\
%DE$\rightarrow$EN	& 43.35	& 52.53 \\
%\hline
%\end{tabular}
%}{ABC BLEU scores}
%
%And we can reference the large table in the appendix as Table \ref{appendixTable}
%
%\section{Evaluation}
%\label{sec:5_evaluation}
%We saw in section \ref{sec:5_bleuscores}
%
%We will see in subsection \ref{subsec:5_moreeval} some more evaluations.
%
%\subsection{More evaluation}
%\label{subsec:5_moreeval}
%
%
%\section{Citations}
%Although BLEU scores should be taken with caution (see \citet{Callison-Burch2006})
%or if you prefer to cite like this: \citep{Callison-Burch2006} \ldots
%
%to cite: \cite[30-31]{Koehn2005} \\
%to cite within parentheses/brackets: \citep{Koehn2005}, \citep[30-32]{Koehn2005}\\ %\usepackage[square]{natbib} => square brackets
%
%to cite within the text: \citet{Koehn2005}, \citet[37]{Koehn2005}\\
%only the author(s): \citeauthor{Callison-Burch2006}\\
%only the year: \citeyear{Callison-Burch2006}\\
%
%\section{Graphics}
%
%To include a graphic that appears in the list of figures, use the predefined fig command:\\
%%\fig{#1: filename}{#2: label}{#3: long caption}{#4: width}{#5: short caption}
%\fig{images/Rosetta_Stone.jpg}{fig:rosetta}{The Rosetta Stone}{10}{Rosetta}
%
%%\reffig{#1: label}
%And then reference it as \reffig{fig:rosetta} is easy.
%
%\section{Some Linguistics}
%
%(With the package 'covington')\\
%
%Gloss:
%
%\begin{examples}
% \item \gll The cat sits on the table.
%	    die Katze sitzt auf dem Tisch
%	\glt 'Die Katze sitzt auf dem Tisch.'
%    \glend
%\end{examples}
%
%Gloss with morphology:
%
%\begin{examples}
% \item \gll La gata duerm -e en la cama.
%	    Art.Fem.Sg Katze schlaf -3.Sg in Art.Fem.Sg Bett
%	\glt 'Die Katze schl\"aft im Bett.'
%    \glend
%\end{examples}
%
