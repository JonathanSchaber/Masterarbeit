\newchap{Results}
\label{chap:5_results}

% \epigraph{Yada, yada, yada}{\textit{Someone, somewhere}}

In this chapter I report the outcomings of my experiments on the GerGLUE dataset. Because there
were several different implementations of various parameters tested against each other (SRLs duplicated vs.
SRLs zeroed, BERT tokens merged vs. SRLs splitted, etc.), I provide several aggregated ``views'' on the
plain numerical results, where one or more of these implementations is paid attention to. Further, I
document the ourcomings of a human assessment of the quality of the DAMESRL produced SRLs to be able to
make propositions about the usefulness of those and their effect on the results. Similar to this, the
general data quality of random samples of two datasets is manually reviewed, for the same reasons.
Eventually, I carry out a small ablation study, controlling the effect of ghosting out different
SRL structures to show that the actual, semanticity providing power of SRLs lies in the combination
of these structures.

Since the different dataset types were tested with different heads, I group the them
the following way: Results for classification datasets (deISEAR, SCARE, PAWS-X, XNLI)
are reported together, and the results for question answering datasets (MLQA, XQuAD),
are grouped together. Since the latter group consists of only two datasets addressing
the same task, and bearing in mind that there were only experiments for one head in
this group, the Span Prediction Head, the discussion analyzing these results will not
be as interesting and substantial as for the first group. For space reasons, and for
the sake of straightforwardness, only test set results are reported in the tables.
However, model selection was always based on development set results as is visualized
in figure \ref{fig:acc-loss}:

Based on the progression of the accuracy value on the development set the epoch with
the highest accuracy on the development set was chosen and the corresponding test set
accuracy was taken as best performance for this experiment on the dataset. The vertical
line in those three example experiments\myfootnote{\textbf{deISEAR} $\beta$ +SRL normal
duplicate [CLS] head, \textbf{SCARE} $\beta$ +SRL merge zeros GRU head, \textbf{XNLI}
$\alpha$ +SRL merge zeros [CLS] head.} accuracy and loss progression on development and
test results compared). marks this epoch, the horizontal dran through line marks the
development accuarcy (the ``peak'' of the red curve), and the horizontal dotted line
marks the correpsonding test accuracy. On the right the corresponding losses for the
same epoch are marked in the same fashion.

\begin{figure}[H]
  \begin{center}
    \includegraphics[width=11cm]{images/acc_loss-3_sets.pdf}
  \end{center}
  \stepcounter{myfigure}
  \caption[Accuracy/Loss plots of three experiments]{Accuracy and loss plots for three
experiments (\textcolor{std-blue}{training}, \textcolor{std-red}{development}, and
\textcolor{std-green}{test} set): The vertical line marks the epoch with the highest
development set accuracy}
  \label{fig:acc-loss}
\end{figure}

In the deISEAR plot, we see that early stopping
was triggered after the loss on the development set increased for four contiguous
epochs --- indicating an overfitting of the model on the training set. Both SCARE
and XNLI experiments ran until the maximum number of epochs were reached without
triggering early stopping. However, the SCARE accuracy and loss progressions show
much more fluctuations and erratic behavior than the XNLI ones, indicating the
noisiness of the data and the randomness of the function that needs to be learned
by the model.


% (see figure
% \ref{fig:acc-loss} for visualizations of example\myfootnote{\textbf{deISEAR} $\beta$
% +SRL normal duplicate [CLS] head, \textbf{SCARE} $\beta$ +SRL merge zeros GRU head,
% \textbf{XNLI} $\alpha$ +SRL merge zeros [CLS] head.} accuracy and loss progression on
% development and test results compared).


\section{Controlling for Statistical Significance}

Before reporting the actual results, I briefly elaborate on my strategy for
assessing statistical significance, since this is a crucial aspect of empirical
analysis in general, and in attributing superiority of one model over the other
on the basis of measured performance on a dataset in particular:
``if we rely on empirical evaluation to validate our hypotheses and reveal the
correct language processing mechanisms, we better be sure that our results are
not coincidental'' \citep{dror2018hitchhiker}. In a formalized way, if we have a
performance measure $M$ --- in my case accuracy --- to evaluate the predictions
of a Model $A$ on a dataset $X$, we want to assess, if this performance was better
than the one of a model $B$:

$\delta(X) = M(A, X) - M(B, X)$

where $\delta(X)$ refers to the test statistic, which will be shortly explained.
Thus, the null-hypothesis which needs to be rejected, and the corresponding
alternative hypothesis (that model $A$ \emph{is} in fact truly superior to model
$B$) are formulated:

$H_0:\delta(X) \leq 0$

$H_1:\delta(X) > 0$

However, it is normally not the case that one is able to answer this question --- is the observed
performance measurement due to true model improvement or simply due to chance --- by simply looking
at the pure results; ``[b]ut with statistics, one can answer the following proxy question: if the
new technique was actually no different than the old technique (the null hypothesis), what is the
probability that the results on the test set would be at least this skewed in the new technique’s
favor?'' \citep{yeh2000more}

In other words, to be able to recet the above defined null-hypothesis, usually a $p$-value test is
computed, where $p$ is defined ``as the probability, under the null hypothesis $H_0$, of obtaining
a result equal to or more extreme than what was actually observe'' \citep[p.~1384]{dror2018hitchhiker}:

$Pr(\delta(X) \geq \delta_{observed} | H_0)$.

There are different approaches as to how this probability can
be computed: \citep{koehn2004statistical}, e.g., proposes a
``paired bootstrap resampling'' algorithm he applies to machine
translation systems. I follow here \cite{morgan2005statistical} who
argues in favour of an ``approximate randomization '' approach,
which makes less assumptions about the distribution of the sample
distributions.\myfootnote{ \citeauthor{koehn2004statistical}
presupposes that the results to be compared stem from different
subsamples of the original test set which get re-drawn repeatedly
with replacement. In my case, this does not hold since my results
are not obtained from subsamples but the whole test set.}

% ``It is important to have a method at hand that gives us assurances that the
% observed increase in the test score on a test set reflects true improvement in system
% quality.'' \citep{koehn2004statistical}

% \citet{koehn2004statistical} focus strongly on significance testing in the context of evaluating
% on a sub-sample of the test set --- due to expensiveness of testing on the whole set ---
% and making statements about the reliability of this subset sample:

% ``Given a test result of \emph{m} BLEU, we want to compute with a confidence \emph{q} (or
% p-level P = 1 - \emph{q}) that the rue BLEU score lies in an interval [\emph{m} - \emph{d},
% \emph{m} + \emph{d}].'' \citep{koehn2004statistical}

% Since the systems under review here predict on the exact same test set, the assumed independence
% of the predictions of the two models holds no longer. \citet{morgan2005statistical} propose
% the following algorithm for testing difference significance:

% ``When the results are better with the new technique, a question arises as to whether
% these result differences are due to the new technique actually being better or just due to
% chance. Unfortunately, one usually cannot directly answer the question “what is the probability
% that the new technique is better given the results on the test data set'' \citep{yeh2000more}

% ``But with statistics, one can answer the following proxy question: if the new technique was
% actually no different than the old technique (the null hypothesis), what is the probability
% that the results on the test set would be at least this skewed in the new technique’s
% favor?'' \citep{yeh2000more}

% Many evaluation metrics ``have a tendency to underestimate the significance of the results'',
% due to their inherent assumption that the compared systems ``produce independent results''
% when in reality, they tend to produce ``positively correlated results''. \citep{yeh2000more}

The basic idea is to go through the paired predictions of two models (on
the same test set) and
randomly (i.e. with a 50\% chance) flip the predictions between them. If
this has been completed for the whole test set, the difference $\delta_{perm}$ of the
evaluation metric between the recomputed performance of them is calculated again
and it is checked whether $\delta_{perm} \geq \delta_{orig}$. This process is repeated
$R$ times and if the number of times $\delta_{perm}$ was greater/equal is small
enough, in statistics, normally 5\%, for a large enough number $R$, we can reject
the null-hypothesis with good confidence. See the following algorithm \ref{alg:alg:approximate-randomization}
for a more detailed formulation of this process:

\begin{algorithm}
\caption{Approximate Randomization Algorithm}
\label{alg:approximate-randomization}
	\begin{algorithmic}[1]
    \STATE $p(M,x) =$ prediction of model $M$ on example $x$
    \STATE $A, B =$ Two different models
    \STATE $O = \{x_1, \dotsc, x_n\} =$ test set
    \STATE $O_A = \{p(A,x_1), \dotsc, p(A,x_n)\}$
    \STATE $O_B = \{p(B,x_1), \dotsc, p(B,x_n)\}$
    \STATE $O_{gold} =$ gold labels for $\{x_1, \dotsc, x_n\}$
    \STATE $e(\hat{Y},Y) =$ evaluation function for gold labels $\hat{Y}$ and predictions $Y$
    \STATE $t_{original} =\ \mid e(O_{gold},O_A) - e(O_{gold},O_B) \mid$
    \STATE $rand() =$ returns $0$ or $1$, randomly
    \STATE $swap(x,y) =$ exchanges elements $x \in A,y \in B$ such that $y \in A, x \in B$
    \STATE $r \leftarrow 0$
    \STATE $R \leftarrow 0$
    \STATE $threshold \leftarrow 1,000$
    \STATE $p \leftarrow 0.05$
    \WHILE{$R < threshold$}
      \FORALL{$(a_i, b_i) \in O_A \times O_B \mid i \in I$}
        \IF{$rand() = 0$}
          \STATE $swap(a_i,b_i)$
        \ENDIF
      \ENDFOR
      \STATE $t_{permute} =\ \mid e(O_{gold},O_A') - e(O_{gold},O_B') \mid$
      \IF{$t_{permute} \geq t_{original}$}
        \STATE $r \mathrel{+}= 1$
      \ENDIF
      \STATE $R \mathrel{+}= 1$
    \ENDWHILE
    \IF{$\frac{r+1}{R+1} < p$}
      \STATE system $A$ truly better than system $B$
    \ENDIF
  \end{algorithmic}
\end{algorithm}


% \subsubsection{Example Case for XNLI}

% Let's consider the case for the non-merged subtokens setting in the resampled XNLI dataset. The test
% set contains 1,125 sentence pairs for which textual entailment must be predicted. From these 1,125
% sentence pairs, 398 bear the gold label \emph{contradiction}, 357 are labeled \emph{entailment},
% and 370 are \emph{neutral}; so, the class distribution of the set is fairly balanced.

% I trained and optimized five systems for two architectures on the training and development set
% of XNLI: One architecture is the plain ``vanilla'' GRU classifier described in section XXX, the
% other is the same GRU architecture enriched with embedded SRLs (implementing the duplication
% approach, described in section XXX). The ``vanilla'' system ensemble achieved an accuracy of
% 66,58\% on the XNLI test set, while the SRL enriched ensemble scored a 68,27\% --- in other
% words, the SRL enchriched ensemble performed 1,69\% better than the ``vanilla'' ensemble.

% To check if this difference truly measures the supremacy of the latter model over the first, I
% apply the above described algorithm \ref{alg:approximate-randomization} for testing significance
% by permuting the actual ensemble predictions. Note that both ensemble models were equally
% right or wrong in 1,018 cases out of 1,125.  From this follows, in consequence, that in 90,49\%
% of the cases the flipping of predictions between the ensemble models will have no effect.

% Result p = 4.80\%

% In contrary, if we compare this results to the zero implementation of SRLs, we observe something
% different: The accuracy of this ensemble was slightly lower than the duplicate architecture;
% namely 67,73\% or, speaking in differences, 1.15\% better than the vanilly ensemble. The
% number of equally right or wrong examples was also slightly lower --- 1,010 examples were
% equally wrong or correct predicted by the systems.

% Result zeros p = 14.09\%

% In summary it is safe to say that although there is a positive effect of injecting
% SRL information during training over all datasets and architectures, this effect is
% arguably quite small and unsteady. {\color{red} this is especially in yontrast to
% \cite{zhang2019semantics}, who report more stable and higher effects} In the next
% sections I will try to give an answer as to what are the reasons for these, honestly
% spoken, moderate results. Concretely, I will argue that this is mainly due to noise,
% present in differing intensities and at various levels in the data I acquired, that
% the model has to cope with:

% Afterwards, statistical signifance is indicated by appending one, two, or three asterisks
% to a result that was compared with one or several others: * stands for $p < 10\%$, ** for
% $p < 5\%$, and *** indicates very high significance of $p < 1\%$.



\section{Classification Dataset Results}

{\color{red} \begin{itemize}
  \item conjecture: SRLs are rather adding noise in sequences that are too long. Extreme examples are the Q\&A datasets.
  \item GRU architecture is probably strongest: most best models (even though mostly -SRL) and second best models, no worst performance
  \item 6 significantly better +SRL vs. 3 significantly worse +SRL. There seems to be a slight trend that when merging subtokens, duplicating SRLs when too less predicates is better.
  \item all 3 worsening are for subtokenized architectures.
\end{itemize}}

To obtain as stable results as possible, I decided to train five models for each architecture
and configuration, all initialized with different random seeds. Additionally, I ensembled the
five models, achieving a performance gain of several percentage points (see example of PAWS-X,
table \ref{tab:pawsx-beta}).\myfootnote{For ensembling, a straightforward majority vote of the five models
is implemented.} In table \ref{tab:results} below, the test set ensemble results for
each architecture on the classification datasets are reported. For each row, i.e. for
one hyperparameter set-up for one dataset, The best, second best and worst performace over
all three heads and SRL configurations are marekd. In the last row, Best and second best
results per head and +/-SRL for each subtokenization settings are accumulated.
As the Scores indicate, taken the results without controlling for significance,\myfootnote{
Here I don't control for statistical significance because it is not clear, against what model(s) should
a peak performance be controlled for: Take the 77.45\% accuracy of the deISEAR $\alpha$, achieved
by the +SRL, BERT tokens subtokenized, FFNN head: Against what should this results be compared? To all
other -SRL results? Only to the corresponding -SRL results for the same head?} the +SRL
configurations achieved 5 times the best, and 10 times the second best results --- compared
to 4 best and 5 second best results for -SRL. This is a first indicator that adding SRL information
seems to be able to support plain BERT embeddings in classification tasks.

The accumulations in roman numerals also indicate a further, observable trend: The GRU head
accumulated 5 best and 6 second best results, independent of with or without SRLs, appears to be better
suited for classification tasks than the [CLS] (2 best, 6 second bset) and FFNN (2 best, 3 second bset) heads.
Supporting this, the GRU head never was responsible for the worst performance, which were all
achieved by the FFNN and [CLS] heads.

In the following table \ref{tab:pawsx-beta}, the ensembling of each of the results in the main table is
exemplary disaggregated. Each head-SRL configuration is randomly initialized 5 times, resulting in
5 models achieving a certain performance on the dataset. By ensembling them, a steady gain of, in this case,
1.26\% compared to the average of the 5 models is achieved. Similar ensembling improvements where
obseverd in all other datasets.

% In a first step, I will discuss on the overall performance of models when the SRLs are added,
% compared to the same architectures without.

\begin{landscape}\centering
  % \vspace*{\fill}
  \tab{tab:results}{Test set accuracy ensemble results (per 5 models) on single sentence and sentence pair tasks.
                    \textbf{Bold} font marks the best result per line, \underline{underline} the second best, and \textit{italics} the poorest.
                    In the \emph{Scores} row, the afore mentioned positive extremes are accumulated for $-$SRL and $+$SRL;
                    note that if both +SRL configurations of an architecture achieved an extreme, it is only counted once.

                    The line marked with light gray --- PAWS-X $\beta$ --- is ``expanded'' in table \ref{tab:pawsx-beta} to illustrate
                    that each result in this table is actually a majority voting out of an ensembeling of fice models.}{
    \scalebox{0.90}{
      \begin{tabular}{llccc|ccc|ccc|ccc|ccc|ccc}
                                                      &           & \multicolumn{18}{c}{\large \textbf{Classification Datasets}}  \\ \\
                                                      &           & \multicolumn{6}{c|}{\textbf{{[}CLS{]} Head}}                                                                                                                                                                                                                      & \multicolumn{6}{c|}{\textbf{FFNN Head}}                                                                                                                                                                                                & \multicolumn{6}{c}{\textbf{GRU Head}}                                                                                                                                                                                                                           \\ \cline{3-20}
                                                      &           & \multicolumn{3}{c|}{subtokenized}                                                                                               & \multicolumn{3}{c|}{subtokens merged}                                                                                           & \multicolumn{3}{c|}{subtokenized}                                                                                   & \multicolumn{3}{c|}{subtokens merged}                                                                            & \multicolumn{3}{c|}{subtokenized}                                                                                             & \multicolumn{3}{c}{subtokens merged}                                                                                            \\ \cline{3-20}
                                                      &           & \multicolumn{1}{c|}{$-$SRL}                  & \multicolumn{2}{c|}{+SRL}                                                        & \multicolumn{1}{c|}{$-$SRL}                & \multicolumn{2}{c|}{+SRL}                                                          & \multicolumn{1}{c|}{$-$SRL}                    & \multicolumn{2}{c|}{+SRL}                                          & \multicolumn{1}{c|}{$-$SRL}                    & \multicolumn{2}{c|}{+SRL}                                       & \multicolumn{1}{c|}{$-$SRL}                  & \multicolumn{2}{c|}{+SRL}                                                      & \multicolumn{1}{c|}{$-$SRL}                     & \multicolumn{2}{c}{+SRL}                                                      \\ % \cline{3-4}\cline{6-7}\cline{9-10}\cline{12-13}\cline{15-16}\cline{18-19}
                                                      &           & \multicolumn{1}{c|}{}                        & \multicolumn{1}{c}{zeros}              & \multicolumn{1}{c|}{dupl.}              & \multicolumn{1}{c|}{}                      & \multicolumn{1}{c}{zeros}                 & \multicolumn{1}{c|}{dupl.}             & \multicolumn{1}{c|}{}                          & \multicolumn{1}{c}{zeros}             & \multicolumn{1}{c|}{dupl.} & \multicolumn{1}{c|}{}                          & \multicolumn{1}{c}{zeros}          & dupl.                      & \multicolumn{1}{c|}{}                        & \multicolumn{1}{c}{zeros}             & dupl.                                  & \multicolumn{1}{c|}{}                           & \multicolumn{1}{c}{zeros}             & dupl.                                 \\ \hline\hline
         \multicolumn{1}{c}{\multirow{2}{*}{deISEAR}} & $\alpha$  & \multicolumn{1}{c|}{71.52}                   & \multicolumn{1}{c}{72.19}              & \multicolumn{1}{c|}{71.52}              & \multicolumn{1}{c|}{72.19}                 & \multicolumn{1}{c}{\textit{67.55}}        & \multicolumn{1}{c|}{72.19}             & \multicolumn{1}{c|}{70.86}                     & \multicolumn{1}{c}{\textbf{77.48}}    & \multicolumn{1}{c|}{72.85} & \multicolumn{1}{c|}{74.17}                     & \multicolumn{1}{c}{72.85}          & \multicolumn{1}{c|}{74.17} & \multicolumn{1}{c|}{70.20}                   & \multicolumn{1}{c}{\underline{74.83}} & \multicolumn{1}{c|}{74.17}             & \multicolumn{1}{c|}{73.51}                      & \multicolumn{1}{c}{70.20}             & \multicolumn{1}{c}{71.52}             \\
         \multicolumn{1}{c}{}                         & $\beta$   & \multicolumn{1}{c|}{71.52}                   & \multicolumn{1}{c}{\underline{74.83}}  & \multicolumn{1}{c|}{\underline{74.83}}  & \multicolumn{1}{c|}{70.86}                 & \multicolumn{1}{c}{70.86}                 & \multicolumn{1}{c|}{72.85}             & \multicolumn{1}{c|}{\underline{74.83}}         & \multicolumn{1}{c}{\textit{68.21}}    & \multicolumn{1}{c|}{70.20} & \multicolumn{1}{c|}{\underline{74.83}}         & \multicolumn{1}{c}{73.51}          & \multicolumn{1}{c|}{70.86} & \multicolumn{1}{c|}{73.51}                   & \multicolumn{1}{c}{\underline{74.83}} & \multicolumn{1}{c|}{72.19}             & \multicolumn{1}{c|}{\textbf{76.82}}             & \multicolumn{1}{c}{70.20}             & \multicolumn{1}{c}{\underline{74.83}} \\ \cline{3-20}
         \multicolumn{1}{c}{\multirow{2}{*}{SCARE}}   & $\alpha$  & \multicolumn{1}{c|}{\underline{85.61}}       & \multicolumn{1}{c}{82.58}              & \multicolumn{1}{c|}{83.71}              & \multicolumn{1}{c|}{83.33}                 & \multicolumn{1}{c}{83.71}                 & \multicolumn{1}{c|}{\underline{85.61}} & \multicolumn{1}{c|}{83.33}                     & \multicolumn{1}{c}{83.71}             & \multicolumn{1}{c|}{84.09} & \multicolumn{1}{c|}{84.09}                     & \multicolumn{1}{c}{\textit{81.44}} & \multicolumn{1}{c|}{84.47} & \multicolumn{1}{c|}{83.71}                   & \multicolumn{1}{c}{83.33}             & \multicolumn{1}{c|}{84.09}             & \multicolumn{1}{c|}{\textbf{85.98}}             & \multicolumn{1}{c}{84.09}             & \multicolumn{1}{c}{83.71}             \\
         \multicolumn{1}{c}{}                         & $\beta$   & \multicolumn{1}{c|}{\underline{86.36}}       & \multicolumn{1}{c}{84.85}              & \multicolumn{1}{c|}{84.47}              & \multicolumn{1}{c|}{85.23}                 & \multicolumn{1}{c}{85.23}                 & \multicolumn{1}{c|}{85.23}             & \multicolumn{1}{c|}{\textbf{86.74}}            & \multicolumn{1}{c}{85.98}             & \multicolumn{1}{c|}{85.23} & \multicolumn{1}{c|}{84.47}                     & \multicolumn{1}{c}{\textit{83.33}} & \multicolumn{1}{c|}{84.09} & \multicolumn{1}{c|}{\textbf{86.74}}          & \multicolumn{1}{c}{85.98}             & \multicolumn{1}{c|}{83.71}             & \multicolumn{1}{c|}{\underline{86.36}}          & \multicolumn{1}{c}{84.09}             & \multicolumn{1}{c}{85.23}             \\ \hline
         \multicolumn{1}{c}{\multirow{2}{*}{PAWS-X}}  & $\alpha$  & \multicolumn{1}{c|}{80.63}                   & \multicolumn{1}{c}{81.60}              & \multicolumn{1}{c|}{81.49}              & \multicolumn{1}{c|}{\textit{79.92}}        & \multicolumn{1}{c}{80.63}                 & \multicolumn{1}{c|}{82.51}             & \multicolumn{1}{c|}{81.19}                     & \multicolumn{1}{c}{80.78}             & \multicolumn{1}{c|}{80.07} & \multicolumn{1}{c|}{80.43}                     & \multicolumn{1}{c}{80.02}          & \multicolumn{1}{c|}{80.68} & \multicolumn{1}{c|}{82.26}                   & \multicolumn{1}{c}{82.77}             & \multicolumn{1}{c|}{82.77}             & \multicolumn{1}{c|}{82.82}                      & \multicolumn{1}{c}{\underline{82.87}} & \multicolumn{1}{c}{\textbf{83.53}}    \\
         \multicolumn{1}{c}{}                         & $\beta$   & \multicolumn{1}{g|}{87.49}                   & \multicolumn{1}{g}{\underline{88.05}}  & \multicolumn{1}{g|}{\textbf{88.21}}     & \multicolumn{1}{g|}{87.75}                 & \multicolumn{1}{g}{87.24}                 & \multicolumn{1}{g|}{88.00}             & \multicolumn{1}{g|}{86.83}                     & \multicolumn{1}{g}{87.39}             & \multicolumn{1}{g|}{87.09} & \multicolumn{1}{g|}{87.75}                     & \multicolumn{1}{g}{\textit{86.58}} & \multicolumn{1}{g|}{86.68} & \multicolumn{1}{g|}{87.60}                   & \multicolumn{1}{g}{87.60}             & \multicolumn{1}{g|}{87.90}             & \multicolumn{1}{g|}{88.00}                      & \multicolumn{1}{g}{88.00}             & \multicolumn{1}{g}{\underline{88.05}} \\ \cline{3-20}
         \multicolumn{1}{c}{\multirow{2}{*}{XNLI}}    & $\alpha$  & \multicolumn{1}{c|}{67.34}                   & \multicolumn{1}{c}{\textbf{67.52}}     & \multicolumn{1}{c|}{66.64}              & \multicolumn{1}{c|}{66.94}                 & \multicolumn{1}{c}{66.94}                 & \multicolumn{1}{c|}{\textit{66.26}}    & \multicolumn{1}{c|}{67.20}                     & \multicolumn{1}{c}{\underline{67.42}} & \multicolumn{1}{c|}{67.34} & \multicolumn{1}{c|}{66.38}                     & \multicolumn{1}{c}{67.08}          & \multicolumn{1}{c|}{66.92} & \multicolumn{1}{c|}{66.68}                   & \multicolumn{1}{c}{66.60}             & \multicolumn{1}{c|}{67.14}             & \multicolumn{1}{c|}{66.42}                      & \multicolumn{1}{c}{66.54}             & \multicolumn{1}{c}{66.26}             \\
         \multicolumn{1}{c}{}                         & $\beta$   & \multicolumn{1}{c|}{68.09}                   & \multicolumn{1}{c}{68.18}              & \multicolumn{1}{c|}{66.84}              & \multicolumn{1}{c|}{67.82}                 & \multicolumn{1}{c}{67.82}                 & \multicolumn{1}{c|}{\underline{68.36}} & \multicolumn{1}{c|}{66.31}                     & \multicolumn{1}{c}{65.60}             & \multicolumn{1}{c|}{66.40} & \multicolumn{1}{c|}{\textit{64.98}}            & \multicolumn{1}{c}{65.51}          & \multicolumn{1}{c|}{65.07} & \multicolumn{1}{c|}{66.84}                   & \multicolumn{1}{c}{67.82}             & \multicolumn{1}{c|}{67.02}             & \multicolumn{1}{c|}{67.64}                      & \multicolumn{1}{c}{66.31}             & \multicolumn{1}{c}{\textbf{68.53}}    \\ \hline\hline
         \multicolumn{1}{c}{Scores}                   &           & \multicolumn{1}{c|}{\underline{II}}          & \multicolumn{2}{c|}{\textbf{II} \underline{II}}                                  & \multicolumn{1}{c|}{}                      & \multicolumn{2}{c|}{\underline{II}}                                                & \multicolumn{1}{c|}{\textbf{I} \underline{I}}  & \multicolumn{2}{c|}{\textbf{I} \underline{I}}                      & \multicolumn{1}{c|}{\underline{I}}             & \multicolumn{2}{c|}{}                                           & \multicolumn{1}{c|}{\textbf{I}}              & \multicolumn{2}{c|}{\underline{II}}                                            & \multicolumn{1}{c|}{\textbf{II} \underline{I}}  & \multicolumn{2}{c}{\textbf{II} \underline{III}}                               \\ \cline{1-2}
         \multicolumn{1}{c}{+SRL}                     & \multicolumn{3}{l}{\textbf{5} \underline{10}} \\
         \multicolumn{1}{c}{$-$SRL}                   & \multicolumn{3}{l}{\textbf{4} \underline{5}}
      \end{tabular}
    }
  }{Results}

  \tab{tab:pawsx-beta}{The ``expanded'' PAWS-X $\beta$ results. The light gray line corresponds to the one in table \ref{tab:results}.
                       As can be seen, the fluctuations between single models is not too big, {\textcolor{red} which is an indicator that the architecture
                       is fairly stable.} Ensembeling reliably leads to a 1.26 percentage points gain on average, with a standard deviation of 0.26\%.}{
    \scalebox{0.9}{
      \begin{tabular}{lccc|ccc|ccc|ccc|ccc|ccc}
                 & \multicolumn{18}{c}{\large \textbf{PAWS-X $\beta$}}  \\ \\
                 & \multicolumn{6}{c|}{\textbf{{[}CLS{]} Head}}                                                                                                                                                                                                                      & \multicolumn{6}{c|}{\textbf{FFNN Head}}                                                                                                                                                                                                         & \multicolumn{6}{c}{\textbf{GRU Head}}                                                                                                                                                                                                                           \\ \cline{2-19}
                 & \multicolumn{3}{c|}{subtokenized}                                                                                               & \multicolumn{3}{c|}{subtokens merged}                                                                                           & \multicolumn{3}{c|}{subtokenized}                                                                                            & \multicolumn{3}{c|}{subtokens merged}                                                                            & \multicolumn{3}{c|}{subtokenized}                                                                                             & \multicolumn{3}{c}{subtokens merged}                                                                                            \\ \cline{2-19}
                 & \multicolumn{1}{c|}{$-$SRL}                  & \multicolumn{2}{c|}{+SRL}                                                        & \multicolumn{1}{c|}{$-$SRL}                & \multicolumn{2}{c|}{+SRL}                                                          & \multicolumn{1}{c|}{$-$SRL}                    & \multicolumn{2}{c|}{+SRL}                                                   & \multicolumn{1}{c|}{$-$SRL}                    & \multicolumn{2}{c|}{+SRL}                                       & \multicolumn{1}{c|}{$-$SRL}                  & \multicolumn{2}{c|}{+SRL}                                                      & \multicolumn{1}{c|}{$-$SRL}                     & \multicolumn{2}{c}{+SRL}                                                      \\
                 & \multicolumn{1}{c|}{}                        & \multicolumn{1}{c}{zeros}              & \multicolumn{1}{c|}{dupl.}              & \multicolumn{1}{c|}{}                      & \multicolumn{1}{c}{zeros}                 & \multicolumn{1}{c|}{dupl.}             & \multicolumn{1}{c|}{}                          & \multicolumn{1}{c}{zeros}             & \multicolumn{1}{c|}{dupl.}          & \multicolumn{1}{c|}{}                          & \multicolumn{1}{c}{zeros}          & dupl.                      & \multicolumn{1}{c|}{}                        & \multicolumn{1}{c}{zeros}             & dupl.                                  & \multicolumn{1}{c|}{}                           & \multicolumn{1}{c}{zeros}             & dupl.                                 \\ \hline\hline
        Model 1  & \multicolumn{1}{c|}{85.41}                   & \multicolumn{1}{c}{85.36}              & \multicolumn{1}{c|}{86.02}              & \multicolumn{1}{c|}{86.43}                 & \multicolumn{1}{c}{86.53}                 & \multicolumn{1}{c|}{87.04}             & \multicolumn{1}{c|}{85.77}                     & \multicolumn{1}{c}{85.61}             & \multicolumn{1}{c|}{85.77}          & \multicolumn{1}{c|}{86.22}                     & \multicolumn{1}{c}{84.70}          & \multicolumn{1}{c|}{86.53} & \multicolumn{1}{c|}{87.54}                   & \multicolumn{1}{c}{87.49}             & \multicolumn{1}{c|}{86.43}             & \multicolumn{1}{c|}{85.51}                      & \multicolumn{1}{c}{86.93}             & \multicolumn{1}{c}{86.53}             \\
        Model 2  & \multicolumn{1}{c|}{86.07}                   & \multicolumn{1}{c}{86.83}              & \multicolumn{1}{c|}{86.99}              & \multicolumn{1}{c|}{85.87}                 & \multicolumn{1}{c}{86.32}                 & \multicolumn{1}{c|}{86.68}             & \multicolumn{1}{c|}{86.17}                     & \multicolumn{1}{c}{85.82}             & \multicolumn{1}{c|}{87.39}          & \multicolumn{1}{c|}{85.92}                     & \multicolumn{1}{c}{85.36}          & \multicolumn{1}{c|}{85.26} & \multicolumn{1}{c|}{87.04}                   & \multicolumn{1}{c}{86.99}             & \multicolumn{1}{c|}{85.87}             & \multicolumn{1}{c|}{87.19}                      & \multicolumn{1}{c}{86.07}             & \multicolumn{1}{c}{87.44}             \\
        Model 3  & \multicolumn{1}{c|}{86.07}                   & \multicolumn{1}{c}{87.49}              & \multicolumn{1}{c|}{86.99}              & \multicolumn{1}{c|}{87.14}                 & \multicolumn{1}{c}{85.26}                 & \multicolumn{1}{c|}{86.73}             & \multicolumn{1}{c|}{86.22}                     & \multicolumn{1}{c}{84.90}             & \multicolumn{1}{c|}{85.36}          & \multicolumn{1}{c|}{85.41}                     & \multicolumn{1}{c}{85.31}          & \multicolumn{1}{c|}{85.71} & \multicolumn{1}{c|}{86.12}                   & \multicolumn{1}{c}{85.66}             & \multicolumn{1}{c|}{86.83}             & \multicolumn{1}{c|}{86.48}                      & \multicolumn{1}{c}{87.09}             & \multicolumn{1}{c}{86.93}             \\
        Model 4  & \multicolumn{1}{c|}{87.39}                   & \multicolumn{1}{c}{86.32}              & \multicolumn{1}{c|}{86.58}              & \multicolumn{1}{c|}{86.38}                 & \multicolumn{1}{c}{84.04}                 & \multicolumn{1}{c|}{87.65}             & \multicolumn{1}{c|}{86.53}                     & \multicolumn{1}{c}{86.73}             & \multicolumn{1}{c|}{85.61}          & \multicolumn{1}{c|}{85.82}                     & \multicolumn{1}{c}{85.61}          & \multicolumn{1}{c|}{86.38} & \multicolumn{1}{c|}{84.99}                   & \multicolumn{1}{c}{86.02}             & \multicolumn{1}{c|}{87.70}             & \multicolumn{1}{c|}{86.99}                      & \multicolumn{1}{c}{86.68}             & \multicolumn{1}{c}{86.88}             \\
        Model 5  & \multicolumn{1}{c|}{86.63}                   & \multicolumn{1}{c}{86.43}              & \multicolumn{1}{c|}{86.58}              & \multicolumn{1}{c|}{86.99}                 & \multicolumn{1}{c}{85.26}                 & \multicolumn{1}{c|}{85.56}             & \multicolumn{1}{c|}{86.18}                     & \multicolumn{1}{c}{87.09}             & \multicolumn{1}{c|}{84.75}          & \multicolumn{1}{c|}{87.04}                     & \multicolumn{1}{c}{85.77}          & \multicolumn{1}{c|}{85.82} & \multicolumn{1}{c|}{86.12}                   & \multicolumn{1}{c}{85.82}             & \multicolumn{1}{c|}{86.73}             & \multicolumn{1}{c|}{87.34}                      & \multicolumn{1}{c}{86.73}             & \multicolumn{1}{c}{86.58}             \\ \hline\hline %\hhline{~==================}
        Average  & \multicolumn{1}{c|}{86.31}                   & \multicolumn{1}{c}{86.49}              & \multicolumn{1}{c|}{86.63}              & \multicolumn{1}{c|}{86.56}                 & \multicolumn{1}{c}{85.48}                 & \multicolumn{1}{c|}{\underline{86.81}} & \multicolumn{1}{c|}{86.22}                     & \multicolumn{1}{c}{86.03}             & \multicolumn{1}{c|}{\textit{85.78}} & \multicolumn{1}{c|}{86.08}                     & \multicolumn{1}{c}{85.35}          & \multicolumn{1}{c|}{85.94} & \multicolumn{1}{c|}{86.35}                   & \multicolumn{1}{c}{86.40}             & \multicolumn{1}{c|}{86.71}             & \multicolumn{1}{c|}{86.70}                      & \multicolumn{1}{c}{86.70}             & \multicolumn{1}{c}{\textbf{86.87}}    \\
        Ensemble & \multicolumn{1}{g|}{87.49}                   & \multicolumn{1}{g}{\underline{88.05}}  & \multicolumn{1}{g|}{\textbf{88.21}}     & \multicolumn{1}{g|}{87.75}                 & \multicolumn{1}{g}{87.24}                 & \multicolumn{1}{g|}{88.00}             & \multicolumn{1}{g|}{86.83}                     & \multicolumn{1}{g}{87.39}             & \multicolumn{1}{g|}{87.09}          & \multicolumn{1}{g|}{87.75}                     & \multicolumn{1}{g}{\textit{86.58}} & \multicolumn{1}{g|}{86.68} & \multicolumn{1}{g|}{87.60}                   & \multicolumn{1}{g}{87.60}             & \multicolumn{1}{g|}{87.90}             & \multicolumn{1}{g|}{88.00}                      & \multicolumn{1}{g}{88.00}             & \multicolumn{1}{g}{\underline{88.05}} \\ \cline{1-19}
        Gain     & \multicolumn{1}{c|}{1.18}                    & \multicolumn{1}{c}{1.56}               & \multicolumn{1}{c|}{1.58}               & \multicolumn{1}{c|}{1.19}                  & \multicolumn{1}{c}{1.76}                  & \multicolumn{1}{c|}{1.19}              & \multicolumn{1}{c|}{.65}                       & \multicolumn{1}{c}{1.36}              & \multicolumn{1}{c|}{1.31}           & \multicolumn{1}{c|}{1.67}                      & \multicolumn{1}{c}{1.23}           & \multicolumn{1}{c|}{.74}   & \multicolumn{1}{c|}{1.25}                    & \multicolumn{1}{c}{1.20}              & \multicolumn{1}{c|}{1.19}              & \multicolumn{1}{c|}{1.30}                       & \multicolumn{1}{c}{1.30}              & \multicolumn{1}{c}{1.18}              \\ \cline{1-1}
        Average  & 1.26 ($\sigma$ 0.28)
      \end{tabular}
    }
  }{Gains Ensemble vs Average}
  \vfill
\end{landscape}

To see whether there can be seen a tendency as to which SRL-BERT aligning strategy turns out
to be more effective, the results of the main table \ref{tab:results} are aggregated in table
\ref{tab:token-vs-merged}: For each head, the +SRL results are compared, and the differences are
reported in the table. For example, we look at the [CLS] head on deISEAR $\alpha$ and ask us, which
strategy --- merging the BERT subtokens back ot ``normal'' tokens, or splitting the SRLs up to
align with the subtokenized BERT tokens --- worked better. For this, the difference between both
for +SRL zeros and +SRL duplicate is calculated and controlled for statistical significance between
both ensembles. The subtokenizing strategy (yellow) outperformed the merging strategy (purple) 28
times, 15 times of it statistically significant, while merging was better 20 times, only 15\% of
it significantly. Therefore, at least for the GerGLUE classification datasets, splitting the SRLs
up to align with the BERT subtokens seems more effective than merging the BERT subtokens. This
also makes sense intuitively --- using the merging strategy of averaging the BERT embeddings of
subtokens leads clearly to an information loss or distortion that cannot be fully balanced by the
added SRL information.


\tab{tab:token-vs-merged}{Performance of architectures when BERT \customcolorbox{subtokenized}{yellow} vs. \customcolorbox{merged}{purple}. Both SRL implementations were
                          compared pairwise. Example case, upper left 4.64**: Comparison of deISEAR $\alpha$, +SRL zero
                          implementation, [CLS] Head, subtokenized ensemble (72.19\% accuracy) and the merged ensemble (67.55\%
                          accuracy) --- the subtokenized ensemble performed 4.64\% better, apparently with quite high significance (p $<$ 5\%).}{
  \scalebox{0.90}{
    \begin{tabular}{llcc|cc|cc}
                                                 &           & \multicolumn{2}{c|}{\textbf{{[}CLS{]} Head}}                                                     & \multicolumn{2}{c|}{\textbf{FFNN Head}}                                                            & \multicolumn{2}{c}{\textbf{GRU Head}}                                                           \\ \cline{3-8}
                                                 &           & \multicolumn{1}{c|}{zeros}                      & \multicolumn{1}{c|}{dupl.}                     & \multicolumn{1}{c|}{zeros}                        & \multicolumn{1}{c|}{dupl.}                     & \multicolumn{1}{c|}{zeros}                    & dupl.                                           \\ \hline\hline
    \multicolumn{1}{c}{\multirow{2}{*}{deISEAR}} & $\alpha$  & \multicolumn{1}{c|}{\cellcolor{yellow} 4.64**}  & \multicolumn{1}{c|}{\cellcolor{purple} .67}    & \multicolumn{1}{c|}{\cellcolor{yellow} 4.63*}     & \multicolumn{1}{c|}{\cellcolor{purple} 1.32}   & \multicolumn{1}{c|}{\cellcolor{yellow} 4.63*} & \multicolumn{1}{c}{\cellcolor{yellow} 2.65}     \\
    \multicolumn{1}{c}{}                         & $\beta$   & \multicolumn{1}{c|}{\cellcolor{yellow} 3.97*}   & \multicolumn{1}{c|}{\cellcolor{yellow} 1.98}   & \multicolumn{1}{c|}{\cellcolor{purple} 5.30*}     & \multicolumn{1}{c|}{\cellcolor{purple} .66}    & \multicolumn{1}{c|}{\cellcolor{yellow} 4.63*} & \multicolumn{1}{c}{\cellcolor{purple} 2.64}     \\ \cline{3-8}
    \multicolumn{1}{c}{\multirow{2}{*}{SCARE}}   & $\alpha$  & \multicolumn{1}{c|}{\cellcolor{purple} 1.13}    & \multicolumn{1}{c|}{\cellcolor{purple} 1.90}   & \multicolumn{1}{c|}{\cellcolor{yellow} 2.27*}     & \multicolumn{1}{c|}{\cellcolor{purple} .38}    & \multicolumn{1}{c|}{\cellcolor{purple} .76}   & \multicolumn{1}{c}{\cellcolor{yellow} .38}      \\
    \multicolumn{1}{c}{}                         & $\beta$   & \multicolumn{1}{c|}{\cellcolor{purple} .38}     & \multicolumn{1}{c|}{\cellcolor{purple} .76}    & \multicolumn{1}{c|}{\cellcolor{yellow} 2.65**}    & \multicolumn{1}{c|}{\cellcolor{yellow} 1.14}   & \multicolumn{1}{c|}{\cellcolor{yellow} 1.89}  & \multicolumn{1}{c}{\cellcolor{purple} 1.52}     \\ \hline
    \multicolumn{1}{c}{\multirow{2}{*}{PAWS-X}}  & $\alpha$  & \multicolumn{1}{c|}{\cellcolor{yellow} .97*}    & \multicolumn{1}{c|}{\cellcolor{purple} 1.02**} & \multicolumn{1}{c|}{\cellcolor{yellow} .76}       & \multicolumn{1}{c|}{\cellcolor{purple} .61}    & \multicolumn{1}{c|}{\cellcolor{purple} .10}   & \multicolumn{1}{c}{\cellcolor{purple} .76}      \\
    \multicolumn{1}{c}{}                         & $\beta$   & \multicolumn{1}{c|}{\cellcolor{yellow} .81**}   & \multicolumn{1}{c|}{\cellcolor{yellow} .21}    & \multicolumn{1}{c|}{\cellcolor{yellow} .81*}      & \multicolumn{1}{c|}{\cellcolor{yellow} .41}    & \multicolumn{1}{c|}{\cellcolor{purple} .40}   & \multicolumn{1}{c}{\cellcolor{purple} .15}      \\ \cline{3-8}
    \multicolumn{1}{c}{\multirow{2}{*}{XNLI}}    & $\alpha$  & \multicolumn{1}{c|}{\cellcolor{yellow} .58**}   & \multicolumn{1}{c|}{\cellcolor{yellow} .38}    & \multicolumn{1}{c|}{\cellcolor{yellow} .34}       & \multicolumn{1}{c|}{\cellcolor{yellow} .42}    & \multicolumn{1}{c|}{\cellcolor{yellow} .06}   & \multicolumn{1}{c}{\cellcolor{yellow} .88**}    \\
    \multicolumn{1}{c}{}                         & $\beta$   & \multicolumn{1}{c|}{\cellcolor{yellow} .36}     & \multicolumn{1}{c|}{\cellcolor{purple} 1.52*}  & \multicolumn{1}{c|}{\cellcolor{yellow} .09}       & \multicolumn{1}{c|}{\cellcolor{yellow} 1.33*}  & \multicolumn{1}{c|}{\cellcolor{yellow} 1.51*} & \multicolumn{1}{c}{\cellcolor{purple} 1.51*}    \\
    \end{tabular}
  }
}{Tokenized vs. Merged wo QA}

% \tab{tab:configs}{The different hyperparameter configurations for each dataset.}{
%   \scalebox{0.9}{
%     \begin{tabular}{ll|ccccc}
%                                                    &             & \# of epochs                             & split set up                                & batch size                              & maximum length                 & SRL implementation                          \\ \hline
%     \multicolumn{1}{c}{\multirow{2}{*}{deISEAR}}   &  $\alpha$   & \multicolumn{1}{c}{\multirow{2}{*}{100}} & \multicolumn{1}{c}{\multirow{2}{*}{normal}} & \multicolumn{1}{c}{\multirow{2}{*}{16}} & 40                             & \multicolumn{1}{c}{\multirow{2}{*}{normal}} \\
%     \multicolumn{1}{c}{}                           &  $\beta$    &                                          &                                             &                                         & 200                            &                                             \\
%     \multicolumn{1}{c}{\multirow{2}{*}{SCARE}}     &  $\alpha$   & \multicolumn{1}{c}{\multirow{2}{*}{50}}  & \multicolumn{1}{c}{\multirow{2}{*}{normal}} & \multicolumn{1}{c}{\multirow{2}{*}{16}} & 50                             & \multicolumn{1}{c}{\multirow{2}{*}{normal}} \\
%     \multicolumn{1}{c}{}                           &  $\beta$    &                                          &                                             &                                         & 100                            &                                             \\ \hline
%     \multicolumn{1}{c}{\multirow{2}{*}{PAWS-X}}    &  $\alpha$   & 20                                       & normal                                      & 16                                      & 16                             & normal                                      \\
%     \multicolumn{1}{c}{}                           &  $\beta$    & 20                                       & normal                                      & 16                                      & 16                             & normal                                      \\
%     \multicolumn{1}{c}{\multirow{2}{*}{XNLI}}      &  $\alpha$   & 50                                       & normal                                      & 16                                      & 100                            & normal                                      \\
%     \multicolumn{1}{c}{}                           &  $\beta$    & 50                                       & re-split                                    & 16                                      & 100                            & normal                                      \\ \hline
%     \multicolumn{1}{c}{\multirow{2}{*}{MLQA}}      &  $\alpha$   & \colorbox{blue}{40}                      & \colorbox{blue}{200}                        & \colorbox{blue}{50}                     & \colorbox{blue}{100}           & normal                                      \\
%     \multicolumn{1}{c}{}                           &  $\beta$    & \colorbox{blue}{40}                      & \colorbox{blue}{200}                        & \colorbox{blue}{50}                     & \colorbox{blue}{100}           & normal                                      \\
%     \multicolumn{1}{c}{\multirow{2}{*}{XQuAD}}     &  $\alpha$   & \colorbox{blue}{40}                      & \colorbox{blue}{200}                        & \colorbox{blue}{50}                     & \colorbox{blue}{100}           & 100                                         \\
%     \multicolumn{1}{c}{}                           &  $\beta$    & \colorbox{blue}{40}                      & \colorbox{blue}{200}                        & \colorbox{blue}{50}                     & \colorbox{blue}{100}           & 100                                         \\
%     \end{tabular}
%   }
% }{Dataset specific Configs}

\tab{tab:hyper-configs}{Stable hyperparameter configurations.}{
  \scalebox{0.9}{
    \begin{tabular}{ll}
    learning rate              & 2e-05                         \\
    SRL embedding dimensions   & 20                            \\
    SRL GRU hidden size        & 32                            \\
    SRL number of layers       & 2                             \\
    SRL bias                   & True                          \\
    SRL bidirectional          & True                          \\
    SRL dropout                & 0.1                           \\
    \# of Epochs               & 50 (deISEAR, SCARE, XNLI, MLQA, XQuAD), 20 (PAWS-X) \\
    Batch Size                 & 16 (classification datasets) 8 (Q\&A datasets) \\
    maximum sequence length    & 100 (PAWS-X, XNLI) 512 (MLQA, XQuAD)
    \end{tabular}
  }
}{Stable Hyperparameter Configs}

Another accumulating view on the main table \ref{tab:results} is constructed by not just
looking for the best results ov a whole row, i.e. over all heads, merging strategies,
and SRL implementations, but instead record the superiority or inferiority of +SRL
compared to $-$SRL for each pairing: Take for example the deISEAR $\alpha$ subtokenized
[CLS] head setting: Without SRLs, the ensemble performance was 71.52\%; now the better
of the two +SRL implementations of this setting is taken into account, in this case
zeroing apparently was better. The difference, .67\% is controlled for significance and
reported in the table. The coloring indicates which SRL implementation performed better
and was taken into account; sometimes both implementations performed equally, which is
also reflected in coloring. Negative numbers indicate, of course, that the head produced
better results when SRL information was \emph{not} added (and this was also controlled
for significance).
Looking at the such accumulated results (table \ref{gain-loss}), no clear picture emerges
at first glance; sometimes zeroing SRLs performed better than duplicating SRLs, sometimes not,
sometimes +SRLs clearly outperforms $-$SRL, even highly statistically, sometimes it is
the other way around adding SRLs seems to create a disadvantage for the head.

To add one more abstraction layer and see a more complete picture, this table is again
summarized in figure \ref{fig:classification-gains}. Doing this, the image
clarifies, allowing to stipulate that adding SRLs on GerGLUE classification tasks
leads to a measurable improvement. The total gains clearly outweigh the losses, and also
more statistically significant. Regarding the SRL implementation, there is no clear advantage
of one method over the other, only a slight tendency of duplicating being more effective
than zeroing.


\tab{tab:gain-loss}{Ensemble percentage points gains (positive numbers) / losses (negative numbers) for +SRL
                      over $-$SRL for each configuration from table \ref{tab:results}. The better of the +SRL configurations was taken into account:
                      \customcolorbox{zeros}{blue},
                      \customcolorbox{duplicate}{dark-blue}.
                      Light blue denotes that both architectures performed
                      \customcolorbox{equally}{llight-blue}
                      (in which case both ensembles were controlled for significance). One asterisk signifies
                      a $p$-value $<$ 10\%, two stand for $p <$ 5\% and three for $p <$ 1\%.}{
    \scalebox{1}{
      \begin{tabular}{llP{1.5cm}P{1.5cm}P{1.5cm}P{1.5cm}P{1.5cm}P{1.5cm}}
                                                   &           & \multicolumn{2}{c|}{\textbf{{[}CLS{]} Head}}                                                                 & \multicolumn{2}{c|}{\textbf{FFNN Head}}                                                                        & \multicolumn{2}{c}{\textbf{GRU Head}}                                                                     \\ \cline{3-8}
                                                   &           & \multicolumn{1}{c|}{subtok.}                          & \multicolumn{1}{c|}{merged}                          & \multicolumn{1}{c|}{subtok.}                          & \multicolumn{1}{c|}{merged}                            & \multicolumn{1}{c|}{subtok.}                        & \multicolumn{1}{c}{merged}                          \\ \hline\hline
      \multicolumn{1}{c}{\multirow{2}{*}{deISEAR}} & $\alpha$  & \multicolumn{1}{c|}{\cellcolor{blue} .67}             & \multicolumn{1}{c|}{\cellcolor{dark-blue} .00}       & \multicolumn{1}{c|}{\cellcolor{blue} 6.62**}          & \multicolumn{1}{c|}{\cellcolor{dark-blue} .00}         & \multicolumn{1}{c|}{\cellcolor{blue} 4.63**}        & \multicolumn{1}{c}{\cellcolor{dark-blue} $-1.99$}   \\
      \multicolumn{1}{c}{}                         & $\beta$   & \multicolumn{1}{c|}{\cellcolor{llight-blue} 3.31}     & \multicolumn{1}{c|}{\cellcolor{dark-blue} 1.99}      & \multicolumn{1}{c|}{\cellcolor{dark-blue} $-4.63$*}   & \multicolumn{1}{c|}{\cellcolor{blue} $-1.32$}          & \multicolumn{1}{c|}{\cellcolor{blue} 1.32}          & \multicolumn{1}{c}{\cellcolor{dark-blue} $-1.99$}   \\ \cline{3-8}
      \multicolumn{1}{c}{\multirow{2}{*}{SCARE}}   & $\alpha$  & \multicolumn{1}{c|}{\cellcolor{dark-blue} $-1.90$*}   & \multicolumn{1}{c|}{\cellcolor{dark-blue} 2.28*}     & \multicolumn{1}{c|}{\cellcolor{dark-blue} .76}        & \multicolumn{1}{c|}{\cellcolor{dark-blue} .38}         & \multicolumn{1}{c|}{\cellcolor{dark-blue} .38}      & \multicolumn{1}{c}{\cellcolor{blue} $-1.89$}        \\
      \multicolumn{1}{c}{}                         & $\beta$   & \multicolumn{1}{c|}{\cellcolor{blue} $-1.51$**}       & \multicolumn{1}{c|}{\cellcolor{llight-blue} .00}     & \multicolumn{1}{c|}{\cellcolor{blue} $-.76$}          & \multicolumn{1}{c|}{\cellcolor{dark-blue} $-.38$}      & \multicolumn{1}{c|}{\cellcolor{blue} .76}           & \multicolumn{1}{c}{\cellcolor{dark-blue} $-1.13$}   \\ \hline
      \multicolumn{1}{c}{\multirow{2}{*}{PAWS-X}}  & $\alpha$  & \multicolumn{1}{c|}{\cellcolor{blue} .97*}            & \multicolumn{1}{c|}{\cellcolor{dark-blue} 2.59***}   & \multicolumn{1}{c|}{\cellcolor{blue} $-.41$}          & \multicolumn{1}{c|}{\cellcolor{dark-blue} .25}         & \multicolumn{1}{c|}{\cellcolor{llight-blue} .51}     & \multicolumn{1}{c}{\cellcolor{dark-blue} .71}       \\
      \multicolumn{1}{c}{}                         & $\beta$   & \multicolumn{1}{c|}{\cellcolor{dark-blue} .72*}       & \multicolumn{1}{c|}{\cellcolor{dark-blue} .25}       & \multicolumn{1}{c|}{\cellcolor{blue} .56}             & \multicolumn{1}{c|}{\cellcolor{dark-blue} $-1.07$***}  & \multicolumn{1}{c|}{\cellcolor{dark-blue} .30}      & \multicolumn{1}{c}{\cellcolor{dark-blue} .05}       \\ \cline{3-8}
      \multicolumn{1}{c}{\multirow{2}{*}{XNLI}}    & $\alpha$  & \multicolumn{1}{c|}{\cellcolor{blue} .18}             & \multicolumn{1}{c|}{\cellcolor{blue} $-.22$}         & \multicolumn{1}{c|}{\cellcolor{blue} .22}             & \multicolumn{1}{c|}{\cellcolor{blue} .70*}             & \multicolumn{1}{c|}{\cellcolor{dark-blue} .46}      & \multicolumn{1}{c}{\cellcolor{dark-blue} .12}       \\
      \multicolumn{1}{c}{}                         & $\beta$   & \multicolumn{1}{c|}{\cellcolor{blue} .09}             & \multicolumn{1}{c|}{\cellcolor{dark-blue} .44}       & \multicolumn{1}{c|}{\cellcolor{dark-blue} .09}        & \multicolumn{1}{c|}{\cellcolor{blue} .53}              & \multicolumn{1}{c|}{\cellcolor{blue} .98}           & \multicolumn{1}{c}{\cellcolor{dark-blue} .89}       \\ % \hline\hline
      % & \multicolumn{2}{l}{Accumulation}                  \\ \cline{2-4}
      % & \multicolumn{2}{l}{\textbf{Gains} (significant)}  & 32 (5) \\
      % & \multicolumn{2}{l}{\textbf{Losses} (significant)} & 15 (3) \\
     \end{tabular}
    }
  }{Gain-Loss}

\begin{figure}
  \begin{minipage}{0.45\linewidth}
  \vspace{0pt}
    \includegraphics[width=0.9\linewidth]{images/gain_losses_accumulated.pdf}
  \end{minipage}
  \hfill
  \begin{minipage}{0.45\linewidth}
  \vspace{0pt}
    \includegraphics[width=0.9\linewidth]{images/gain_losses_SRL.pdf}
  \end{minipage}
  \stepcounter{myfigure}
  \label{fig:classification-gains}
  \caption[Accumulated Gains and Losses.]{Accumulated scores from table \ref{tab:gain-loss}. \textbf{Left}: Which SRL mode performed stronger out of a total of 48 settings. The bars indicate a slight outperforming of duplicating SRLs instead of adding zeros. \textbf{Right}: Counts for Gains and Losses in all 48 settings. Darker shades indicate significant results. The light green tip stands for settings where the gain equals 0.00.}
\end{figure}

As described in chapter \ref{chap:3_datasets}, the datasets compiled in GerGLUE are a quite
heterogeneous assemble: Some datasets like deISEAR and, especially, SCARE comprise rather
informal, colloquial tests, while PAWS-X and XNLI consists of more technical, standardized text.
Further, as depicted in figure \ref{fig:num_predarg_structs}, over 30\% of the sentences
in SCARE don't have any predicate-argument structures --- in other words there is no exploitable SRL
information for the model.

In figure \ref{fig:each-dataset-gains}, the same accumulation process as for the general overview
% in figure \ref{fig:classification-gains} is conducted for each dataset. The following observations
can be made: The positive effect of enriching BERT embeddings with SRLs is especially evident for
the sentence pair classification tasks: PAWS-X has the highest number of experiments where a significant
improvement over vanilla BERT embeddings could be measured, and has overall clearly gained from adding
SRLs. While XNLI has only one significant improved experiment, the overall number of experiments
where a positive effect was measured outweighs the negative one by far.

For the single sentence tasks, however, the picture somewhat darkens. While there were some
significant improvements for deISEAR, there were also quite some experiments where adding SRLs
seems to have weakend the model. Generally, deISEAR is the dataset that shows the strongest
fluctuations ranging from 67.55 to 77.48\% --- a range of staggering 9.93\%. It is not clear
to me why especially deISEAR shows this behaviour, but the relative small amount of examples
in the dataset could indicate that it is more prone to unlucky random initializations which
could be countered with more examples for the models to extrapolate from.
For SCARE, there is no clear positive effect measurable at all
--- in contrary, the significant deteriorations outnumber the significant gains. However, this
is not too surprising taking into account the afore mentioned fact of predicate scarceness in
SCARE (or at least, ParZu couldn't detect any). Further, the register is highly colloquial with
very frequent deviations from standard orthography etc. which all probably leads to a collapsing
of the already not too stable DAMESRL system.


\fig{images/all_datasets_gain_dup.pdf}{fig:each-dataset-gains}{Accumulation of statistics for each classification
                                       dataset \textbf{Left}: Which SRL architecture performed better.
                                       \textbf{Right}: Comparison of accuray points gained/lost after adding SRLs.}{15}{Results Accumulation for each Dataset}

\fig{images/all_heads_gain_dup.pdf}{fig:each-head-gains}{Accumulation of statistics for each head. \textbf{Left}: Which SRL architecture performed better.
                                       \textbf{Right}: Comparison of accuray points gained/lost after adding SRLs.}{15}{Results Accumulation for each Dataset}

One might ask if a simple accuracy is the right measure for all datasets, since
it is often common to compute other metrics, especially if class imbalance is
a known property of datasets. There are two main reasons as to why I chose to
stay with simple accuracy: (1) I am not interested in building a classifier
which explicitely handles such a problem, e.g. spam detection tasks. In such
cases, an F1-score of course is more meaningful because it is more sensibel to
predictions on underrepresented but task-important classes (such as spam). (2)
As reported in chapter \ref{chap:3_datasets}, most of my datasets do not show a
drastic class impbalance. To further substantiate this, I compute some metrics
for the most significantly imbalanced dataset, namely SCARE: A brute force
``stupid'' prediction of the majority class on the test set would results in an
accuracy of 59.09\% and a macro F1 of 24.76. The example confusion of an actual
experiment is shown in table \ref{tab:confusion-scare}: Altough the algorithm
overprefers the majority (``Positive'') class, it also predicts to some extent
the other ones. The measures resulting from this experiment are an accuracy of
83.71\% compared to the macro F1 of 73.52. Therefore, although the accuracy may
distort the picture to some extent, this is negligible in the context of this
thesis.


\tab{tab:confusion-scare}{Confusion matrix for SCARE $\alpha$ +SRL merged duplicated [CLS] head.}{
  \begin{tabular}{|ll|ccc|}
    \hline
                                                    &           & \multicolumn{3}{c|}{Predicted} \\
                                                    &           & Positive & Neutral & Negative  \\ \hline
    \multirow{3}{*}{\rotatebox[origin=c]{90}{True}} & Positive  & 149      & 12      & 5         \\
                                                    & Neutral   & 4        & 11      & 6         \\
                                                    & Negative  & 3        & 8       & 66        \\ \hline
  \end{tabular}
}{Confusion matrix for one SCARE +SRL ensemble}


\section{Question Answering Dataset Results}

The reportings of the results for the question answering data sets follows
the line that was taken for the classification sets: A general table with the
ensemble test set results is reported in \ref{tab:results-qa}. But the verdict is far more
devastating: 3 out of 4 best results were achieved by models implementing vanilla BERT
embeddings and 3 out of 4 times the worst performance was measured for +SRL settings.

\tab{tab:results-qa}{Test set accuracy ensemble results (per 5 models) on question answering tasks. \textbf{Bold} font marks the best result per line, \underline{underline} the second best, and \textit{italics} the poorest.}{
  \scalebox{1}{
    \begin{tabular}{llccc|ccc}
                                               &           & \multicolumn{6}{c}{\large \textbf{Q\&A Datasets}}  \\ \\
                                               &           & \multicolumn{6}{c}{\textbf{Span Prediction Head}}                                                                                                                                                                                                \\ \cline{3-8}
                                               &           & \multicolumn{3}{c|}{subtokenized}                                                                                                & \multicolumn{3}{c}{subtokens merged}                                                                          \\ \cline{3-8}
                                               &           & \multicolumn{1}{c|}{$-$SRL}                     & \multicolumn{2}{c|}{+SRL}                                                      & \multicolumn{1}{c|}{$-$SRL}         & \multicolumn{2}{c}{+SRL}                                                \\ %\cline{3-4}\cline{6-7}
                                               &           & \multicolumn{1}{c|}{}                           & \multicolumn{1}{c}{zeros}             & \multicolumn{1}{c|}{dupl.}             & \multicolumn{1}{c|}{}               & \multicolumn{1}{c}{zeros}          & dupl.                              \\ \hline\hline
    \multicolumn{1}{c}{\multirow{2}{*}{MLQA}}  & $\alpha$  & \multicolumn{1}{c|}{\textbf{30.69}}             & \multicolumn{1}{c}{\underline{29.68}} & \multicolumn{1}{c|}{\underline{29.68}} & \multicolumn{1}{c|}{21.92}          & \multicolumn{1}{c}{21.92}          & \multicolumn{1}{c}{\textit{21.81}} \\
    \multicolumn{1}{c}{}                       & $\beta$   & \multicolumn{1}{c|}{\textbf{44.75}}             & \multicolumn{1}{c}{\underline{44.55}} & \multicolumn{1}{c|}{43.41}             & \multicolumn{1}{c|}{\textit{41.66}} & \multicolumn{1}{c}{41.86}          & \multicolumn{1}{c}{41.79}          \\ \cline{3-8}
    \multicolumn{1}{c}{\multirow{2}{*}{XQuAD}} & $\alpha$  & \multicolumn{1}{c|}{\textbf{42.01}}             & \multicolumn{1}{c}{\underline{41.42}} & \multicolumn{1}{c|}{41.12}             & \multicolumn{1}{c|}{37.87}          & \multicolumn{1}{c}{36.98}          & \multicolumn{1}{c}{\textit{35.50}} \\
    \multicolumn{1}{c}{}                       & $\beta$   & \multicolumn{1}{c|}{\underline{46.57}}          & \multicolumn{1}{c}{45.43}             & \multicolumn{1}{c|}{\textbf{46.86}}    & \multicolumn{1}{c|}{37.43}          & \multicolumn{1}{c}{\textit{37.14}} & \multicolumn{1}{c}{39.14}          \\ \hline\hline
    \multicolumn{1}{c}{Scores}                 &           & \multicolumn{1}{c|}{\textbf{III} \underline{I}} & \multicolumn{2}{c|}{\textbf{I} \underline{III}}                                & \multicolumn{1}{c|}{}               & \multicolumn{2}{c}{}                                                    \\ \cline{1-2}
    \multicolumn{1}{c}{+SRL}                   & \multicolumn{3}{l}{\textbf{1} \underline{3}} \\
    \multicolumn{1}{c}{$-$SRL}                 & \multicolumn{3}{l}{\textbf{3} \underline{1}}

    \end{tabular}
  }
}{Results-QA}

When accumulated for unfolding subtokenized vs. merged patterns, there emerges a surprisingly
clear tendency (see left side of table \ref{tab:qa-gain-loss-token-merged}): Splitting SRLs according to
the BERT subtokenization always showed stronger results than BERT merging. 5 times out of the
total 8 settings the differences were even highly significant with $p < 1\%$ and one time
moderately significant with $p < 5\%$. The reason for this rather {\color{red} drastic pattern
remains unclear to me}; despite tediously controlling the merging algorithm and validating the
re-computing of start and end indices, I could not make out any error.

Also for the Q\&A datasets, I compare setting-wise the performance of $-$SRL against the better +SRL experiment
(see right side of table \ref{tab:qa-gain-loss-token-merged}): The only significant result is the MLQA $\alpha$
subtokenized setting, where the SRL-enriching led to a loss of 1.01\%. The other results are mixed, with $-$SRL
performing 3 times better than +SRL.
The only dataset hyperparameter configuration where for both SRL combination methods the +SRL implementation
performed better was XQuAD $\beta$ --- however in both cases unsignificant.


\tab{tab:qa-gain-loss-token-merged}{\textbf{Left part}: Ensemble percentage points gains (positive numbers) / losses (negative numbers) for +SRL
                       over $-$SRL for the Span Prediction Head from table \ref{tab:results-qa}. The better of the +SRL configurations was taken into
                       account: \customcolorbox{zeros}{blue},
                       \customcolorbox{duplicate}{dark-blue}.
                       Light blue denotes that both architectures performed \customcolorbox{equally}{llight-blue}
                       (in which case both ensembles were controlled for significance).
                       One asterisk signifies a $p$-value $<$ 10\%, two stand for $p <$ 5\% and three for $p <$ 1\%.
                       \textbf{Right part}: Performance of architectures when BERT \customcolorbox{subtokenized}{yellow} vs. \customcolorbox{merged}{purple}. Both SRL implementations were
                          compared pairwise..}{
  \scalebox{1}{
    \begin{tabular}{llP{2cm}P{2cm}cP{2cm}P{2cm}}
                                                 &           & \multicolumn{5}{c}{\textbf{Span Prediction Head}}                                                                                                                                                                   \\
                                                 &           & \multicolumn{2}{c}{Gains/Losses}                                                                            &  & \multicolumn{2}{c}{subtokenized/merged}                                                            \\ \cline{3-4} \cline{6-7}
                                                 &           & \multicolumn{1}{P{1.5cm}|}{subtok.}                            & \multicolumn{1}{P{1.5cm}}{merged}                        &  & \multicolumn{1}{P{1.5cm}|}{zeros}                       & \multicolumn{1}{P{1.5cm}}{dupl.}                       \\ \hline\hline
    \multicolumn{1}{P{1.5cm}}{\multirow{2}{*}{MLQA}}    & $\alpha$  & \multicolumn{1}{P{1.5cm}|}{\cellcolor{llight-blue} $-$1.01***} & \multicolumn{1}{P{1.5cm}}{\cellcolor{blue} .00}          &  & \multicolumn{1}{P{1.5cm}|}{\cellcolor{yellow} 7.76***}  & \multicolumn{1}{P{1.5cm}}{\cellcolor{yellow} 7.86***}  \\
    \multicolumn{1}{P{1.5cm}}{}                         & $\beta$   & \multicolumn{1}{P{1.5cm}|}{\cellcolor{blue} $-$.20}            & \multicolumn{1}{P{1.5cm}}{\cellcolor{blue} .20}          &  & \multicolumn{1}{P{1.5cm}|}{\cellcolor{yellow} 2.69}     & \multicolumn{1}{P{1.5cm}}{\cellcolor{yellow} 1.62}     \\ \cline{3-4} \cline{6-7}
    \multicolumn{1}{P{1.5cm}}{\multirow{2}{*}{XQuAD}}   & $\alpha$  & \multicolumn{1}{P{1.5cm}|}{\cellcolor{blue} $-$.59}            & \multicolumn{1}{P{1.5cm}}{\cellcolor{blue} $-$.89}         &  & \multicolumn{1}{P{1.5cm}|}{\cellcolor{yellow} 4.44**}   & \multicolumn{1}{P{1.5cm}}{\cellcolor{yellow} 5.62***}  \\
    \multicolumn{1}{P{1.5cm}}{}                         & $\beta$   & \multicolumn{1}{P{1.5cm}|}{\cellcolor{dark-blue} .29}          & \multicolumn{1}{P{1.5cm}}{\cellcolor{dark-blue} 1.71}    &  & \multicolumn{1}{P{1.5cm}|}{\cellcolor{yellow} 8.29***}  & \multicolumn{1}{P{1.5cm}}{\cellcolor{yellow} 7.72***}  \\
   \end{tabular}
  }
}{QA Gain-Loss / QA Tokenized vs. merged}


Therefore, the overall aggregation in figure \ref{fig:qa-tot-gains} does not look too promising for the
research question of this thesis: For the two question answering datasets in GerGLUE, the effect of enriching
BERT embeddings with SRL information seems to rather harm the model instead of adding helpful information.
Interestingly, this contrasts with the findings of \citeauthor{zhang2019semantics}, which reported a gain
of 4.3\% in accuracy on the SQuAD 2.0 set for their SemBERT implementation.\myfootnote{However, a ``synthetic
self training'' technique for this results is mentioned which is not elaborated upon any more. For their
``regular'' SemBERT large implementation the reported gain is 1.9\% --- which still would stand
for a positive influence of SRL enriching which is not reflected in my experiments.}

\begin{figure}
  \begin{minipage}{0.45\linewidth}
  \vspace{0pt}
    \includegraphics[width=0.9\linewidth]{images/QA_gain_losses_accumulated.pdf}
  \end{minipage}
  \hfill
  \begin{minipage}{0.45\linewidth}
  \vspace{0pt}
    \includegraphics[width=0.9\linewidth]{images/QA_gain_losses_SRL2.pdf}
  \end{minipage}
  \stepcounter{myfigure}
  \label{fig:qa-tot-gains}
  \caption[Accumulated Gains and Losses.]{Accumulated scores from table \ref{tab:qa-gain-loss}. \textbf{Left}: Which SRL mode performed stronger out of a total of 8 settings. The bars indicate a slight outperforming of duplicating SRLs instead of adding zeros. \textbf{Right}: Counts for Gains and Losses in all 8 settings. Darker shades indicate significant results. The light green tip stands for settings where the gain equals 0.00.}
\end{figure}


\fig{images/all_data_sets_token_stats.pdf}{fig:all-data-sets-token-stats}{Percentages of token-types in all datasets.
                                                                          \#\# Subtokens represent the amount of tokens that
                                                                          get re-merged in the merged settings (e.g. ``Master''
                                                                          ``\#\#arbeit'' $\rightarrow$ ``Masterarbeit''. The amount
                                                                          of tokens that lie outside of the German BERT vocabulary is
                                                                          in all datasets extremely small (for deISEAR and XNLI
                                                                          there are no [UNK]s at all); the largest shares of such tokens
                                                                          are present in MLQA and XQuAD with .79\% and .73\%,
                                                                          respectively.}{14}{Token Types all Datasets}

Main conclusion: SRL information in tendency helpful but the effects are not very stable and even
negative sometimes


After reporting the general results, aggregations and the somewhat disenchanting conclusion, I
now try to investigate the reasons for this mediocre effect. After investigating the data and
SRL quality, I found that noise on several levels is present which probably led to too much
randomness in the complex functions the models needed to approximate. I classify the observed
data irregularites into the follwing categories:

\begin{itemize}
  \item[\textbf{register noise}] The textual styles vary greatly from utilizing complex,
                                 hypotactic sentence structures (e.g. XQuAD), to highly
                                 informal, elliptic --- even erratic --- structures
                                 (e.g. SCARE).
 \item[\textbf{label noise}] Many of my datasets were constructed either automatically
                             (e.g. scrambling text automatically to create paraphrase pairs)
                             or employing crowd-sourcing techniques. Either way, the process
                             is prone to erros. There are, e.g., 84 sentence pairs in the trainig
                             set of PAWS-X that are 100\% identical, yet labelled as non-paraphrases.
 \item[\textbf{translation noise}] Due to the mostly employed semi-automatic translation
                                   approach for creating the various datasets, errors
                                   have been introduced into the data ranging from typical
                                   translation errors (e.g. English ``bishop'' in the clerical
                                   context translated to the German chess figure counterpart
                                   ``Läufer'', not ``Bischof'') to eventually wrongly copied
                                   labels, since the overall meaning changed during
                                   the tranlsation process (e.g. a sentence pair is no more
                                   contradictive but neutral), thus creating label noise.
 \item[\textbf{SRL noise}] The SRLs obtained from DAMESRL are, conservatively formulated,
                           questionable in their quality (e.g. modifiers are completely missing).
\end{itemize}

While it is normal for data in NLP to possess noise in some way or the other, this usually does
not impact the overall performance of a model trainied on it in a severe way, since information
in language is encoded redundantly, and noise present in one channel can be compensated for by
uncorrupted information from another channel.\myfootnote{For example, information about which
constituent takes the syntactic function of the subject is often not marked by using only one
possibility, e.g. though a case ending. Often, several strategies are present, as in German: The
subject is marked morphologically through case endigs (which are not always alient), positionally
(in unmarked contexts), and structurally (in unmarked contexts, normally the proto-agent is
realized as subject) (cf. \cite{bussmann2006routledge,jaeger2010redundancy})} However, if noise
is present on too many channels at the same time, reliably recovering structural information may
break down to some extent. In short --- the good old GIGO concept from informatics holds mutatis
mutandis also in NLP, and human language in general.



\section{Register Noise}
\label{sec:register-noise}

German BERT was pretrained on the German Wikipedia dump, the OpenBooks Corpus and

\section{Label Noise}
\label{sec:label-noise}

As \citep{caswell2021quality} point out,


PAWS-X sentence number 45061, labelled as non-paraphrases:

Riverton was a parliamentary electorate in the New Zealand region of Southland .
Riverton was a parliamentary electorate in the New Zealand region of Southland .

Riverton war ein Parlamentswähler in der neuseeländischen Region Southland.
Riverton war ein Parlamentswähler in der neuseeländischen Region Southland.


\subsubsection{Re-annotation}

\textbf{PAWS-X}

2 human annotators re-label 20 examples of PAWS-X where gold != predicted.
Fleiss' $\kappa$ between 2 annotators: 0.68
Fleiss' $\kappa$ between 2 annotators and gold: 0.3541

6 examples where both annotators agree with predictions, disagree with gold:

\begin{examples}
  \item Der NVIDIA TITAN V wurde von Nvidia am 7. Dezember 2017 offiziell angekündigt.\\
        Am 07. Dezember 2017, verkündete NVIDIA offiziell Nvidia TITAN V.

        humans \& model: False, Gold: True
  \item Die Schäfte sind sehr kurz oder oft nicht vorhanden.\\
        Es sind entweder wenig Landschaften vorhanden oder sie fehlen in den meisten Fällen.

        humans \& model: False, Gold: True
  \item 1963 trat Roy der Kommunistischen Partei Indiens bei und leitete Gewerkschaftsbewegungen in Bansdroni in Kalkutta.\\
        Roy trat 1963 der Kommunistischen Partei Indiens bei und leitete Gewerkschaftsbewegungen im Kolkata-Gebiet von Bansdroni.

        humans \& model: True, Gold:False
  \item Der Kanal ist einer der ältesten schiffbaren Kanäle Europas und sogar Belgiens.\\
        Der Kanal ist einer der ältesten befahrbaren Kanäle in Belgien und Europa.

        humans \& model: True, Gold:False
  \item Propilidium pelseneeri ist eine Art der Meeresschnecken, eine wahre Napfschnecke und Gastropoden-Mollusk in der Familie der Lepetidae.\\
        Propilidium pelseneeri ist eine Art der Meeresschnecken, eine wahre Napfschnecke und Meeres-Gastropoden-Mollusk der Familie der Lepetidae.

        humans \& model: True, Gold:False
  \item Die Chicago Bears sanken auf die Giants 27:21, und verloren 0:6 zum ersten Mal seit 1976.\\
        Die Chicago Bears verloren 21:27 gegen die Bears und standen erstmals seit 1976 bei 0:6.

        humans \& model: False, Gold:True
\end{examples}


\textbf{XNLI}

2 human annotators re-label 20 examples of XNLI where gold != predicted.
Fleiss' $\kappa$ between 2 annotators: 0.36
Fleiss' $\kappa$ between 2 annotators and gold: 0.4787

1 example where 2 humans == model and 2 humans != Gold

Bato ist ein Jahrhunderte altes Wort, das man als Kerl oder Kumpel übersetzen kann.
Bato (oder Vato) ist ein spanisches Wort, das Typ oder Typ bedeutet.

humans \& model: neutral, Gold: Entailment

1 example where 2 humans != model and 2 humans != Gold

Oh, ich sehe oh der Staat braucht es nicht gut, das ist eher das, das ist eher ungewöhnlich, nicht wahr?
Das macht Sinn, dass der Staat es benötigt.

humans: neutral, model: entailment, Gold: contradiction


\section{Translation Noise}
\label{sec:translation-noise}

XNLI labelled as entailment

and that's a lot of it is due to the fact that the mothers are on drugs
The mothers take drugs.

Und vieles davon liegt daran, dass die Mütter Medikamente nehmen.
Die Mütter nehmen Drogen.

PAWS-X; different repair-strategies $\rightarrow$ different labels (gold: false)

Sawyers autorisierte Biografie wurde 2014 von Huston Smith veröffentlicht.
Im Jahr 2014 wurde Huston Smith eine autorisierte Biographie von Sawyer veröffentlicht.


Im Jahr 2014 wurde {\color{red} «}Huston Smith{\color{red} », } eine autorisierte Biographie von Sawyer{\color{red} ,} veröffentlicht.

Im Jahr 2014 wurde {\color{red} von|für|durch|trotz|wegen} Huston Smith eine autorisierte Biographie von Sawyer veröffentlicht.

Im Jahr 2014 wurde Huston Smith eine autorisierte Biographie von Sawyer veröffentlicht.


\section{SRL Noise}
\label{sec:srl-noise}

A major question arising in the context of using automatically assigned Semantic Roles in
downstream tasks, is how good these Semantic Roles are. Since there is no gold standard
available for Semantic Role Labels for the datasets I use in my experiments, there is no
straight-forward way to evaluate their quality {\color{red} automatically}. In contrast to
other tagging tasks like POS prediction or NER, Semantic Roles are not as black and white:
While it is relatively easy to decide if a predicted POS tag is correct or incorrect, it
is more a scale concerning SRLs.

\fig{images/SRL_assessment.pdf}{fig:SRL-assessment}{Independent evaluation of SRL quality by three people. Regardless of the label attributed to each example, it is obvious, that the total amount of sentences for which the annotators evaluated the corresponding semanti roles as \emph{helpful}, is relatively stable.}{11}{SRL assessment}

\fig{images/SRL_assessment_data_set.pdf}{fig:data-set-SRL-assessment}{Estimated quality of SRLs per dataset.}{15}{SRL assessment per datasets}


Fleiss' $\kappa$ = 0.2048 --- this slightly above the threshold of «fair agreement», as defined by \citep{landis1977measurement} (0.20).

The $\kappa$ for helpful vs. other is even worse: 0.1944

for individual datasets:

deISEAR: 0.0814

SCARE: 0.2401

PAWS-X: 0.1245

XNLI: 0.2475

MLQA: -0.3636

XQuAD: -0.5



\cite{do2018flexible}


\section{Ablation study}
\label{sec:ablation}

To be able to make substantial claims about the positive influence about a new algorithm over an
established one, it is common ground to conduct an ablation study. In such a study, one tries to
determine which aspects of the proposed architecture contribute how much to the overall performance
gain (or loss, respectively).

In my case, i.e. the attempt to improve the performance of BERT regarding NLU tasks, the
following question would need some ablation experiments to be answered: What part of the
SRLs is most responsible for the performance boost? To be able to formulate this in a
matter which can be experimentally tested, I identify two easily separatable and testable
aspects of SRLs: Firstly, the information what parts of a sentence are the predicates.
The intuition behind this is that maybe the head relies mostly on the information as to
which tokens carry information about the events that happen in a given sentence. To test
this, I simply drpo the information about all SRLs, except the information that a token
is a predicate. In the second case, the hypothesis is reversed: Maybe the head is able to
get the most useful hints about the information which inidcates what role certain token
groups play in a given sentence. To test for this all information about predicates is
dropped and only information about arguments is preserved.

\begin{minipage}{1.0\linewidth}
  \begin{srl}
  \centering
    \begin{BVerbatim}[commandchars=\\\{\}, fontsize=\footnotesize]
      Ich        \colorbox{llight-blue}{B-A0}         \colorbox{white}{O}
      weiß       \colorbox{blue}{B-V}          \colorbox{white}{O}
      nicht      \colorbox{white}{O}            \colorbox{white}{O}
      ob         \colorbox{llight-blue}{B-A1}         \colorbox{white}{O}
      er         \colorbox{llight-blue}{I-A1}         \colorbox{llight-blue}{B-A0}
      danach     \colorbox{llight-blue}{I-A1}         \colorbox{white}{O}
      in         \colorbox{llight-blue}{I-A1}         \colorbox{llight-blue}{B-A1}
      Augusta    \colorbox{llight-blue}{I-A1}         \colorbox{llight-blue}{I-A1}
      geblieben  \colorbox{llight-blue}{I-A1}         \colorbox{blue}{B-V}
      ist        \colorbox{llight-blue}{I-A1}         \colorbox{white}{O}
      .          \colorbox{white}{O}            \colorbox{white}{O}
      ==============================
      Er         \colorbox{llight-blue}{B-A0}
      wohnte     \colorbox{blue}{B-V}
      weiterhin  \colorbox{white}{O}
      in         \colorbox{llight-blue}{B-A1}
      Augusta    \colorbox{llight-blue}{I-A1}
      .          \colorbox{white}{O}
    \end{BVerbatim}
    \caption{Normal SRLs.}
  \end{srl}
\end{minipage}

\begingroup
\begin{srl}[!h]
\centering
  \begin{minipage}{0.45\linewidth}
  \vspace{0pt}
    \begin{BVerbatim}[commandchars=\\\{\}, fontsize=\footnotesize]
    Ich        \colorbox{white}{O}           \colorbox{white}{O}
    weiß       \colorbox{blue}{B-V}         \colorbox{white}{O}
    nicht      \colorbox{white}{O}           \colorbox{white}{O}
    ob         \colorbox{white}{O}           \colorbox{white}{O}
    er         \colorbox{white}{O}           \colorbox{white}{O}
    danach     \colorbox{white}{O}           \colorbox{white}{O}
    in         \colorbox{white}{O}           \colorbox{white}{O}
    Augusta    \colorbox{white}{O}           \colorbox{white}{O}
    geblieben  \colorbox{white}{O}           \colorbox{blue}{B-V}
    ist        \colorbox{white}{O}           \colorbox{white}{O}
    .          \colorbox{white}{O}           \colorbox{white}{O}
    ==============================
    Er         \colorbox{white}{O}
    wohnte     \colorbox{blue}{B-V}
    weiterhin  \colorbox{white}{O}
    in         \colorbox{white}{O}
    Augusta    \colorbox{white}{O}
    .          \colorbox{white}{O}
    \end{BVerbatim}
  \end{minipage}
  \hfill
  \begin{minipage}{0.45\linewidth}
  \vspace{0pt}
    \begin{BVerbatim}[commandchars=\\\{\}, fontsize=\footnotesize]
      Ich        \colorbox{llight-blue}{B-A0}         \colorbox{white}{O}
      weiß       \colorbox{white}{O}            \colorbox{white}{O}
      nicht      \colorbox{white}{O}            \colorbox{white}{O}
      ob         \colorbox{llight-blue}{B-A1}         \colorbox{white}{O}
      er         \colorbox{llight-blue}{I-A1}         \colorbox{llight-blue}{B-A0}
      danach     \colorbox{llight-blue}{I-A1}         \colorbox{white}{O}
      in         \colorbox{llight-blue}{I-A1}         \colorbox{llight-blue}{B-A1}
      Augusta    \colorbox{llight-blue}{I-A1}         \colorbox{llight-blue}{I-A1}
      geblieben  \colorbox{llight-blue}{I-A1}         \colorbox{white}{O}
      ist        \colorbox{llight-blue}{I-A1}         \colorbox{white}{O}
      .          \colorbox{white}{O}            \colorbox{white}{O}
      ==============================
      Er         \colorbox{llight-blue}{B-A0}
      wohnte     \colorbox{white}{O}
      weiterhin  \colorbox{white}{O}
      in         \colorbox{llight-blue}{B-A1}
      Augusta    \colorbox{llight-blue}{I-A1}
      .          \colorbox{white}{O}
    \end{BVerbatim}
  \end{minipage}
\end{srl}
\captionof{srl}{\textbf{Left}: Only predicate SRLs. \textbf{Right}:  Only argument SRLs.}
\endgroup


\tab{tab:pawsx-abla}{Ablation on Effect of PREDs and ARGs isolated. note that PRED/ARG SRL not significant (SCARE, XNLI ARGs almost, ca. 11\%)}{
  \scalebox{0.9}{
    \begin{tabular}{llcccc}
                     &                               & \multicolumn{1}{c|}{$-$SRL}                  & \multicolumn{3}{c}{+SRL}                                                                                                 \\
                     &                               & \multicolumn{1}{c|}{}                        & \multicolumn{1}{c}{only PREDs}         & \multicolumn{1}{c}{only ARGs}           & \multicolumn{1}{c}{normal}            \\ \cline{3-6}
    deISEAR $\alpha$ & FFNN Head subtok. zeros       & \multicolumn{1}{c|}{\textit{70.86}}          & \multicolumn{1}{c}{72.19}              & \multicolumn{1}{c}{\underline{75.50**}} & \multicolumn{1}{c}{\textbf{77.48**}}  \\
    SCARE $\alpha$   & [CLS] Head merged duplicate   & \multicolumn{1}{c|}{\textit{83.33}}          & \multicolumn{1}{c}{84.47}              & \multicolumn{1}{c}{\underline{85.23}}   & \multicolumn{1}{c}{\textbf{85.61*}}   \\
    PAWS-X $\beta$   & [CLS] Head merged duplicate   & \multicolumn{1}{c|}{\textit{79.92}}          & \multicolumn{1}{c}{80.53}              & \multicolumn{1}{c}{\underline{80.68}}   & \multicolumn{1}{c}{\textbf{82.51***}} \\
    XNLI $\beta$     & GRU Head subtok. zeros        & \multicolumn{1}{c|}{\textit{66.84}}          & \multicolumn{1}{c}{67.02}              & \multicolumn{1}{c}{\textbf{68.00}}      & \multicolumn{1}{c}{\underline{67.82}} \\
    \end{tabular}
  }
}{Ablation Study}
%%\section{BLEU Scores}
%\label{sec:5_bleuscores}
%
%Table \ref{bleuresults} shows how to use the predefined tab command to have it listed.
%%\tab{#1: label}{#2: long caption}{#3: the table content}{#4: short caption}
%\tab{bleuresults}{BLEU scores of different MT systems}
%{\begin{tabular}{ll|ccc|c}
%language pair		& ABC	& YYY	\\
%\hline
%EN$\rightarrow$DE	& 20.56	& 32.53 \\
%DE$\rightarrow$EN	& 43.35	& 52.53 \\
%\hline
%\end{tabular}
%}{ABC BLEU scores}
%
%And we can reference the large table in the appendix as Table \ref{appendixTable}
%
%\section{Evaluation}
%\label{sec:5_evaluation}
%We saw in section \ref{sec:5_bleuscores}
%
%We will see in subsection \ref{subsec:5_moreeval} some more evaluations.
%
%\subsection{More evaluation}
%\label{subsec:5_moreeval}
%
%
%\section{Citations}
%Although BLEU scores should be taken with caution (see \citet{Callison-Burch2006})
%or if you prefer to cite like this: \citep{Callison-Burch2006} \ldots
%
%to cite: \cite[30-31]{Koehn2005} \\
%to cite within parentheses/brackets: \citep{Koehn2005}, \citep[30-32]{Koehn2005}\\ %\usepackage[square]{natbib} => square brackets
%
%to cite within the text: \citet{Koehn2005}, \citet[37]{Koehn2005}\\
%only the author(s): \citeauthor{Callison-Burch2006}\\
%only the year: \citeyear{Callison-Burch2006}\\
%
%\section{Graphics}
%
%To include a graphic that appears in the list of figures, use the predefined fig command:\\
%%\fig{#1: filename}{#2: label}{#3: long caption}{#4: width}{#5: short caption}
%\fig{images/Rosetta_Stone.jpg}{fig:rosetta}{The Rosetta Stone}{10}{Rosetta}
%
%%\reffig{#1: label}
%And then reference it as \reffig{fig:rosetta} is easy.
%
%\section{Some Linguistics}
%
%(With the package 'covington')\\
%
%Gloss:
%
%\begin{examples}
% \item \gll The cat sits on the table.
%	    die Katze sitzt auf dem Tisch
%	\glt 'Die Katze sitzt auf dem Tisch.'
%    \glend
%\end{examples}
%
%Gloss with morphology:
%
%\begin{examples}
% \item \gll La gata duerm -e en la cama.
%	    Art.Fem.Sg Katze schlaf -3.Sg in Art.Fem.Sg Bett
%	\glt 'Die Katze schl\"aft im Bett.'
%    \glend
%\end{examples}
%
