
\newchap{Architecture}
\label{chap:4_architecture}

\section{Overview}

\section{Semantic Role Labeller}

A Semantic Role Labeller (SRL) is a system, that assigns automatically semantic roles to a given input text.\footnote{This may be one or multiple sentences.}

State-of-the-art semantic role labellers (SRLs) are end-to-end models, nowadays often implementing deep learning techniques, like RNNs or attention, that render tedious feature engineering unnecessary.
For my system, I implement the DAMESRL, a model presented by \cite{do2018flexible}.
I use their pre-trained German Character-Attention model which, according to the authors, achieved an F1 score of 73.5 on the CoNLL'09 task \citep{hajivc2009conll}.
However, their SRL needs as input not only the sentence, but also ``its predicate $w_p$ as input'' \citep{do2018flexible}.

``A major advantage of dependency grammars is their ability to deal with languages that are morphologically rich and have a relatively free word order.'' \citep[p.~274]{jurafsky2019speech}
For extracting predicates, I rely on the dependency tree the ParZu parser \cite{sennrich2013exploiting} generates for a given sentence.
Since one sentence can have multiple predicate-argument structures, I need to device an algorithm to extract the relevant predicates in a sentence.
This is not as straight forward as it seems on the first look.

\subsection{Finding Predicates}

Following \cite{foth2006umfassende}

\begin{examples}
	\label{ex:one-predicate}
	\item Die Keita-Dynastie regierte das vorkaiserliche und kaiserliche Mali vom 12. Jahrhundert bis Anfang des 17. Jahrhunderts.
\end{examples}

\begin{examples}
	\label{ex:one-predicate-mod}
	\item Im tibetischen Buddhismus werden die Dharma-Lehrer/innen gewöhnlich als Lama bezeichnet.
\end{examples}

\begin{examples}
	\label{ex:multiple-predicates}
	\item Die Klage wurde abgewiesen, was als Sieg beschrieben werden kann.
\end{examples}

whose dependency parse tree is shown in \reffig{fig:example-parzu}:
This sentence has five verbs in it, \textit{wurde}, \textit{abgewiesen}, \textit{beschrieben}, \textit{werden}, and \textit{kann} (POS-tag ``V'' in the second row), but only two of them are relevant predicates, i.e. predicates that carry ``true'' semantics.

%\fig{#1: filename}{#2: label}{#3: long caption}{#4: width}{#5: short caption}
\fig{images/exampleParzu2.png}{fig:example-parzu}{Example sentence with multiple predicates.}{16}{Multiple Predicates Dependency Parse Tree}

I propose the following algorithm \ref{alg:find-predicates} deciding whether a verb in a sentence is or isn't a predicate using a heuristic, mostly relying on the STTS-tags \citep{schiller1999guidelines} of the parser's output:

\begin{algorithm}
\caption{Predicate finding algorithm}
\label{alg:find-predicates}
	\begin{algorithmic}[1]
	\FORALL{token $t \in$ sentence}
		\IF{POS $t \neq$ 'V'}
			\STATE $t \leftarrow$ NOT\_PRED
		\ELSE
			\IF{STTS $t =$ 'VVFIN'}
				\STATE $t \leftarrow$ PRED
			\ELSE
				\STATE FLAG $\leftarrow True$
				\FORALL{token $u \neq t \in$ subclause \textbf{where} $t \in$ subclause}
					\IF{POS $u =$ 'V' $\land$ $u$ dependent on $t$}
						\STATE $t \leftarrow$ NOT\_PRED
						\STATE FLAG $\leftarrow False$
						\STATE \textbf{break}
					\ENDIF
				\ENDFOR
				\IF{FLAG $= True$}
					\STATE $t \leftarrow$ PRED
				\ENDIF
			\ENDIF
		\ENDIF
	\ENDFOR
\end{algorithmic}
\end{algorithm}

The condition on line 9, that only tokens in the respective subclause are considered, is ensured by making sure that if a token \textit{u}'s POS is ``V'' and it points to its head \textit{t}, that it is not itself the head of a subclause --- i.e. its dependency relation is e.g. ``relative clause''.
If that is the case the token \textit{u} is considered to belong to another subclause and therefore not preventing token \textit{t} from getting labelled as a predicate.
Consider again the example \ref{ex:multiple-predicates}: 
Let's say we are in the for-loop at the token \textit{weitergeleitet}.
Because it is a verb but not a finite full-verb, we enter the else-clause on line 7.
If we were now to loop through all token of sentence \ref{ex:multiple-predicates} we would find that token \textit{führt} is a verb that points to our primary token.
Without the above outlined constraint that only verbs in the same subclause pointing to our original verb are preventing it from being labelled a predicate, \textit{weitergeleitet} would be labelled as non-predicate.
This is obviously false.
Taking into account the above considerations, we see that although \textit{führt} points to \textit{weitergeleitet}, its edge label is \textit{rel} --- which means that it's the head of a relative subclause --- therefore it is not anymore in the same subclause and \textit{weitergeleitet} gets labelled as predicate.


% 
% \begin{itemize}
% 	\item if the POS-tag of a token \textit{t} is not ``V'' --- i.e. it is a not verbal form ---, it is immediately labelled \texttt{NOT\_PRED}
% 	\item if the POS-tag of a token \textit{t} is verbal and its  STTS-tag is ``VVFIN'' --- i.e. it is a inflected full-verb --- it is immediately labelled \texttt{PRED}
% 	\item if the POS-tag of a token \textit{t} is verbal and its STTS-tag is not ``VVFIN'', it is checked whether any of the other tokens in this subclause is POS-tagged as ``V'' and if it is dependent on \textit{t}, i.e. if it points to the index of \textit{t}.
% 	If this is the case for any token in the subclause, \textit{t} gets labelled \texttt{NOT\_PRED}, since it only modifies another verb.
% 	If there is no token that fulfills the above mentioned criteria, \textit{t} is considered a predicate and gets labelled \texttt{PRED}.
% \end{itemize}


\section{German BERT}

Since its publishing two years ago, BERT \citep{devlin2018bert} has often been called a ``turning-point'' in ML in NLP.

% \section{BLEU Scores}
% \label{sec:5_bleuscores}
% 
% Table \ref{bleuresults} shows how to use the predefined tab command to have it listed.
% %\tab{#1: label}{#2: long caption}{#3: the table content}{#4: short caption}
% \tab{bleuresults}{BLEU scores of different MT systems}
% {\begin{tabular}{ll|ccc|c}
% language pair		& ABC	& YYY	\\
% \hline
% EN$\rightarrow$DE	& 20.56	& 32.53 \\
% DE$\rightarrow$EN	& 43.35	& 52.53 \\
% \hline
% \end{tabular}
% }{ABC BLEU scores}
% 
% And we can reference the large table in the appendix as Table \ref{appendixTable}
% 
% \section{Evaluation}
% \label{sec:5_evaluation}
% We saw in section \ref{sec:5_bleuscores} 
% 
% We will see in subsection \ref{subsec:5_moreeval} some more evaluations.
% 
% \subsection{More evaluation}
% \label{subsec:5_moreeval}
% 
% 
% \section{Citations}
% Although BLEU scores should be taken with caution (see \citet{Callison-Burch2006})
% or if you prefer to cite like this: \citep{Callison-Burch2006} \ldots
% 
% to cite: \cite[30-31]{Koehn2005} \\
% to cite within parentheses/brackets: \citep{Koehn2005}, \citep[30-32]{Koehn2005}\\ %\usepackage[square]{natbib} => square brackets
% 
% to cite within the text: \citet{Koehn2005}, \citet[37]{Koehn2005}\\
% only the author(s): \citeauthor{Callison-Burch2006}\\
% only the year: \citeyear{Callison-Burch2006}\\
% 
% \section{Graphics}
% 
% To include a graphic that appears in the list of figures, use the predefined fig command:\\
% %\fig{#1: filename}{#2: label}{#3: long caption}{#4: width}{#5: short caption}
% \fig{images/Rosetta_Stone.jpg}{fig:rosetta}{The Rosetta Stone}{10}{Rosetta}
% 
% %\reffig{#1: label}
% And then reference it as \reffig{fig:rosetta} is easy.
% 
% \section{Some Linguistics}
% 
% (With the package 'covington')\\
% 
% Gloss:
% 
% \begin{examples}
%  \item \gll The cat sits on the table.
% 	    die Katze sitzt auf dem Tisch
% 	\glt 'Die Katze sitzt auf dem Tisch.'
%     \glend
% \end{examples}
% 
% Gloss with morphology:
% 
% \begin{examples}
%  \item \gll La gata duerm -e en la cama.
% 	    Art.Fem.Sg Katze schlaf -3.Sg in Art.Fem.Sg Bett
% 	\glt 'Die Katze schl\"aft im Bett.'
%     \glend
% \end{examples}
% 
